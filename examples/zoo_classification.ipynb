{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "fxXpmnw8KinY"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Activation Functions"
      ],
      "metadata": {
        "id": "mQtpSxbKKzTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Base Activation Function Class\n",
        "class Activation:\n",
        "    def forward(self, z):\n",
        "        \"\"\"Forward pass for activation\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def backward(self, z):\n",
        "        \"\"\"Backward pass for activation derivative\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "# ReLU Activation\n",
        "class ReLU(Activation):\n",
        "    def forward(self, z):\n",
        "        \"\"\"ReLU activation: f(z) = max(0, z)\"\"\"\n",
        "        return np.maximum(0, z)\n",
        "\n",
        "    def backward(self, z):\n",
        "        \"\"\"Derivative of ReLU: 1 if z > 0, else 0\"\"\"\n",
        "        return (z > 0).astype(float)\n",
        "\n",
        "# Sigmoid Activation\n",
        "class Sigmoid(Activation):\n",
        "    def forward(self, z):\n",
        "        \"\"\"Sigmoid activation: f(z) = 1 / (1 + exp(-z))\"\"\"\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def backward(self, z):\n",
        "        \"\"\"Derivative of Sigmoid\"\"\"\n",
        "        s = self.forward(z) # Calculate sigmoid output during backward pass\n",
        "        return s * (1 - s)\n",
        "\n",
        "# Tanh Activation\n",
        "class Tanh(Activation):\n",
        "    def forward(self, z):\n",
        "        \"\"\"Tanh activation\"\"\"\n",
        "        return np.tanh(z)\n",
        "\n",
        "    def backward(self, z):\n",
        "        \"\"\"Derivative of Tanh\"\"\"\n",
        "        return 1 - np.tanh(z) ** 2\n",
        "\n",
        "# Softmax Activation\n",
        "class Softmax(Activation):\n",
        "    def forward(self, z):\n",
        "        \"\"\"Softmax activation for multi-class output\"\"\"\n",
        "        exp_z = np.exp(z - np.max(z, axis=0, keepdims=True))  # Subtract max for numerical stability\n",
        "        return exp_z / np.sum(exp_z, axis=0, keepdims=True)\n",
        "\n",
        "    def backward(self, z):\n",
        "        \"\"\"Dummy derivative for softmax when used with crossentropy loss\"\"\"\n",
        "        # The gradient for softmax is typically handled together with the cross-entropy loss\n",
        "        # For backpropagation purposes with crossentropy, we return 1 here and the\n",
        "        # combined gradient is calculated in the loss function's backward pass (or directly in the training loop).\n",
        "        return np.ones_like(z)\n",
        "\n",
        "# Linear Activation\n",
        "class Linear(Activation):\n",
        "    def forward(self, z):\n",
        "        \"\"\"Linear activation: f(z) = z\"\"\"\n",
        "        return z\n",
        "\n",
        "    def backward(self, z):\n",
        "        \"\"\"Derivative of linear activation: 1\"\"\"\n",
        "        return np.ones_like(z)\n",
        "\n",
        "# Leaky ReLU Activation\n",
        "class LeakyReLU(Activation):\n",
        "    def __init__(self, alpha=0.01):\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, z):\n",
        "        \"\"\"Leaky ReLU activation\"\"\"\n",
        "        return np.where(z > 0, z, self.alpha * z)\n",
        "\n",
        "    def backward(self, z):\n",
        "        \"\"\"Derivative of Leaky ReLU\"\"\"\n",
        "        return np.where(z > 0, 1, self.alpha)"
      ],
      "metadata": {
        "id": "__R7LDOtKxDg"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss Functions"
      ],
      "metadata": {
        "id": "y-6G8wGQLXYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Base Loss Function Class\n",
        "class Loss:\n",
        "    def compute_loss(self, y_pred, y_true):\n",
        "        \"\"\"Compute the loss\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def backward(self, y_pred, y_true):\n",
        "        \"\"\"Compute the initial gradient for backpropagation\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "# Mean Squared Error Loss\n",
        "class MSE(Loss):\n",
        "    def compute_loss(self, y_pred, y_true):\n",
        "        \"\"\"Mean Squared Error loss\"\"\"\n",
        "        return np.mean((y_pred - y_true) ** 2) / 2\n",
        "\n",
        "    def backward(self, y_pred, y_true):\n",
        "        \"\"\"Initial gradient for MSE\"\"\"\n",
        "        return y_pred - y_true\n",
        "\n",
        "# Categorical Crossentropy Loss\n",
        "class CategoricalCrossentropy(Loss):\n",
        "    def compute_loss(self, y_pred, y_true):\n",
        "        \"\"\"Categorical Crossentropy loss with clipping to avoid log(0)\"\"\"\n",
        "        epsilon = 1e-15\n",
        "        y_pred_clipped = np.clip(y_pred, epsilon, 1 - epsilon)\n",
        "        return -np.mean(np.sum(y_true * np.log(y_pred_clipped), axis=0))\n",
        "\n",
        "    def backward(self, y_pred, y_true):\n",
        "        \"\"\"Initial gradient for Categorical Crossentropy (often combined with Softmax)\"\"\"\n",
        "        # For Softmax + Categorical Crossentropy, the combined gradient is simply y_pred - y_true\n",
        "        return y_pred - y_true"
      ],
      "metadata": {
        "id": "6Tpae2C5LWui"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizers"
      ],
      "metadata": {
        "id": "v5b9jbQdLdv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Optimizer:\n",
        "    def __init__(self, learning_rate):\n",
        "        \"\"\"Base optimizer class with learning rate\"\"\"\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def update(self, layers, grads):\n",
        "        pass\n",
        "\n",
        "class GradientDescent(Optimizer):\n",
        "    \"\"\"Gradient Descent optimizer (mini-batch GD; SGD with batch_size=1)\"\"\"\n",
        "    def update(self, layers, grads):\n",
        "        \"\"\"Update weights and biases using gradient descent\"\"\"\n",
        "        for layer, (dW, db) in zip(layers, grads):\n",
        "            layer.weights -= self.learning_rate * dW\n",
        "            layer.biases -= self.learning_rate * db\n",
        "\n",
        "class Adam(Optimizer):\n",
        "    \"\"\"Adam optimizer with momentum and RMSprop components\"\"\"\n",
        "    def __init__(self, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
        "        super().__init__(learning_rate)\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.epsilon = epsilon\n",
        "        self.v = {}  # First moment estimate\n",
        "        self.s = {}  # Second moment estimate\n",
        "        self.t = 0   # Time step\n",
        "\n",
        "    def update(self, layers, grads):\n",
        "        \"\"\"Update weights and biases using Adam optimization\"\"\"\n",
        "        self.t += 1\n",
        "        for i, (layer, (dW, db)) in enumerate(zip(layers, grads)):\n",
        "            if i not in self.v:\n",
        "                self.v[i] = {'W': np.zeros_like(layer.weights), 'b': np.zeros_like(layer.biases)}\n",
        "                self.s[i] = {'W': np.zeros_like(layer.weights), 'b': np.zeros_like(layer.biases)}\n",
        "            # Update biased first moment estimate\n",
        "            self.v[i]['W'] = self.beta1 * self.v[i]['W'] + (1 - self.beta1) * dW\n",
        "            self.v[i]['b'] = self.beta1 * self.v[i]['b'] + (1 - self.beta1) * db\n",
        "            # Update biased second raw moment estimate\n",
        "            self.s[i]['W'] = self.beta2 * self.s[i]['W'] + (1 - self.beta2) * (dW ** 2)\n",
        "            self.s[i]['b'] = self.beta2 * self.s[i]['b'] + (1 - self.beta2) * (db ** 2)\n",
        "            # Compute bias-corrected estimates\n",
        "            v_corr_W = self.v[i]['W'] / (1 - self.beta1 ** self.t)\n",
        "            v_corr_b = self.v[i]['b'] / (1 - self.beta1 ** self.t)\n",
        "            s_corr_W = self.s[i]['W'] / (1 - self.beta2 ** self.t)\n",
        "            s_corr_b = self.s[i]['b'] / (1 - self.beta2 ** self.t)\n",
        "            # Update parameters\n",
        "            layer.weights -= self.learning_rate * v_corr_W / (np.sqrt(s_corr_W) + self.epsilon)\n",
        "            layer.biases -= self.learning_rate * v_corr_b / (np.sqrt(s_corr_b) + self.epsilon)"
      ],
      "metadata": {
        "id": "7QM9oP-ZLcaf"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Layers"
      ],
      "metadata": {
        "id": "yRx8KWvPLpwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseLayer:\n",
        "    def __init__(self, input_size, output_size, activation):\n",
        "        \"\"\"Initialize a dense layer with weights, biases, and an activation object\"\"\"\n",
        "        # Xavier/Glorot initialization\n",
        "        self.weights = np.random.randn(output_size, input_size) * np.sqrt(1.0 / input_size)\n",
        "        self.biases = np.zeros((output_size, 1))\n",
        "        self.activation = activation # Store an instance of an Activation class\n",
        "        self.a_prev = None  # Previous layer's activation\n",
        "        self.z = None       # Pre-activation value\n",
        "\n",
        "    def forward(self, a_prev):\n",
        "        \"\"\"Forward propagation through the layer\"\"\"\n",
        "        self.a_prev = a_prev\n",
        "        self.z = self.weights @ a_prev + self.biases\n",
        "        return self.activation.forward(self.z) # Use the activation object's forward method\n",
        "\n",
        "    def backward(self, da):\n",
        "        \"\"\"Backward propagation to compute gradients\"\"\"\n",
        "        batch_size = self.a_prev.shape[1]\n",
        "        dz = da * self.activation.backward(self.z) # Use the activation object's backward method\n",
        "        dW = (dz @ self.a_prev.T) / batch_size\n",
        "        db = np.sum(dz, axis=1, keepdims=True) / batch_size\n",
        "        da_prev = self.weights.T @ dz\n",
        "        return da_prev, dW, db"
      ],
      "metadata": {
        "id": "KyKXdftVLncH"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utility Functions"
      ],
      "metadata": {
        "id": "9wxpr9GNOCJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BatchGenerator:\n",
        "    def __init__(self, X, y, batch_size):\n",
        "        \"\"\"Initialize BatchGenerator with data and batch size\"\"\"\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.batch_size = batch_size\n",
        "        self.num_samples = X.shape[1]\n",
        "        self.indices = np.arange(self.num_samples)\n",
        "        self.current_index = 0\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Shuffle indices and reset current index for a new epoch\"\"\"\n",
        "        np.random.shuffle(self.indices)\n",
        "        self.current_index = 0\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        \"\"\"Generate the next mini-batch\"\"\"\n",
        "        if self.current_index >= self.num_samples:\n",
        "            raise StopIteration\n",
        "\n",
        "        end_index = min(self.current_index + self.batch_size, self.num_samples)\n",
        "        batch_indices = self.indices[self.current_index:end_index]\n",
        "\n",
        "        self.current_index = end_index\n",
        "\n",
        "        return self.X[:, batch_indices], self.y[:, batch_indices]"
      ],
      "metadata": {
        "id": "9SUiv1TMOIHq"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Networks"
      ],
      "metadata": {
        "id": "2ecfL3jRLyDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, optimizer, loss_function, verbosity=1):\n",
        "        \"\"\"Initialize the network with an optimizer, loss function object, and verbosity level\"\"\"\n",
        "        self.layers = []\n",
        "        self.optimizer = optimizer\n",
        "        self.loss_function = loss_function # Store an instance of a Loss class\n",
        "        self.verbosity = verbosity # Add verbosity parameter\n",
        "\n",
        "    def add_layer(self, layer):\n",
        "        \"\"\"Add a layer to the network\"\"\"\n",
        "        self.layers.append(layer)\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"Forward propagation through all layers\"\"\"\n",
        "        a = X\n",
        "        for layer in self.layers:\n",
        "            a = layer.forward(a)\n",
        "        return a\n",
        "\n",
        "    def compute_loss(self, y_pred, y_true):\n",
        "        \"\"\"Compute the loss using the loss function object\"\"\"\n",
        "        return self.loss_function.compute_loss(y_pred, y_true)\n",
        "\n",
        "    def train(self, X, y, epochs, batch_size):\n",
        "        \"\"\"Train the network using mini-batch processing\"\"\"\n",
        "        n_batches = X.shape[1] // batch_size\n",
        "        batch_generator = BatchGenerator(X, y, batch_size) # Create a BatchGenerator instance\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            # Process data in mini-batches\n",
        "            batch_loss = 0\n",
        "            for i, (X_batch, y_batch) in enumerate(batch_generator): # Iterate through the BatchGenerator\n",
        "                y_pred = self.forward(X_batch)\n",
        "                loss = self.compute_loss(y_pred, y_batch)\n",
        "                batch_loss += loss\n",
        "\n",
        "                # Print batch loss if verbosity is high enough\n",
        "                if self.verbosity >= 2:\n",
        "                    print(f\"\\nEpoch {epoch+1}, Batch {i+1}/{n_batches}\")\n",
        "                    print(f\"  Loss: {loss:.6f}\")\n",
        "                    # Print y_pred for the first sample in the batch\n",
        "                    if self.verbosity >= 2 and X_batch.shape[1] > 0:\n",
        "                         print(f\"  y_pred (first sample): {y_pred[:, 0]}\")\n",
        "                         print(f\"  y_true (first sample): {y_batch[:, 0]}\")\n",
        "\n",
        "\n",
        "                # Initial gradient for output layer\n",
        "                da = self.loss_function.backward(y_pred, y_batch) # Use loss object's backward method\n",
        "\n",
        "                grads = []\n",
        "                # Backpropagation through layers\n",
        "                for layer in reversed(self.layers):\n",
        "                    da, dW, db = layer.backward(da)\n",
        "                    grads.append((dW, db))\n",
        "                # Reverse the grads list to match the layer order\n",
        "                grads.reverse()\n",
        "\n",
        "                # Print summary of gradients if verbosity is high enough\n",
        "                if self.verbosity >= 2:\n",
        "                    print(\"  Gradients (per layer):\")\n",
        "                    for idx, (dW, db) in enumerate(grads):\n",
        "                        print(f\"    Layer {idx}: dW (mean={np.mean(dW):.6f}, std={np.std(dW):.6f}), \"\n",
        "                              f\"db (mean={np.mean(db):.6f}, std={np.std(db):.6f})\")\n",
        "\n",
        "\n",
        "                # Update parameters\n",
        "                self.optimizer.update(self.layers, grads)\n",
        "\n",
        "\n",
        "            # Monitor progress (epoch loss)\n",
        "            if self.verbosity >= 1 and (epoch % 10 == 0 or epoch == epochs - 1): # Print epoch loss every 10 epochs or on the last epoch\n",
        "                y_pred_full = self.forward(X)\n",
        "                loss_full = self.compute_loss(y_pred_full, y)\n",
        "                print(f\"\\n=== Epoch {epoch+1} Summary ===\")\n",
        "                print(f\"Average Batch Loss: {batch_loss / n_batches:.6f}\")\n",
        "                print(f\"Full Dataset Loss: {loss_full:.6f}\")\n",
        "                if self.verbosity >= 2:\n",
        "                    print(f\"Final y_pred sample: {y_pred_full[:, 0]}\")\n",
        "                    print(f\"Final y_true sample: {y[:, 0]}\")"
      ],
      "metadata": {
        "id": "sXaA1zLALwZ1"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zoo Classification Training"
      ],
      "metadata": {
        "id": "7QGI9SFiNLig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# --- Load and Preprocess Data ---\n",
        "# Load zoo.csv from Google Drive\n",
        "df = pd.read_csv('/content/drive/MyDrive/data_preprocessing_dataset/zoo.csv')\n",
        "\n",
        "# Extract features and target\n",
        "X = df.drop(['animal_name', 'class_type'], axis=1).values.T  # Shape: (16, n_samples)\n",
        "y = df['class_type'].values.reshape(-1, 1)  # Shape: (n_samples, 1)\n",
        "\n",
        "# One-hot encode the target (shift from 1-7 to 0-6)\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y_onehot = encoder.fit_transform(y).T  # Shape: (7, n_samples)\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.T, y_onehot.T, test_size=0.2, random_state=42)\n",
        "X_train = X_train.T  # Shape: (16, n_train)\n",
        "X_test = X_test.T    # Shape: (16, n_test)\n",
        "y_train = y_train.T  # Shape: (7, n_train)\n",
        "y_test = y_test.T    # Shape: (7, n_test)\n",
        "\n",
        "# --- Create and Configure Neural Network ---\n",
        "# Pass an instance of the optimizer and loss function classes\n",
        "nn = NeuralNetwork(optimizer=Adam(learning_rate=0.01), loss_function=CategoricalCrossentropy(), verbosity=2)\n",
        "\n",
        "# Add layers using instances of the activation classes\n",
        "nn.add_layer(DenseLayer(16, 32, activation=ReLU()))\n",
        "nn.add_layer(DenseLayer(32, 16, activation=ReLU()))\n",
        "nn.add_layer(DenseLayer(16, 8, activation=ReLU()))\n",
        "nn.add_layer(DenseLayer(8, 7, activation=Softmax()))\n",
        "\n",
        "# --- Train the Network ---\n",
        "print(\"Training the neural network...\")\n",
        "nn.train(X_train, y_train, epochs=200, batch_size=8)\n",
        "\n",
        "# --- Evaluate on Test Set ---\n",
        "y_pred = nn.forward(X_test)\n",
        "accuracy = np.mean(np.argmax(y_pred, axis=0) == np.argmax(y_test, axis=0))\n",
        "print(f\"\\nTest accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "RFbXwz7yNezs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a78bb4a2-ed00-4f5e-ca41-9172ca2cce88"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000006), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000014), db (mean=0.000000, std=0.000002)\n",
            "\n",
            "Epoch 155, Batch 10/10\n",
            "  Loss: 0.000018\n",
            "  y_pred (first sample): [9.99986084e-01 5.27700521e-23 1.39160328e-05 8.58260069e-16\n",
            " 4.29585146e-23 1.83269651e-10 8.97238484e-26]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000007), db (mean=-0.000002, std=0.000004)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000004), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000012), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000052), db (mean=-0.000000, std=0.000006)\n",
            "\n",
            "Epoch 156, Batch 1/10\n",
            "  Loss: 0.000032\n",
            "  y_pred (first sample): [9.99999922e-01 8.15405241e-25 7.84501022e-08 6.46544183e-17\n",
            " 1.03080995e-27 2.41122956e-12 1.88418423e-29]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000016), db (mean=-0.000001, std=0.000015)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000013), db (mean=-0.000001, std=0.000008)\n",
            "    Layer 2: dW (mean=0.000003, std=0.000055), db (mean=0.000001, std=0.000011)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000103), db (mean=0.000000, std=0.000012)\n",
            "\n",
            "Epoch 156, Batch 2/10\n",
            "  Loss: 0.000035\n",
            "  y_pred (first sample): [1.87515882e-16 9.99999731e-01 2.50186725e-12 5.94780807e-12\n",
            " 1.28391660e-18 1.14385455e-10 2.69334533e-07]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000009), db (mean=0.000000, std=0.000025)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000009), db (mean=-0.000001, std=0.000013)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000028), db (mean=-0.000001, std=0.000010)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000073), db (mean=0.000000, std=0.000013)\n",
            "\n",
            "Epoch 156, Batch 3/10\n",
            "  Loss: 0.000090\n",
            "  y_pred (first sample): [5.03990634e-06 4.10708217e-08 2.90335216e-13 9.99994919e-01\n",
            " 1.79147722e-14 2.69311595e-11 3.90491354e-15]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000003, std=0.000034), db (mean=-0.000007, std=0.000032)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000025), db (mean=-0.000002, std=0.000017)\n",
            "    Layer 2: dW (mean=-0.000011, std=0.000085), db (mean=-0.000004, std=0.000021)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000208), db (mean=0.000000, std=0.000029)\n",
            "\n",
            "Epoch 156, Batch 4/10\n",
            "  Loss: 0.000003\n",
            "  y_pred (first sample): [3.31134112e-12 9.99999992e-01 7.31054995e-10 1.59112169e-10\n",
            " 1.09211039e-19 6.22956231e-09 1.16776293e-09]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 2: dW (mean=0.000000, std=0.000006), db (mean=0.000000, std=0.000001)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000011), db (mean=-0.000000, std=0.000001)\n",
            "\n",
            "Epoch 156, Batch 5/10\n",
            "  Loss: 0.000065\n",
            "  y_pred (first sample): [9.99999243e-01 1.36523391e-26 7.56736367e-07 4.02719897e-18\n",
            " 5.14233126e-27 2.11174800e-12 7.44276256e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000004, std=0.000023), db (mean=-0.000006, std=0.000032)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000021), db (mean=-0.000000, std=0.000017)\n",
            "    Layer 2: dW (mean=-0.000016, std=0.000052), db (mean=-0.000007, std=0.000012)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000106), db (mean=0.000000, std=0.000011)\n",
            "\n",
            "Epoch 156, Batch 6/10\n",
            "  Loss: 0.000060\n",
            "  y_pred (first sample): [9.99989196e-01 2.10798389e-24 1.08036552e-05 1.02117922e-16\n",
            " 2.90571553e-24 6.20818949e-11 2.67350061e-27]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000070), db (mean=0.000003, std=0.000051)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000041), db (mean=-0.000001, std=0.000028)\n",
            "    Layer 2: dW (mean=-0.000011, std=0.000116), db (mean=-0.000004, std=0.000023)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000226), db (mean=0.000000, std=0.000026)\n",
            "\n",
            "Epoch 156, Batch 7/10\n",
            "  Loss: 0.000035\n",
            "  y_pred (first sample): [1.97597509e-14 9.99999999e-01 1.73163053e-12 3.77170427e-10\n",
            " 2.93241154e-21 8.67803098e-13 4.13275522e-10]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000045), db (mean=-0.000003, std=0.000030)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000028), db (mean=-0.000002, std=0.000017)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000088), db (mean=-0.000002, std=0.000017)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000156), db (mean=-0.000000, std=0.000016)\n",
            "\n",
            "Epoch 156, Batch 8/10\n",
            "  Loss: 0.000051\n",
            "  y_pred (first sample): [9.99999245e-01 1.34297474e-26 7.54517035e-07 3.97802730e-18\n",
            " 5.01537850e-27 2.08480296e-12 7.28350055e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000062), db (mean=-0.000003, std=0.000045)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000036), db (mean=-0.000001, std=0.000023)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000096), db (mean=-0.000002, std=0.000018)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000141), db (mean=0.000000, std=0.000013)\n",
            "\n",
            "Epoch 156, Batch 9/10\n",
            "  Loss: 0.000044\n",
            "  y_pred (first sample): [4.49958700e-30 5.45754980e-12 5.18682079e-17 3.77529784e-24\n",
            " 1.09571686e-06 5.44099887e-08 9.99998850e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000003, std=0.000011), db (mean=-0.000005, std=0.000009)\n",
            "    Layer 1: dW (mean=-0.000003, std=0.000007), db (mean=-0.000003, std=0.000005)\n",
            "    Layer 2: dW (mean=-0.000009, std=0.000024), db (mean=-0.000003, std=0.000004)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000140), db (mean=0.000000, std=0.000018)\n",
            "\n",
            "Epoch 156, Batch 10/10\n",
            "  Loss: 0.000042\n",
            "  y_pred (first sample): [9.99999974e-01 8.75248216e-26 2.58970419e-08 1.22764703e-17\n",
            " 3.49884915e-29 6.43153524e-13 8.12547806e-31]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000011), db (mean=-0.000005, std=0.000028)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000011), db (mean=-0.000002, std=0.000016)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000034), db (mean=-0.000003, std=0.000013)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000082), db (mean=0.000000, std=0.000015)\n",
            "\n",
            "Epoch 157, Batch 1/10\n",
            "  Loss: 0.000074\n",
            "  y_pred (first sample): [9.73523811e-06 1.30974675e-06 2.67017204e-12 9.99988955e-01\n",
            " 3.27277171e-13 3.74234470e-10 3.86873706e-13]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000036), db (mean=-0.000003, std=0.000033)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000023), db (mean=0.000002, std=0.000016)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000059), db (mean=-0.000002, std=0.000012)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000119), db (mean=0.000000, std=0.000012)\n",
            "\n",
            "Epoch 157, Batch 2/10\n",
            "  Loss: 0.000074\n",
            "  y_pred (first sample): [2.75781724e-14 8.02710313e-05 2.44882106e-08 2.76913822e-11\n",
            " 1.24754115e-04 8.23212883e-05 9.99712629e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000003, std=0.000045), db (mean=-0.000009, std=0.000034)\n",
            "    Layer 1: dW (mean=-0.000003, std=0.000027), db (mean=-0.000004, std=0.000013)\n",
            "    Layer 2: dW (mean=-0.000011, std=0.000072), db (mean=-0.000005, std=0.000011)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000142), db (mean=0.000000, std=0.000014)\n",
            "\n",
            "Epoch 157, Batch 3/10\n",
            "  Loss: 0.000018\n",
            "  y_pred (first sample): [1.45974665e-06 3.05698401e-07 3.16658151e-14 9.99998235e-01\n",
            " 3.11926671e-15 1.40456151e-11 6.43369940e-15]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000006), db (mean=-0.000002, std=0.000004)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000005), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000014), db (mean=-0.000001, std=0.000001)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000056), db (mean=-0.000000, std=0.000006)\n",
            "\n",
            "Epoch 157, Batch 4/10\n",
            "  Loss: 0.000000\n",
            "  y_pred (first sample): [9.99999974e-01 8.54641308e-26 2.56272176e-08 1.20388307e-17\n",
            " 3.34777098e-29 6.32305468e-13 7.81860147e-31]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000000), db (mean=-0.000000, std=0.000000)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000000), db (mean=-0.000000, std=0.000000)\n",
            "    Layer 2: dW (mean=-0.000000, std=0.000001), db (mean=-0.000000, std=0.000000)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000001), db (mean=0.000000, std=0.000000)\n",
            "\n",
            "Epoch 157, Batch 5/10\n",
            "  Loss: 0.000006\n",
            "  y_pred (first sample): [9.99999392e-01 1.38919748e-22 6.07926624e-07 1.48520197e-15\n",
            " 2.60769737e-25 4.75165216e-11 5.70330376e-27]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000002), db (mean=-0.000001, std=0.000003)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000005), db (mean=-0.000001, std=0.000001)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000011), db (mean=-0.000000, std=0.000002)\n",
            "\n",
            "Epoch 157, Batch 6/10\n",
            "  Loss: 0.000085\n",
            "  y_pred (first sample): [4.71217709e-15 2.42198315e-16 3.38264222e-05 2.96952819e-16\n",
            " 9.99886190e-01 3.89603336e-05 4.10235137e-05]\n",
            "  y_true (first sample): [0. 0. 0. 0. 1. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000003, std=0.000034), db (mean=-0.000003, std=0.000023)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000024), db (mean=-0.000002, std=0.000018)\n",
            "    Layer 2: dW (mean=-0.000013, std=0.000095), db (mean=-0.000005, std=0.000024)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000174), db (mean=-0.000000, std=0.000024)\n",
            "\n",
            "Epoch 157, Batch 7/10\n",
            "  Loss: 0.000057\n",
            "  y_pred (first sample): [4.35996038e-30 5.25112565e-12 5.15519949e-17 3.65198894e-24\n",
            " 1.10976131e-06 5.43617377e-08 9.99998836e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000003, std=0.000031), db (mean=0.000005, std=0.000039)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000021), db (mean=0.000000, std=0.000018)\n",
            "    Layer 2: dW (mean=0.000012, std=0.000071), db (mean=0.000003, std=0.000016)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000103), db (mean=-0.000000, std=0.000014)\n",
            "\n",
            "Epoch 157, Batch 8/10\n",
            "  Loss: 0.000068\n",
            "  y_pred (first sample): [8.69723222e-10 9.99976050e-01 3.49779536e-06 1.03845170e-08\n",
            " 7.30963055e-13 5.30909363e-06 1.51316560e-05]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000063), db (mean=-0.000006, std=0.000035)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000027), db (mean=-0.000002, std=0.000014)\n",
            "    Layer 2: dW (mean=-0.000013, std=0.000068), db (mean=-0.000003, std=0.000012)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000113), db (mean=-0.000000, std=0.000009)\n",
            "\n",
            "Epoch 157, Batch 9/10\n",
            "  Loss: 0.000045\n",
            "  y_pred (first sample): [9.91077033e-12 9.99999963e-01 5.15172170e-09 1.87564642e-10\n",
            " 2.82361140e-19 2.96758885e-08 1.66961963e-09]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000012), db (mean=-0.000004, std=0.000011)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000009), db (mean=-0.000001, std=0.000005)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000029), db (mean=-0.000001, std=0.000006)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000086), db (mean=0.000000, std=0.000012)\n",
            "\n",
            "Epoch 157, Batch 10/10\n",
            "  Loss: 0.000022\n",
            "  y_pred (first sample): [2.43694752e-10 2.93667295e-08 1.11311742e-05 5.33457840e-15\n",
            " 1.10258204e-14 9.99988839e-01 1.74301546e-10]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000020), db (mean=-0.000001, std=0.000017)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000011), db (mean=0.000001, std=0.000007)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000027), db (mean=-0.000000, std=0.000005)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000060), db (mean=0.000000, std=0.000006)\n",
            "\n",
            "Epoch 158, Batch 1/10\n",
            "  Loss: 0.000027\n",
            "  y_pred (first sample): [1.55896971e-12 9.99992937e-01 6.88224883e-10 6.17978375e-08\n",
            " 2.48630582e-14 3.64458682e-10 7.00056803e-06]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000028), db (mean=-0.000001, std=0.000024)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000017), db (mean=0.000001, std=0.000011)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000045), db (mean=-0.000000, std=0.000009)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000068), db (mean=-0.000000, std=0.000006)\n",
            "\n",
            "Epoch 158, Batch 2/10\n",
            "  Loss: 0.000039\n",
            "  y_pred (first sample): [2.66533930e-14 7.90808754e-05 2.40462797e-08 2.68935857e-11\n",
            " 1.23242128e-04 8.14367379e-05 9.99716216e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000010), db (mean=-0.000003, std=0.000029)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000010), db (mean=-0.000002, std=0.000015)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000032), db (mean=-0.000002, std=0.000012)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000085), db (mean=-0.000000, std=0.000016)\n",
            "\n",
            "Epoch 158, Batch 3/10\n",
            "  Loss: 0.000005\n",
            "  y_pred (first sample): [3.31201029e-12 9.99999992e-01 7.16181645e-10 1.59433322e-10\n",
            " 9.99051152e-20 6.01863102e-09 1.11888315e-09]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000005), db (mean=-0.000001, std=0.000004)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000004), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000012), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000024), db (mean=-0.000000, std=0.000002)\n",
            "\n",
            "Epoch 158, Batch 4/10\n",
            "  Loss: 0.000042\n",
            "  y_pred (first sample): [9.60189104e-06 1.28277959e-06 2.58625154e-12 9.99989115e-01\n",
            " 3.15986326e-13 3.64073977e-10 3.71562813e-13]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000030), db (mean=-0.000004, std=0.000025)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000022), db (mean=-0.000000, std=0.000015)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000084), db (mean=-0.000002, std=0.000020)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000152), db (mean=0.000000, std=0.000019)\n",
            "\n",
            "Epoch 158, Batch 5/10\n",
            "  Loss: 0.000047\n",
            "  y_pred (first sample): [9.99999925e-01 7.30660142e-25 7.48093196e-08 5.93008133e-17\n",
            " 8.42632112e-28 2.18691354e-12 1.58583958e-29]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000004, std=0.000038), db (mean=-0.000007, std=0.000024)\n",
            "    Layer 1: dW (mean=-0.000003, std=0.000027), db (mean=-0.000003, std=0.000016)\n",
            "    Layer 2: dW (mean=-0.000008, std=0.000083), db (mean=-0.000002, std=0.000016)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000147), db (mean=0.000000, std=0.000015)\n",
            "\n",
            "Epoch 158, Batch 6/10\n",
            "  Loss: 0.000035\n",
            "  y_pred (first sample): [1.97835183e-14 9.99999999e-01 1.67153507e-12 3.82862066e-10\n",
            " 2.64661739e-21 8.26220863e-13 3.92379603e-10]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000009), db (mean=0.000000, std=0.000025)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000009), db (mean=-0.000001, std=0.000013)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000028), db (mean=-0.000002, std=0.000010)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000072), db (mean=-0.000000, std=0.000013)\n",
            "\n",
            "Epoch 158, Batch 7/10\n",
            "  Loss: 0.000075\n",
            "  y_pred (first sample): [1.52870018e-15 1.28081230e-16 2.08552433e-05 1.10819337e-16\n",
            " 9.99903283e-01 3.35208117e-05 4.23406730e-05]\n",
            "  y_true (first sample): [0. 0. 0. 0. 1. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000016), db (mean=-0.000003, std=0.000016)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000015), db (mean=-0.000000, std=0.000008)\n",
            "    Layer 2: dW (mean=-0.000013, std=0.000043), db (mean=-0.000007, std=0.000008)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000112), db (mean=-0.000000, std=0.000017)\n",
            "\n",
            "Epoch 158, Batch 8/10\n",
            "  Loss: 0.000062\n",
            "  y_pred (first sample): [3.62697287e-14 3.47824950e-17 1.49979299e-04 5.92924615e-16\n",
            " 9.99823470e-01 2.15011211e-05 5.04975348e-06]\n",
            "  y_true (first sample): [0. 0. 0. 0. 1. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000033), db (mean=-0.000001, std=0.000030)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000020), db (mean=-0.000001, std=0.000013)\n",
            "    Layer 2: dW (mean=0.000003, std=0.000056), db (mean=0.000000, std=0.000011)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000089), db (mean=0.000000, std=0.000010)\n",
            "\n",
            "Epoch 158, Batch 9/10\n",
            "  Loss: 0.000006\n",
            "  y_pred (first sample): [9.54886256e-08 9.99976594e-01 2.24446518e-05 3.77331044e-07\n",
            " 2.34478869e-14 3.03068145e-07 1.85131430e-07]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000006), db (mean=-0.000000, std=0.000008)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000004), db (mean=0.000000, std=0.000003)\n",
            "    Layer 2: dW (mean=-0.000000, std=0.000010), db (mean=-0.000000, std=0.000003)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000014), db (mean=0.000000, std=0.000002)\n",
            "\n",
            "Epoch 158, Batch 10/10\n",
            "  Loss: 0.000106\n",
            "  y_pred (first sample): [2.34713814e-13 8.44622379e-15 1.38130931e-04 1.63127954e-14\n",
            " 9.99672790e-01 1.02452035e-04 8.66269308e-05]\n",
            "  y_true (first sample): [0. 0. 0. 0. 1. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000068), db (mean=-0.000006, std=0.000039)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000027), db (mean=-0.000002, std=0.000012)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000079), db (mean=-0.000001, std=0.000013)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000126), db (mean=0.000000, std=0.000014)\n",
            "\n",
            "Epoch 159, Batch 1/10\n",
            "  Loss: 0.000047\n",
            "  y_pred (first sample): [1.95026395e-14 1.34601788e-10 4.57026326e-05 1.84207159e-16\n",
            " 4.87504014e-05 9.99748760e-01 1.56786993e-04]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000004, std=0.000040), db (mean=-0.000007, std=0.000025)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000027), db (mean=-0.000002, std=0.000016)\n",
            "    Layer 2: dW (mean=-0.000007, std=0.000082), db (mean=-0.000002, std=0.000015)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000145), db (mean=0.000000, std=0.000015)\n",
            "\n",
            "Epoch 159, Batch 2/10\n",
            "  Loss: 0.000023\n",
            "  y_pred (first sample): [9.51294839e-06 1.26926754e-06 2.53466804e-12 9.99989217e-01\n",
            " 3.09139797e-13 3.57919104e-10 3.63075965e-13]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000006), db (mean=-0.000003, std=0.000004)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000004), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000005, std=0.000012), db (mean=-0.000002, std=0.000002)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000058), db (mean=0.000000, std=0.000007)\n",
            "\n",
            "Epoch 159, Batch 3/10\n",
            "  Loss: 0.000030\n",
            "  y_pred (first sample): [3.31287490e-12 9.99999992e-01 7.10470267e-10 1.59776970e-10\n",
            " 9.57813379e-20 5.89989097e-09 1.09752679e-09]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000071), db (mean=0.000002, std=0.000035)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000037), db (mean=-0.000000, std=0.000017)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000092), db (mean=-0.000001, std=0.000014)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000160), db (mean=-0.000000, std=0.000013)\n",
            "\n",
            "Epoch 159, Batch 4/10\n",
            "  Loss: 0.000052\n",
            "  y_pred (first sample): [9.99999409e-01 1.29502742e-22 5.91177711e-07 1.40865721e-15\n",
            " 2.29804143e-25 4.45524415e-11 5.11279473e-27]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000003, std=0.000032), db (mean=0.000005, std=0.000038)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000022), db (mean=0.000000, std=0.000019)\n",
            "    Layer 2: dW (mean=0.000012, std=0.000072), db (mean=0.000003, std=0.000016)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000109), db (mean=-0.000000, std=0.000014)\n",
            "\n",
            "Epoch 159, Batch 5/10\n",
            "  Loss: 0.000045\n",
            "  y_pred (first sample): [1.95124607e-14 9.99999999e-01 1.63818140e-12 3.84462280e-10\n",
            " 2.55952756e-21 8.05359415e-13 3.89242205e-10]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000027), db (mean=-0.000003, std=0.000020)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000021), db (mean=-0.000000, std=0.000014)\n",
            "    Layer 2: dW (mean=-0.000007, std=0.000079), db (mean=-0.000003, std=0.000019)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000148), db (mean=-0.000000, std=0.000018)\n",
            "\n",
            "Epoch 159, Batch 6/10\n",
            "  Loss: 0.000019\n",
            "  y_pred (first sample): [9.99996102e-01 7.54292131e-25 3.89816905e-06 3.99169368e-17\n",
            " 5.26694693e-25 1.94583567e-11 1.06183117e-27]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000023), db (mean=-0.000002, std=0.000019)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000013), db (mean=0.000001, std=0.000009)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000030), db (mean=-0.000001, std=0.000006)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000069), db (mean=0.000000, std=0.000007)\n",
            "\n",
            "Epoch 159, Batch 7/10\n",
            "  Loss: 0.000044\n",
            "  y_pred (first sample): [2.05236514e-13 7.89856165e-15 1.27407539e-04 1.48688578e-14\n",
            " 9.99687588e-01 9.78968789e-05 8.71077775e-05]\n",
            "  y_true (first sample): [0. 0. 0. 0. 1. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000030), db (mean=-0.000001, std=0.000026)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000017), db (mean=0.000000, std=0.000012)\n",
            "    Layer 2: dW (mean=0.000005, std=0.000065), db (mean=0.000002, std=0.000015)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000137), db (mean=0.000000, std=0.000018)\n",
            "\n",
            "Epoch 159, Batch 8/10\n",
            "  Loss: 0.000044\n",
            "  y_pred (first sample): [9.99944908e-01 8.65642477e-17 5.50911601e-05 7.22621503e-12\n",
            " 7.44440967e-23 5.65048933e-10 2.54993847e-23]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000015), db (mean=-0.000003, std=0.000016)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000011), db (mean=-0.000001, std=0.000008)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000031), db (mean=-0.000002, std=0.000007)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000083), db (mean=-0.000000, std=0.000011)\n",
            "\n",
            "Epoch 159, Batch 9/10\n",
            "  Loss: 0.000067\n",
            "  y_pred (first sample): [4.56510546e-26 1.75427557e-09 3.38686332e-15 1.28986932e-20\n",
            " 8.27194874e-07 1.44370829e-07 9.99999027e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000046), db (mean=-0.000001, std=0.000033)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000025), db (mean=-0.000003, std=0.000012)\n",
            "    Layer 2: dW (mean=-0.000009, std=0.000072), db (mean=-0.000004, std=0.000012)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000132), db (mean=-0.000000, std=0.000012)\n",
            "\n",
            "Epoch 159, Batch 10/10\n",
            "  Loss: 0.000068\n",
            "  y_pred (first sample): [2.26252073e-10 2.87751432e-08 1.07686591e-05 5.19268325e-15\n",
            " 1.08671612e-14 9.99989202e-01 1.75699191e-10]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000015), db (mean=-0.000006, std=0.000019)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000013), db (mean=-0.000001, std=0.000007)\n",
            "    Layer 2: dW (mean=-0.000010, std=0.000043), db (mean=-0.000006, std=0.000008)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000141), db (mean=0.000000, std=0.000023)\n",
            "\n",
            "Epoch 160, Batch 1/10\n",
            "  Loss: 0.000006\n",
            "  y_pred (first sample): [9.99986654e-01 4.41995613e-23 1.33455198e-05 7.54579355e-16\n",
            " 3.32369948e-23 1.60125084e-10 7.04104094e-26]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000003), db (mean=-0.000001, std=0.000004)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000003), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000010), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000022), db (mean=0.000000, std=0.000002)\n",
            "\n",
            "Epoch 160, Batch 2/10\n",
            "  Loss: 0.000059\n",
            "  y_pred (first sample): [9.99999274e-01 1.13621147e-26 7.26219365e-07 3.52436563e-18\n",
            " 3.95962392e-27 1.83510226e-12 5.82020662e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000026), db (mean=-0.000002, std=0.000021)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000017), db (mean=-0.000001, std=0.000011)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000060), db (mean=-0.000001, std=0.000013)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000144), db (mean=-0.000000, std=0.000017)\n",
            "\n",
            "Epoch 160, Batch 3/10\n",
            "  Loss: 0.000010\n",
            "  y_pred (first sample): [6.66408100e-17 7.74010967e-10 1.58895558e-06 2.10044989e-18\n",
            " 2.69181923e-08 9.99977862e-01 2.05208880e-05]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000006), db (mean=-0.000002, std=0.000006)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000005), db (mean=-0.000001, std=0.000003)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000015), db (mean=-0.000001, std=0.000003)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000028), db (mean=0.000000, std=0.000003)\n",
            "\n",
            "Epoch 160, Batch 4/10\n",
            "  Loss: 0.000033\n",
            "  y_pred (first sample): [9.33379181e-06 1.24635449e-06 2.43250193e-12 9.99989420e-01\n",
            " 2.95955893e-13 3.46312845e-10 3.47664566e-13]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000008), db (mean=0.000000, std=0.000022)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000008), db (mean=-0.000001, std=0.000011)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000027), db (mean=-0.000002, std=0.000009)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000069), db (mean=0.000000, std=0.000012)\n",
            "\n",
            "Epoch 160, Batch 5/10\n",
            "  Loss: 0.000052\n",
            "  y_pred (first sample): [9.99999272e-01 1.11740963e-26 7.27977746e-07 3.48574676e-18\n",
            " 3.91321420e-27 1.81327088e-12 5.73628702e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000000, std=0.000056), db (mean=-0.000000, std=0.000027)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000030), db (mean=-0.000000, std=0.000013)\n",
            "    Layer 2: dW (mean=-0.000010, std=0.000083), db (mean=-0.000003, std=0.000012)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000148), db (mean=-0.000000, std=0.000012)\n",
            "\n",
            "Epoch 160, Batch 6/10\n",
            "  Loss: 0.000036\n",
            "  y_pred (first sample): [9.99999413e-01 1.25768958e-22 5.86969350e-07 1.38304289e-15\n",
            " 2.19959170e-25 4.30156329e-11 4.91857255e-27]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000046), db (mean=-0.000002, std=0.000030)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000028), db (mean=-0.000002, std=0.000016)\n",
            "    Layer 2: dW (mean=-0.000005, std=0.000089), db (mean=-0.000002, std=0.000017)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000157), db (mean=0.000000, std=0.000016)\n",
            "\n",
            "Epoch 160, Batch 7/10\n",
            "  Loss: 0.000077\n",
            "  y_pred (first sample): [9.99998889e-01 3.23647396e-25 1.11095892e-06 3.31740141e-17\n",
            " 7.37151009e-26 6.34152522e-12 2.17850952e-28]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000003, std=0.000024), db (mean=-0.000006, std=0.000036)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000024), db (mean=-0.000000, std=0.000020)\n",
            "    Layer 2: dW (mean=-0.000013, std=0.000069), db (mean=-0.000006, std=0.000018)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000215), db (mean=-0.000000, std=0.000027)\n",
            "\n",
            "Epoch 160, Batch 8/10\n",
            "  Loss: 0.000029\n",
            "  y_pred (first sample): [9.99999278e-01 1.10476194e-26 7.21978364e-07 3.45356477e-18\n",
            " 3.81107949e-27 1.79040480e-12 5.61935156e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000008), db (mean=0.000001, std=0.000021)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000008), db (mean=-0.000001, std=0.000011)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000025), db (mean=-0.000002, std=0.000009)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000068), db (mean=0.000000, std=0.000012)\n",
            "\n",
            "Epoch 160, Batch 9/10\n",
            "  Loss: 0.000075\n",
            "  y_pred (first sample): [9.10215650e-12 9.99999965e-01 4.91958285e-09 1.76672993e-10\n",
            " 2.55037821e-19 2.80715970e-08 1.66824883e-09]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000046), db (mean=-0.000006, std=0.000037)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000025), db (mean=-0.000004, std=0.000014)\n",
            "    Layer 2: dW (mean=-0.000007, std=0.000076), db (mean=-0.000003, std=0.000013)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000143), db (mean=0.000000, std=0.000014)\n",
            "\n",
            "Epoch 160, Batch 10/10\n",
            "  Loss: 0.000056\n",
            "  y_pred (first sample): [1.87684245e-13 7.44989757e-15 1.22917636e-04 1.37646987e-14\n",
            " 9.99694086e-01 9.61934018e-05 8.68029941e-05]\n",
            "  y_true (first sample): [0. 0. 0. 0. 1. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000003, std=0.000029), db (mean=-0.000005, std=0.000024)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000017), db (mean=-0.000002, std=0.000012)\n",
            "    Layer 2: dW (mean=-0.000008, std=0.000039), db (mean=-0.000003, std=0.000008)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000129), db (mean=0.000000, std=0.000016)\n",
            "\n",
            "Epoch 161, Batch 1/10\n",
            "  Loss: 0.000033\n",
            "  y_pred (first sample): [9.99989719e-01 1.69908689e-24 1.02805335e-05 8.71292851e-17\n",
            " 2.12747330e-24 5.29850470e-11 1.99389557e-27]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000016), db (mean=-0.000002, std=0.000024)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000015), db (mean=0.000001, std=0.000012)\n",
            "    Layer 2: dW (mean=-0.000009, std=0.000041), db (mean=-0.000004, std=0.000010)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000110), db (mean=0.000000, std=0.000014)\n",
            "\n",
            "Epoch 161, Batch 2/10\n",
            "  Loss: 0.000037\n",
            "  y_pred (first sample): [6.41916584e-17 7.57297800e-10 1.55627278e-06 2.03208649e-18\n",
            " 2.59728345e-08 9.99978331e-01 2.00862202e-05]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000048), db (mean=-0.000002, std=0.000031)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000030), db (mean=-0.000002, std=0.000017)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000093), db (mean=-0.000002, std=0.000017)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000165), db (mean=0.000000, std=0.000016)\n",
            "\n",
            "Epoch 161, Batch 3/10\n",
            "  Loss: 0.000004\n",
            "  y_pred (first sample): [2.61389725e-14 1.00000000e+00 1.90772803e-12 9.35486731e-12\n",
            " 1.57063711e-23 1.60665100e-11 1.25873901e-11]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000002), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000008), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000017), db (mean=-0.000000, std=0.000001)\n",
            "\n",
            "Epoch 161, Batch 4/10\n",
            "  Loss: 0.000019\n",
            "  y_pred (first sample): [4.81020095e-06 3.75518325e-08 2.59499423e-13 9.99995152e-01\n",
            " 1.57114787e-14 2.42220103e-11 3.32596299e-15]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000021), db (mean=-0.000001, std=0.000018)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000012), db (mean=0.000001, std=0.000008)\n",
            "    Layer 2: dW (mean=-0.000000, std=0.000027), db (mean=-0.000000, std=0.000005)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000067), db (mean=0.000000, std=0.000007)\n",
            "\n",
            "Epoch 161, Batch 5/10\n",
            "  Loss: 0.000045\n",
            "  y_pred (first sample): [1.47779657e-05 3.65755820e-09 1.17602607e-12 9.99985218e-01\n",
            " 3.52672261e-14 2.66160191e-11 9.20600775e-16]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000026), db (mean=-0.000004, std=0.000019)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000021), db (mean=-0.000000, std=0.000014)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000078), db (mean=-0.000002, std=0.000018)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000145), db (mean=-0.000000, std=0.000018)\n",
            "\n",
            "Epoch 161, Batch 6/10\n",
            "  Loss: 0.000072\n",
            "  y_pred (first sample): [9.99999998e-01 2.81473907e-20 1.74267198e-09 3.75072635e-11\n",
            " 7.61334609e-25 2.75870376e-12 3.89762296e-26]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000047), db (mean=-0.000005, std=0.000032)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000029), db (mean=-0.000003, std=0.000018)\n",
            "    Layer 2: dW (mean=-0.000007, std=0.000093), db (mean=-0.000003, std=0.000019)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000162), db (mean=-0.000000, std=0.000018)\n",
            "\n",
            "Epoch 161, Batch 7/10\n",
            "  Loss: 0.000026\n",
            "  y_pred (first sample): [8.46072886e-10 9.99977434e-01 3.34280990e-06 1.02583056e-08\n",
            " 6.33071770e-13 4.92361782e-06 1.42883553e-05]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000023), db (mean=0.000001, std=0.000019)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000014), db (mean=-0.000001, std=0.000009)\n",
            "    Layer 2: dW (mean=0.000005, std=0.000051), db (mean=0.000001, std=0.000009)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000099), db (mean=0.000000, std=0.000011)\n",
            "\n",
            "Epoch 161, Batch 8/10\n",
            "  Loss: 0.000089\n",
            "  y_pred (first sample): [1.13199912e-17 9.99998807e-01 7.14901647e-13 1.06055500e-12\n",
            " 2.04886538e-18 2.10479254e-10 1.19244683e-06]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000017), db (mean=-0.000005, std=0.000041)\n",
            "    Layer 1: dW (mean=-0.000003, std=0.000015), db (mean=-0.000004, std=0.000021)\n",
            "    Layer 2: dW (mean=-0.000012, std=0.000054), db (mean=-0.000006, std=0.000019)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000145), db (mean=0.000000, std=0.000023)\n",
            "\n",
            "Epoch 161, Batch 9/10\n",
            "  Loss: 0.000035\n",
            "  y_pred (first sample): [9.99994410e-01 5.29835419e-15 3.26687863e-08 5.55665316e-06\n",
            " 2.04890726e-17 2.99938337e-10 3.65388655e-19]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000071), db (mean=0.000001, std=0.000038)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000037), db (mean=-0.000001, std=0.000019)\n",
            "    Layer 2: dW (mean=-0.000008, std=0.000094), db (mean=-0.000002, std=0.000015)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000162), db (mean=0.000000, std=0.000013)\n",
            "\n",
            "Epoch 161, Batch 10/10\n",
            "  Loss: 0.000069\n",
            "  y_pred (first sample): [3.28427671e-12 9.99999993e-01 6.86374379e-10 1.59629407e-10\n",
            " 8.49407992e-20 5.60573099e-09 1.03782388e-09]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000034), db (mean=0.000001, std=0.000037)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000022), db (mean=-0.000000, std=0.000020)\n",
            "    Layer 2: dW (mean=0.000004, std=0.000082), db (mean=0.000001, std=0.000021)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000131), db (mean=0.000000, std=0.000016)\n",
            "\n",
            "=== Epoch 161 Summary ===\n",
            "Average Batch Loss: 0.000043\n",
            "Full Dataset Loss: 0.000042\n",
            "Final y_pred sample: [2.02414417e-13 7.30076059e-15 1.32586093e-04 1.40226418e-14\n",
            " 9.99685193e-01 9.88889907e-05 8.33322350e-05]\n",
            "Final y_true sample: [0. 0. 0. 0. 1. 0. 0.]\n",
            "\n",
            "Epoch 162, Batch 1/10\n",
            "  Loss: 0.000077\n",
            "  y_pred (first sample): [4.91105276e-25 1.29190110e-11 9.36025888e-11 8.14366931e-23\n",
            " 7.48722759e-05 1.46676338e-04 9.99778451e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000040), db (mean=-0.000003, std=0.000017)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000020), db (mean=-0.000001, std=0.000009)\n",
            "    Layer 2: dW (mean=-0.000012, std=0.000055), db (mean=-0.000003, std=0.000008)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000113), db (mean=0.000000, std=0.000009)\n",
            "\n",
            "Epoch 162, Batch 2/10\n",
            "  Loss: 0.000050\n",
            "  y_pred (first sample): [9.99999308e-01 1.02904558e-26 6.92476898e-07 3.23110316e-18\n",
            " 3.18392981e-27 1.68102346e-12 4.89791116e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000002, std=0.000032), db (mean=0.000004, std=0.000040)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000022), db (mean=-0.000000, std=0.000020)\n",
            "    Layer 2: dW (mean=0.000003, std=0.000069), db (mean=0.000000, std=0.000017)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000107), db (mean=-0.000000, std=0.000014)\n",
            "\n",
            "Epoch 162, Batch 3/10\n",
            "  Loss: 0.000041\n",
            "  y_pred (first sample): [9.99999307e-01 1.02554507e-26 6.93198217e-07 3.22563789e-18\n",
            " 3.17852846e-27 1.67802527e-12 4.88283611e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000012), db (mean=-0.000002, std=0.000025)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000011), db (mean=-0.000002, std=0.000013)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000036), db (mean=-0.000002, std=0.000010)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000093), db (mean=0.000000, std=0.000015)\n",
            "\n",
            "Epoch 162, Batch 4/10\n",
            "  Loss: 0.000031\n",
            "  y_pred (first sample): [1.91848442e-14 9.99999999e-01 1.55152030e-12 3.90387417e-10\n",
            " 2.24275319e-21 7.45126706e-13 3.68848858e-10]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000008), db (mean=0.000000, std=0.000021)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000008), db (mean=-0.000001, std=0.000010)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000025), db (mean=-0.000002, std=0.000009)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000066), db (mean=-0.000000, std=0.000012)\n",
            "\n",
            "Epoch 162, Batch 5/10\n",
            "  Loss: 0.000036\n",
            "  y_pred (first sample): [2.23835240e-10 2.75770962e-08 1.03545917e-05 4.89257218e-15\n",
            " 9.14652626e-15 9.99989617e-01 1.58741735e-10]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000009), db (mean=-0.000003, std=0.000014)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000008), db (mean=-0.000001, std=0.000007)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000029), db (mean=-0.000001, std=0.000008)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000102), db (mean=0.000000, std=0.000014)\n",
            "\n",
            "Epoch 162, Batch 6/10\n",
            "  Loss: 0.000078\n",
            "  y_pred (first sample): [8.86296602e-12 9.99999966e-01 4.77252981e-09 1.72846522e-10\n",
            " 2.33680449e-19 2.76043487e-08 1.61993833e-09]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000048), db (mean=-0.000004, std=0.000042)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000032), db (mean=0.000000, std=0.000023)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000113), db (mean=-0.000000, std=0.000027)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000184), db (mean=-0.000000, std=0.000023)\n",
            "\n",
            "Epoch 162, Batch 7/10\n",
            "  Loss: 0.000029\n",
            "  y_pred (first sample): [9.99987224e-01 3.99199646e-23 1.27758860e-05 6.93462470e-16\n",
            " 2.70278924e-23 1.46570989e-10 5.94869783e-26]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000003, std=0.000012), db (mean=-0.000004, std=0.000008)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000007), db (mean=-0.000002, std=0.000004)\n",
            "    Layer 2: dW (mean=-0.000007, std=0.000021), db (mean=-0.000002, std=0.000003)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000098), db (mean=-0.000000, std=0.000011)\n",
            "\n",
            "Epoch 162, Batch 8/10\n",
            "  Loss: 0.000034\n",
            "  y_pred (first sample): [8.89819020e-08 9.99978256e-01 2.08423311e-05 3.61954716e-07\n",
            " 1.98829305e-14 2.74670073e-07 1.76238835e-07]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000014), db (mean=-0.000002, std=0.000019)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000013), db (mean=0.000001, std=0.000009)\n",
            "    Layer 2: dW (mean=-0.000007, std=0.000038), db (mean=-0.000003, std=0.000009)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000111), db (mean=-0.000000, std=0.000013)\n",
            "\n",
            "Epoch 162, Batch 9/10\n",
            "  Loss: 0.000039\n",
            "  y_pred (first sample): [3.14646759e-12 9.99999993e-01 6.60075639e-10 1.55515510e-10\n",
            " 8.01488921e-20 5.35688926e-09 1.03185535e-09]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000044), db (mean=-0.000002, std=0.000028)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000026), db (mean=-0.000002, std=0.000015)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000082), db (mean=-0.000002, std=0.000016)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000145), db (mean=-0.000000, std=0.000015)\n",
            "\n",
            "Epoch 162, Batch 10/10\n",
            "  Loss: 0.000007\n",
            "  y_pred (first sample): [9.99999436e-01 1.14783752e-22 5.63896280e-07 1.28155762e-15\n",
            " 1.81722663e-25 3.96996799e-11 4.21716653e-27]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000005), db (mean=-0.000001, std=0.000004)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000004), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000011), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000021), db (mean=-0.000000, std=0.000002)\n",
            "\n",
            "Epoch 163, Batch 1/10\n",
            "  Loss: 0.000020\n",
            "  y_pred (first sample): [2.60280106e-30 4.20431714e-12 3.85173264e-17 2.42167250e-24\n",
            " 9.60987028e-07 4.58852380e-08 9.99998993e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000021), db (mean=-0.000001, std=0.000018)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000012), db (mean=0.000001, std=0.000008)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000029), db (mean=-0.000000, std=0.000006)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000076), db (mean=0.000000, std=0.000008)\n",
            "\n",
            "Epoch 163, Batch 2/10\n",
            "  Loss: 0.000026\n",
            "  y_pred (first sample): [9.99998928e-01 2.90872428e-25 1.07238987e-06 3.04106451e-17\n",
            " 6.02230399e-26 5.80233756e-12 1.84236414e-28]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000020), db (mean=0.000001, std=0.000018)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000015), db (mean=-0.000001, std=0.000009)\n",
            "    Layer 2: dW (mean=0.000014, std=0.000061), db (mean=0.000004, std=0.000011)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000090), db (mean=0.000000, std=0.000010)\n",
            "\n",
            "Epoch 163, Batch 3/10\n",
            "  Loss: 0.000003\n",
            "  y_pred (first sample): [2.07218783e-10 2.73870230e-08 1.02134413e-05 4.77619948e-15\n",
            " 9.54141987e-15 9.99989759e-01 1.66010827e-10]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 2: dW (mean=0.000000, std=0.000006), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000011), db (mean=0.000000, std=0.000001)\n",
            "\n",
            "Epoch 163, Batch 4/10\n",
            "  Loss: 0.000018\n",
            "  y_pred (first sample): [1.06947516e-15 9.81403150e-17 1.81922756e-05 8.03230795e-17\n",
            " 9.99909896e-01 3.10175940e-05 4.08939839e-05]\n",
            "  y_true (first sample): [0. 0. 0. 0. 1. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000009), db (mean=-0.000002, std=0.000007)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000007), db (mean=-0.000001, std=0.000004)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000018), db (mean=-0.000001, std=0.000003)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000054), db (mean=0.000000, std=0.000006)\n",
            "\n",
            "Epoch 163, Batch 5/10\n",
            "  Loss: 0.000016\n",
            "  y_pred (first sample): [3.28642317e-15 1.77716315e-16 2.97763028e-05 2.11595441e-16\n",
            " 9.99896163e-01 3.54815110e-05 3.85796473e-05]\n",
            "  y_true (first sample): [0. 0. 0. 0. 1. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000006), db (mean=-0.000002, std=0.000004)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000004), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000011), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000053), db (mean=-0.000000, std=0.000006)\n",
            "\n",
            "Epoch 163, Batch 6/10\n",
            "  Loss: 0.000104\n",
            "  y_pred (first sample): [1.51772235e-04 5.36624923e-17 9.99743945e-01 7.23195319e-12\n",
            " 1.01194234e-04 3.08850298e-06 6.98552317e-11]\n",
            "  y_true (first sample): [0. 0. 1. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000004, std=0.000031), db (mean=-0.000011, std=0.000030)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000023), db (mean=-0.000003, std=0.000017)\n",
            "    Layer 2: dW (mean=-0.000012, std=0.000096), db (mean=-0.000006, std=0.000025)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000243), db (mean=0.000000, std=0.000035)\n",
            "\n",
            "Epoch 163, Batch 7/10\n",
            "  Loss: 0.000068\n",
            "  y_pred (first sample): [8.85141040e-08 9.99978345e-01 2.07593096e-05 3.61388037e-07\n",
            " 1.94881660e-14 2.70785484e-07 1.74993061e-07]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000086), db (mean=-0.000003, std=0.000055)\n",
            "    Layer 1: dW (mean=-0.000003, std=0.000051), db (mean=-0.000003, std=0.000029)\n",
            "    Layer 2: dW (mean=-0.000011, std=0.000162), db (mean=-0.000003, std=0.000031)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000286), db (mean=-0.000000, std=0.000029)\n",
            "\n",
            "Epoch 163, Batch 8/10\n",
            "  Loss: 0.000088\n",
            "  y_pred (first sample): [9.99999298e-01 9.52102154e-27 7.01789758e-07 3.07906840e-18\n",
            " 3.02569029e-27 1.60551188e-12 4.56126296e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000002, std=0.000060), db (mean=0.000004, std=0.000063)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000040), db (mean=-0.000001, std=0.000034)\n",
            "    Layer 2: dW (mean=-0.000011, std=0.000127), db (mean=-0.000005, std=0.000028)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000269), db (mean=-0.000000, std=0.000035)\n",
            "\n",
            "Epoch 163, Batch 9/10\n",
            "  Loss: 0.000070\n",
            "  y_pred (first sample): [1.64571368e-13 6.36984327e-15 1.18590491e-04 1.19597151e-14\n",
            " 9.99707390e-01 9.16308991e-05 8.23889416e-05]\n",
            "  y_true (first sample): [0. 0. 0. 0. 1. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000003, std=0.000019), db (mean=-0.000006, std=0.000027)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000018), db (mean=-0.000001, std=0.000015)\n",
            "    Layer 2: dW (mean=-0.000017, std=0.000047), db (mean=-0.000007, std=0.000010)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000098), db (mean=0.000000, std=0.000009)\n",
            "\n",
            "Epoch 163, Batch 10/10\n",
            "  Loss: 0.000001\n",
            "  y_pred (first sample): [9.99999988e-01 4.56940243e-17 4.48824237e-09 7.84808387e-09\n",
            " 6.55344256e-22 4.14142228e-11 1.15515646e-22]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000001), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000001), db (mean=0.000000, std=0.000001)\n",
            "    Layer 2: dW (mean=-0.000000, std=0.000003), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000006), db (mean=-0.000000, std=0.000001)\n",
            "\n",
            "Epoch 164, Batch 1/10\n",
            "  Loss: 0.000004\n",
            "  y_pred (first sample): [2.54400302e-14 1.00000000e+00 1.81208925e-12 9.27556104e-12\n",
            " 1.36434756e-23 1.49786727e-11 1.19229196e-11]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000004), db (mean=-0.000001, std=0.000004)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000003), db (mean=0.000000, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000008), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000012), db (mean=-0.000000, std=0.000001)\n",
            "\n",
            "Epoch 164, Batch 2/10\n",
            "  Loss: 0.000109\n",
            "  y_pred (first sample): [9.99999930e-01 5.90913764e-25 6.98520263e-08 5.04605942e-17\n",
            " 5.71844009e-28 1.80141254e-12 1.14050592e-29]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000006, std=0.000043), db (mean=-0.000011, std=0.000019)\n",
            "    Layer 1: dW (mean=-0.000003, std=0.000026), db (mean=-0.000003, std=0.000011)\n",
            "    Layer 2: dW (mean=-0.000016, std=0.000065), db (mean=-0.000006, std=0.000012)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000115), db (mean=-0.000000, std=0.000011)\n",
            "\n",
            "Epoch 164, Batch 3/10\n",
            "  Loss: 0.000084\n",
            "  y_pred (first sample): [2.02781257e-09 9.99999967e-01 1.48787753e-08 1.59345328e-08\n",
            " 4.19067501e-21 5.46082819e-10 9.97606737e-12]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000055), db (mean=-0.000004, std=0.000041)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000026), db (mean=-0.000003, std=0.000017)\n",
            "    Layer 2: dW (mean=-0.000014, std=0.000071), db (mean=-0.000005, std=0.000013)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000153), db (mean=0.000000, std=0.000016)\n",
            "\n",
            "Epoch 164, Batch 4/10\n",
            "  Loss: 0.000056\n",
            "  y_pred (first sample): [9.99982615e-01 7.02785829e-24 1.73848582e-05 1.24642071e-14\n",
            " 1.91687010e-21 4.51330571e-11 1.34115229e-25]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000000, std=0.000020), db (mean=-0.000001, std=0.000021)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000016), db (mean=-0.000002, std=0.000011)\n",
            "    Layer 2: dW (mean=0.000010, std=0.000059), db (mean=0.000002, std=0.000011)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000070), db (mean=-0.000000, std=0.000008)\n",
            "\n",
            "Epoch 164, Batch 5/10\n",
            "  Loss: 0.000057\n",
            "  y_pred (first sample): [9.99999310e-01 9.21851509e-27 6.90250129e-07 2.99609751e-18\n",
            " 2.80555112e-27 1.56047734e-12 4.28264293e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000033), db (mean=-0.000002, std=0.000027)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000020), db (mean=0.000001, std=0.000014)\n",
            "    Layer 2: dW (mean=0.000005, std=0.000068), db (mean=0.000002, std=0.000015)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000125), db (mean=-0.000000, std=0.000015)\n",
            "\n",
            "Epoch 164, Batch 6/10\n",
            "  Loss: 0.000008\n",
            "  y_pred (first sample): [3.27061384e-26 1.48200230e-09 2.81719531e-15 9.84321580e-21\n",
            " 7.65722584e-07 1.30695483e-07 9.99999102e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000000, std=0.000011), db (mean=0.000000, std=0.000009)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000008), db (mean=0.000001, std=0.000004)\n",
            "    Layer 2: dW (mean=-0.000000, std=0.000025), db (mean=-0.000000, std=0.000004)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000049), db (mean=-0.000000, std=0.000004)\n",
            "\n",
            "Epoch 164, Batch 7/10\n",
            "  Loss: 0.000011\n",
            "  y_pred (first sample): [5.45475981e-17 6.85488051e-10 1.44516357e-06 1.79995701e-18\n",
            " 2.36045194e-08 9.99979664e-01 1.88662977e-05]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000007), db (mean=-0.000001, std=0.000009)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000005), db (mean=-0.000000, std=0.000004)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000018), db (mean=-0.000000, std=0.000004)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000031), db (mean=0.000000, std=0.000003)\n",
            "\n",
            "Epoch 164, Batch 8/10\n",
            "  Loss: 0.000016\n",
            "  y_pred (first sample): [1.41830789e-05 3.43365537e-09 1.08199274e-12 9.99985813e-01\n",
            " 3.21519486e-14 2.45916815e-11 8.19186672e-16]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000006), db (mean=-0.000002, std=0.000003)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000004), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000011), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000046), db (mean=0.000000, std=0.000005)\n",
            "\n",
            "Epoch 164, Batch 9/10\n",
            "  Loss: 0.000034\n",
            "  y_pred (first sample): [9.99999313e-01 9.00265821e-27 6.86603049e-07 2.94585740e-18\n",
            " 2.72251768e-27 1.53361993e-12 4.15595784e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000008), db (mean=-0.000004, std=0.000024)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000009), db (mean=-0.000001, std=0.000013)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000029), db (mean=-0.000002, std=0.000011)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000076), db (mean=-0.000000, std=0.000014)\n",
            "\n",
            "Epoch 164, Batch 10/10\n",
            "  Loss: 0.000029\n",
            "  y_pred (first sample): [6.96143303e-05 5.98676099e-19 9.99773184e-01 1.05016138e-12\n",
            " 1.56888572e-04 3.13150212e-07 8.98611101e-12]\n",
            "  y_true (first sample): [0. 0. 1. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000015), db (mean=-0.000002, std=0.000022)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000015), db (mean=0.000001, std=0.000012)\n",
            "    Layer 2: dW (mean=-0.000008, std=0.000040), db (mean=-0.000004, std=0.000010)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000108), db (mean=-0.000000, std=0.000013)\n",
            "\n",
            "Epoch 165, Batch 1/10\n",
            "  Loss: 0.000040\n",
            "  y_pred (first sample): [1.47950821e-04 5.11009684e-17 9.99749635e-01 6.90922160e-12\n",
            " 9.93678707e-05 3.04581004e-06 6.77352782e-11]\n",
            "  y_true (first sample): [0. 0. 1. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000013), db (mean=-0.000003, std=0.000014)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000010), db (mean=-0.000001, std=0.000007)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000029), db (mean=-0.000001, std=0.000007)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000080), db (mean=0.000000, std=0.000011)\n",
            "\n",
            "Epoch 165, Batch 2/10\n",
            "  Loss: 0.000064\n",
            "  y_pred (first sample): [1.55745199e-13 5.98819021e-15 1.17380949e-04 1.12377123e-14\n",
            " 9.99711074e-01 9.06800256e-05 8.08652726e-05]\n",
            "  y_true (first sample): [0. 0. 0. 0. 1. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000031), db (mean=0.000001, std=0.000034)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000020), db (mean=-0.000000, std=0.000018)\n",
            "    Layer 2: dW (mean=0.000003, std=0.000075), db (mean=0.000001, std=0.000019)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000120), db (mean=-0.000000, std=0.000015)\n",
            "\n",
            "Epoch 165, Batch 3/10\n",
            "  Loss: 0.000009\n",
            "  y_pred (first sample): [9.99990184e-01 1.38057600e-24 9.81639223e-06 7.43735829e-17\n",
            " 1.54529644e-24 4.57413464e-11 1.48298554e-27]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000006), db (mean=-0.000001, std=0.000005)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000004), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000013), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000024), db (mean=0.000000, std=0.000003)\n",
            "\n",
            "Epoch 165, Batch 4/10\n",
            "  Loss: 0.000047\n",
            "  y_pred (first sample): [8.88185042e-06 1.16106057e-06 2.17277151e-12 9.99989957e-01\n",
            " 2.61689218e-13 3.14450725e-10 3.02064131e-13]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000003, std=0.000032), db (mean=-0.000005, std=0.000028)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000022), db (mean=-0.000001, std=0.000016)\n",
            "    Layer 2: dW (mean=-0.000008, std=0.000082), db (mean=-0.000003, std=0.000020)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000148), db (mean=0.000000, std=0.000018)\n",
            "\n",
            "Epoch 165, Batch 5/10\n",
            "  Loss: 0.000033\n",
            "  y_pred (first sample): [9.99987377e-01 3.49313194e-23 1.26225322e-05 6.30610819e-16\n",
            " 2.29861041e-23 1.34174319e-10 5.04393505e-26]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000042), db (mean=-0.000002, std=0.000028)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000025), db (mean=-0.000002, std=0.000015)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000078), db (mean=-0.000002, std=0.000015)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000137), db (mean=0.000000, std=0.000014)\n",
            "\n",
            "Epoch 165, Batch 6/10\n",
            "  Loss: 0.000051\n",
            "  y_pred (first sample): [1.90606632e-05 8.18442709e-07 3.39938438e-11 9.99980118e-01\n",
            " 7.15602610e-12 2.93346190e-09 2.22006062e-12]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000020), db (mean=0.000004, std=0.000032)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000016), db (mean=-0.000002, std=0.000015)\n",
            "    Layer 2: dW (mean=0.000009, std=0.000066), db (mean=0.000002, std=0.000015)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000107), db (mean=-0.000000, std=0.000013)\n",
            "\n",
            "Epoch 165, Batch 7/10\n",
            "  Loss: 0.000014\n",
            "  y_pred (first sample): [2.92156573e-15 1.51730893e-16 2.89219317e-05 1.85161741e-16\n",
            " 9.99900959e-01 3.37674344e-05 3.63513112e-05]\n",
            "  y_true (first sample): [0. 0. 0. 0. 1. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000005), db (mean=-0.000002, std=0.000004)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000003), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000010), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000048), db (mean=-0.000000, std=0.000005)\n",
            "\n",
            "Epoch 165, Batch 8/10\n",
            "  Loss: 0.000088\n",
            "  y_pred (first sample): [2.09917636e-28 7.47141753e-11 2.51797314e-16 1.24870543e-22\n",
            " 7.50198778e-07 7.00643957e-08 9.99999180e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000000, std=0.000065), db (mean=-0.000003, std=0.000035)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000036), db (mean=-0.000000, std=0.000021)\n",
            "    Layer 2: dW (mean=-0.000016, std=0.000107), db (mean=-0.000007, std=0.000019)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000243), db (mean=-0.000000, std=0.000030)\n",
            "\n",
            "Epoch 165, Batch 9/10\n",
            "  Loss: 0.000036\n",
            "  y_pred (first sample): [9.99998951e-01 2.55329183e-25 1.04910995e-06 2.76468391e-17\n",
            " 5.05046631e-26 5.28086584e-12 1.55505656e-28]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000040), db (mean=-0.000004, std=0.000026)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000025), db (mean=-0.000002, std=0.000014)\n",
            "    Layer 2: dW (mean=-0.000005, std=0.000079), db (mean=-0.000001, std=0.000015)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000138), db (mean=0.000000, std=0.000014)\n",
            "\n",
            "Epoch 165, Batch 10/10\n",
            "  Loss: 0.000020\n",
            "  y_pred (first sample): [9.99990175e-01 1.32311402e-24 9.82531328e-06 7.22339820e-17\n",
            " 1.49305244e-24 4.47099520e-11 1.42319976e-27]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000021), db (mean=-0.000002, std=0.000016)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000012), db (mean=0.000001, std=0.000007)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000027), db (mean=-0.000000, std=0.000005)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000070), db (mean=0.000000, std=0.000007)\n",
            "\n",
            "Epoch 166, Batch 1/10\n",
            "  Loss: 0.000053\n",
            "  y_pred (first sample): [9.99987424e-01 3.39001502e-23 1.25754753e-05 6.16917155e-16\n",
            " 2.22054512e-23 1.31683506e-10 4.86915950e-26]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000022), db (mean=-0.000005, std=0.000023)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000015), db (mean=-0.000000, std=0.000012)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000042), db (mean=-0.000002, std=0.000010)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000153), db (mean=-0.000000, std=0.000019)\n",
            "\n",
            "Epoch 166, Batch 2/10\n",
            "  Loss: 0.000045\n",
            "  y_pred (first sample): [2.42216586e-14 2.38564129e-17 1.24730186e-04 4.39725578e-16\n",
            " 9.99851948e-01 1.88331479e-05 4.48841158e-06]\n",
            "  y_true (first sample): [0. 0. 0. 0. 1. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000071), db (mean=0.000001, std=0.000040)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000037), db (mean=-0.000002, std=0.000019)\n",
            "    Layer 2: dW (mean=-0.000009, std=0.000091), db (mean=-0.000002, std=0.000014)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000153), db (mean=-0.000000, std=0.000013)\n",
            "\n",
            "Epoch 166, Batch 3/10\n",
            "  Loss: 0.000096\n",
            "  y_pred (first sample): [1.50896447e-14 1.14786725e-10 4.03581360e-05 1.56279930e-16\n",
            " 4.52206002e-05 9.99766903e-01 1.47518450e-04]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000004, std=0.000048), db (mean=-0.000007, std=0.000044)\n",
            "    Layer 1: dW (mean=-0.000003, std=0.000033), db (mean=-0.000003, std=0.000025)\n",
            "    Layer 2: dW (mean=-0.000020, std=0.000097), db (mean=-0.000008, std=0.000020)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000151), db (mean=0.000000, std=0.000014)\n",
            "\n",
            "Epoch 166, Batch 4/10\n",
            "  Loss: 0.000028\n",
            "  y_pred (first sample): [9.99999932e-01 5.36282973e-25 6.79028495e-08 4.67835801e-17\n",
            " 4.84960491e-28 1.66291034e-12 9.89549698e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000007), db (mean=0.000001, std=0.000021)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000008), db (mean=-0.000001, std=0.000011)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000025), db (mean=-0.000001, std=0.000009)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000065), db (mean=0.000000, std=0.000011)\n",
            "\n",
            "Epoch 166, Batch 5/10\n",
            "  Loss: 0.000011\n",
            "  y_pred (first sample): [1.88980515e-05 8.18539365e-07 3.40192827e-11 9.99980280e-01\n",
            " 7.23410968e-12 2.96133524e-09 2.23891230e-12]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000008), db (mean=-0.000001, std=0.000012)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000006), db (mean=-0.000000, std=0.000005)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000017), db (mean=-0.000001, std=0.000005)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000026), db (mean=0.000000, std=0.000003)\n",
            "\n",
            "Epoch 166, Batch 6/10\n",
            "  Loss: 0.000025\n",
            "  y_pred (first sample): [3.97230691e-08 9.99995122e-01 4.28276192e-06 3.48939528e-07\n",
            " 7.65496654e-15 9.40293350e-08 1.13046040e-07]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000011), db (mean=-0.000003, std=0.000009)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000007), db (mean=-0.000001, std=0.000004)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000020), db (mean=-0.000002, std=0.000003)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000088), db (mean=0.000000, std=0.000010)\n",
            "\n",
            "Epoch 166, Batch 7/10\n",
            "  Loss: 0.000003\n",
            "  y_pred (first sample): [9.99990246e-01 1.27981905e-24 9.75439495e-06 7.01834277e-17\n",
            " 1.39570817e-24 4.36712386e-11 1.34676173e-27]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000006), db (mean=-0.000001, std=0.000001)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000014), db (mean=0.000000, std=0.000001)\n",
            "\n",
            "Epoch 166, Batch 8/10\n",
            "  Loss: 0.000011\n",
            "  y_pred (first sample): [9.99949397e-01 6.53080998e-17 5.06024349e-05 5.96758561e-12\n",
            " 4.56565123e-23 4.53873443e-10 1.66811570e-23]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000011), db (mean=-0.000001, std=0.000009)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000009), db (mean=0.000000, std=0.000005)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000029), db (mean=-0.000000, std=0.000005)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000049), db (mean=-0.000000, std=0.000004)\n",
            "\n",
            "Epoch 166, Batch 9/10\n",
            "  Loss: 0.000060\n",
            "  y_pred (first sample): [9.99998965e-01 2.44816090e-25 1.03539353e-06 2.66694190e-17\n",
            " 4.62690646e-26 5.10716083e-12 1.45010292e-28]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000003, std=0.000034), db (mean=-0.000009, std=0.000027)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000022), db (mean=-0.000003, std=0.000010)\n",
            "    Layer 2: dW (mean=-0.000007, std=0.000061), db (mean=-0.000003, std=0.000009)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000120), db (mean=-0.000000, std=0.000012)\n",
            "\n",
            "Epoch 166, Batch 10/10\n",
            "  Loss: 0.000066\n",
            "  y_pred (first sample): [1.90010411e-10 2.45524069e-08 9.53830257e-06 4.25627746e-15\n",
            " 8.04584257e-15 9.99990437e-01 1.46689015e-10]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000026), db (mean=-0.000002, std=0.000019)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000020), db (mean=-0.000001, std=0.000015)\n",
            "    Layer 2: dW (mean=-0.000009, std=0.000079), db (mean=-0.000004, std=0.000021)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000147), db (mean=-0.000000, std=0.000021)\n",
            "\n",
            "Epoch 167, Batch 1/10\n",
            "  Loss: 0.000086\n",
            "  y_pred (first sample): [6.79777015e-05 5.32714216e-19 9.99785992e-01 9.47070326e-13\n",
            " 1.45731667e-04 2.98488012e-07 8.18743878e-12]\n",
            "  y_true (first sample): [0. 0. 1. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000004, std=0.000036), db (mean=-0.000011, std=0.000029)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000026), db (mean=-0.000002, std=0.000013)\n",
            "    Layer 2: dW (mean=-0.000014, std=0.000078), db (mean=-0.000007, std=0.000013)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000156), db (mean=-0.000000, std=0.000019)\n",
            "\n",
            "Epoch 167, Batch 2/10\n",
            "  Loss: 0.000037\n",
            "  y_pred (first sample): [2.48991649e-14 1.00000000e+00 1.71065789e-12 9.21168827e-12\n",
            " 1.16064910e-23 1.39863794e-11 1.11243214e-11]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000026), db (mean=-0.000003, std=0.000023)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000019), db (mean=-0.000000, std=0.000014)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000073), db (mean=-0.000002, std=0.000018)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000132), db (mean=0.000000, std=0.000017)\n",
            "\n",
            "Epoch 167, Batch 3/10\n",
            "  Loss: 0.000003\n",
            "  y_pred (first sample): [2.49857325e-14 1.00000000e+00 1.71606096e-12 9.22702493e-12\n",
            " 1.15556754e-23 1.39699585e-11 1.10915573e-11]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000001), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000001), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 2: dW (mean=-0.000000, std=0.000003), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000007), db (mean=-0.000000, std=0.000001)\n",
            "\n",
            "Epoch 167, Batch 4/10\n",
            "  Loss: 0.000018\n",
            "  y_pred (first sample): [1.43583367e-05 3.27236261e-09 1.05516860e-12 9.99985638e-01\n",
            " 3.03258500e-14 2.37398195e-11 7.62775429e-16]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000005), db (mean=-0.000002, std=0.000002)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000003), db (mean=-0.000001, std=0.000001)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000011), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000050), db (mean=0.000000, std=0.000006)\n",
            "\n",
            "Epoch 167, Batch 5/10\n",
            "  Loss: 0.000008\n",
            "  y_pred (first sample): [7.93008986e-10 9.99979381e-01 3.08496061e-06 9.86616861e-09\n",
            " 5.03980792e-13 4.37035155e-06 1.31527048e-05]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000005), db (mean=-0.000001, std=0.000008)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000004), db (mean=-0.000000, std=0.000004)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000011), db (mean=-0.000001, std=0.000003)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000018), db (mean=0.000000, std=0.000002)\n",
            "\n",
            "Epoch 167, Batch 6/10\n",
            "  Loss: 0.000076\n",
            "  y_pred (first sample): [7.37795086e-07 1.37344960e-18 9.99881912e-01 1.00829989e-14\n",
            " 3.21147831e-05 8.52351651e-05 1.70274783e-11]\n",
            "  y_true (first sample): [0. 0. 1. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000004, std=0.000045), db (mean=-0.000009, std=0.000034)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000031), db (mean=-0.000002, std=0.000021)\n",
            "    Layer 2: dW (mean=-0.000007, std=0.000087), db (mean=-0.000003, std=0.000018)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000174), db (mean=0.000000, std=0.000020)\n",
            "\n",
            "Epoch 167, Batch 7/10\n",
            "  Loss: 0.000022\n",
            "  y_pred (first sample): [9.99999934e-01 5.05069870e-25 6.64252210e-08 4.44798101e-17\n",
            " 4.27551165e-28 1.58239136e-12 8.92163325e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000012), db (mean=-0.000002, std=0.000009)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000009), db (mean=-0.000000, std=0.000005)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000029), db (mean=-0.000001, std=0.000005)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000068), db (mean=0.000000, std=0.000007)\n",
            "\n",
            "Epoch 167, Batch 8/10\n",
            "  Loss: 0.000060\n",
            "  y_pred (first sample): [2.75012886e-14 2.50162451e-17 1.40342987e-04 4.71743926e-16\n",
            " 9.99834551e-01 2.06997199e-05 4.40658572e-06]\n",
            "  y_true (first sample): [0. 0. 0. 0. 1. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000002, std=0.000059), db (mean=0.000003, std=0.000051)\n",
            "    Layer 1: dW (mean=0.000002, std=0.000036), db (mean=0.000002, std=0.000024)\n",
            "    Layer 2: dW (mean=0.000021, std=0.000121), db (mean=0.000007, std=0.000025)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000215), db (mean=0.000000, std=0.000026)\n",
            "\n",
            "Epoch 167, Batch 9/10\n",
            "  Loss: 0.000055\n",
            "  y_pred (first sample): [2.85795546e-26 1.33674836e-09 2.65472541e-15 8.75287686e-21\n",
            " 7.61295124e-07 1.26866752e-07 9.99999111e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000066), db (mean=0.000002, std=0.000047)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000038), db (mean=-0.000001, std=0.000025)\n",
            "    Layer 2: dW (mean=-0.000010, std=0.000109), db (mean=-0.000004, std=0.000021)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000210), db (mean=-0.000000, std=0.000023)\n",
            "\n",
            "Epoch 167, Batch 10/10\n",
            "  Loss: 0.000030\n",
            "  y_pred (first sample): [1.74886657e-14 5.91746992e-05 6.62631147e-08 8.34840569e-12\n",
            " 8.60487494e-05 5.98359692e-05 9.99794874e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000008), db (mean=0.000001, std=0.000022)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000008), db (mean=-0.000001, std=0.000011)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000026), db (mean=-0.000002, std=0.000009)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000066), db (mean=-0.000000, std=0.000011)\n",
            "\n",
            "Epoch 168, Batch 1/10\n",
            "  Loss: 0.000029\n",
            "  y_pred (first sample): [4.01562178e-08 9.99995128e-01 4.27895052e-06 3.51139920e-07\n",
            " 7.26170035e-15 9.26138778e-08 1.09563112e-07]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000003, std=0.000028), db (mean=-0.000006, std=0.000017)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000022), db (mean=-0.000001, std=0.000013)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000073), db (mean=-0.000001, std=0.000014)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000130), db (mean=-0.000000, std=0.000013)\n",
            "\n",
            "Epoch 168, Batch 2/10\n",
            "  Loss: 0.000062\n",
            "  y_pred (first sample): [9.99999934e-01 4.95337916e-25 6.59021963e-08 4.38369078e-17\n",
            " 4.13682047e-28 1.55457724e-12 8.66131052e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000068), db (mean=-0.000000, std=0.000055)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000041), db (mean=-0.000002, std=0.000030)\n",
            "    Layer 2: dW (mean=-0.000010, std=0.000115), db (mean=-0.000004, std=0.000024)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000213), db (mean=-0.000000, std=0.000025)\n",
            "\n",
            "Epoch 168, Batch 3/10\n",
            "  Loss: 0.000007\n",
            "  y_pred (first sample): [9.99983528e-01 5.73793698e-24 1.64719707e-05 1.07338729e-14\n",
            " 1.40896496e-21 3.90885566e-11 1.00734782e-25]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000004), db (mean=-0.000001, std=0.000005)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000003), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000009), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000018), db (mean=0.000000, std=0.000002)\n",
            "\n",
            "Epoch 168, Batch 4/10\n",
            "  Loss: 0.000042\n",
            "  y_pred (first sample): [9.99999350e-01 7.63444752e-27 6.50058044e-07 2.57850124e-18\n",
            " 2.01324052e-27 1.34257277e-12 3.21350231e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000012), db (mean=-0.000000, std=0.000015)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000009), db (mean=-0.000001, std=0.000007)\n",
            "    Layer 2: dW (mean=-0.000005, std=0.000028), db (mean=-0.000002, std=0.000006)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000076), db (mean=0.000000, std=0.000010)\n",
            "\n",
            "Epoch 168, Batch 5/10\n",
            "  Loss: 0.000064\n",
            "  y_pred (first sample): [1.43195137e-13 5.37573351e-15 1.18343078e-04 1.00270582e-14\n",
            " 9.99712544e-01 9.10576909e-05 7.80552084e-05]\n",
            "  y_true (first sample): [0. 0. 0. 0. 1. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000030), db (mean=0.000000, std=0.000032)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000019), db (mean=-0.000000, std=0.000017)\n",
            "    Layer 2: dW (mean=0.000002, std=0.000075), db (mean=0.000000, std=0.000019)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000124), db (mean=0.000000, std=0.000015)\n",
            "\n",
            "Epoch 168, Batch 6/10\n",
            "  Loss: 0.000044\n",
            "  y_pred (first sample): [7.96498299e-12 9.99999969e-01 4.42590373e-09 1.59373009e-10\n",
            " 1.84264056e-19 2.53158008e-08 1.52653862e-09]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000011), db (mean=-0.000005, std=0.000015)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000010), db (mean=-0.000002, std=0.000008)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000034), db (mean=-0.000002, std=0.000009)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000098), db (mean=0.000000, std=0.000013)\n",
            "\n",
            "Epoch 168, Batch 7/10\n",
            "  Loss: 0.000005\n",
            "  y_pred (first sample): [1.86631253e-10 2.46139278e-08 9.29019844e-06 4.19200310e-15\n",
            " 7.35190194e-15 9.99990685e-01 1.41182116e-10]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000003), db (mean=-0.000001, std=0.000004)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000000, std=0.000007), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000015), db (mean=-0.000000, std=0.000002)\n",
            "\n",
            "Epoch 168, Batch 8/10\n",
            "  Loss: 0.000045\n",
            "  y_pred (first sample): [1.31670724e-16 9.99999741e-01 1.74847596e-12 5.53401377e-12\n",
            " 8.20829308e-19 8.78542512e-11 2.58752448e-07]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000029), db (mean=-0.000003, std=0.000037)\n",
            "    Layer 1: dW (mean=0.000002, std=0.000023), db (mean=0.000002, std=0.000019)\n",
            "    Layer 2: dW (mean=-0.000009, std=0.000059), db (mean=-0.000004, std=0.000014)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000156), db (mean=0.000000, std=0.000018)\n",
            "\n",
            "Epoch 168, Batch 9/10\n",
            "  Loss: 0.000038\n",
            "  y_pred (first sample): [1.62946290e-30 3.27979430e-12 3.00749182e-17 1.65171351e-24\n",
            " 8.82015890e-07 4.03247186e-08 9.99999078e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000027), db (mean=-0.000004, std=0.000023)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000020), db (mean=-0.000000, std=0.000014)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000071), db (mean=-0.000002, std=0.000017)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000129), db (mean=0.000000, std=0.000016)\n",
            "\n",
            "Epoch 168, Batch 10/10\n",
            "  Loss: 0.000054\n",
            "  y_pred (first sample): [1.79907295e-05 8.17117963e-07 3.21160933e-11 9.99981189e-01\n",
            " 7.01721051e-12 2.92234935e-09 2.20145175e-12]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000030), db (mean=0.000001, std=0.000017)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000022), db (mean=-0.000001, std=0.000012)\n",
            "    Layer 2: dW (mean=0.000008, std=0.000090), db (mean=0.000002, std=0.000017)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000151), db (mean=0.000000, std=0.000016)\n",
            "\n",
            "Epoch 169, Batch 1/10\n",
            "  Loss: 0.000028\n",
            "  y_pred (first sample): [2.99497609e-12 9.99999994e-01 5.96805864e-10 1.52224099e-10\n",
            " 5.99249985e-20 4.66721892e-09 9.11752614e-10]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000008), db (mean=0.000001, std=0.000020)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000008), db (mean=-0.000001, std=0.000010)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000025), db (mean=-0.000002, std=0.000008)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000058), db (mean=0.000000, std=0.000010)\n",
            "\n",
            "Epoch 169, Batch 2/10\n",
            "  Loss: 0.000032\n",
            "  y_pred (first sample): [9.99999978e-01 5.22097996e-26 2.16973673e-08 8.23562516e-18\n",
            " 1.39193675e-29 4.09680482e-13 3.68335760e-31]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000039), db (mean=-0.000002, std=0.000025)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000023), db (mean=-0.000002, std=0.000013)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000077), db (mean=-0.000001, std=0.000014)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000136), db (mean=-0.000000, std=0.000013)\n",
            "\n",
            "Epoch 169, Batch 3/10\n",
            "  Loss: 0.000073\n",
            "  y_pred (first sample): [1.28093867e-13 4.99155234e-15 1.10551516e-04 9.26477420e-15\n",
            " 9.99725479e-01 8.64210125e-05 7.75487679e-05]\n",
            "  y_true (first sample): [0. 0. 0. 0. 1. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000044), db (mean=-0.000004, std=0.000038)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000029), db (mean=0.000000, std=0.000021)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000104), db (mean=-0.000001, std=0.000025)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000169), db (mean=-0.000000, std=0.000021)\n",
            "\n",
            "Epoch 169, Batch 4/10\n",
            "  Loss: 0.000005\n",
            "  y_pred (first sample): [7.77122067e-12 9.99999969e-01 4.39598100e-09 1.56682745e-10\n",
            " 1.82160764e-19 2.50850140e-08 1.54642370e-09]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000005), db (mean=-0.000000, std=0.000007)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000004), db (mean=0.000000, std=0.000003)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000009), db (mean=-0.000000, std=0.000003)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000012), db (mean=0.000000, std=0.000002)\n",
            "\n",
            "Epoch 169, Batch 5/10\n",
            "  Loss: 0.000029\n",
            "  y_pred (first sample): [3.00440196e-12 9.99999994e-01 5.98375392e-10 1.52804352e-10\n",
            " 5.95158432e-20 4.64492380e-09 9.09094429e-10]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000055), db (mean=0.000001, std=0.000027)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000028), db (mean=-0.000000, std=0.000013)\n",
            "    Layer 2: dW (mean=-0.000007, std=0.000069), db (mean=-0.000002, std=0.000010)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000120), db (mean=-0.000000, std=0.000010)\n",
            "\n",
            "Epoch 169, Batch 6/10\n",
            "  Loss: 0.000043\n",
            "  y_pred (first sample): [9.99951398e-01 6.09887154e-17 4.86011199e-05 5.77016251e-12\n",
            " 3.87429923e-23 4.13116999e-10 1.45887901e-23]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000014), db (mean=-0.000000, std=0.000014)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000009), db (mean=-0.000000, std=0.000005)\n",
            "    Layer 2: dW (mean=-0.000005, std=0.000027), db (mean=-0.000002, std=0.000006)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000072), db (mean=-0.000000, std=0.000010)\n",
            "\n",
            "Epoch 169, Batch 7/10\n",
            "  Loss: 0.000049\n",
            "  y_pred (first sample): [6.88022566e-07 1.35161732e-18 9.99877057e-01 1.01240467e-14\n",
            " 3.55232558e-05 8.67321649e-05 1.81884798e-11]\n",
            "  y_true (first sample): [0. 0. 1. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000023), db (mean=-0.000005, std=0.000023)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000015), db (mean=-0.000000, std=0.000012)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000042), db (mean=-0.000001, std=0.000010)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000154), db (mean=-0.000000, std=0.000019)\n",
            "\n",
            "Epoch 169, Batch 8/10\n",
            "  Loss: 0.000005\n",
            "  y_pred (first sample): [9.99995340e-01 8.24608934e-22 4.66023172e-06 4.90708844e-15\n",
            " 1.21025104e-22 1.30187963e-10 1.85568047e-24]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000003), db (mean=-0.000001, std=0.000004)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000007), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000015), db (mean=-0.000000, std=0.000001)\n",
            "\n",
            "Epoch 169, Batch 9/10\n",
            "  Loss: 0.000059\n",
            "  y_pred (first sample): [9.99999936e-01 4.75090922e-25 6.43062733e-08 4.26325958e-17\n",
            " 3.81698817e-28 1.47166131e-12 8.09753824e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000016), db (mean=-0.000005, std=0.000026)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000013), db (mean=-0.000003, std=0.000012)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000045), db (mean=-0.000001, std=0.000011)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000124), db (mean=0.000000, std=0.000015)\n",
            "\n",
            "Epoch 169, Batch 10/10\n",
            "  Loss: 0.000059\n",
            "  y_pred (first sample): [1.36973651e-14 1.10089297e-10 3.85346079e-05 1.48702971e-16\n",
            " 4.33485111e-05 9.99773229e-01 1.44887386e-04]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000043), db (mean=-0.000003, std=0.000041)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000030), db (mean=-0.000001, std=0.000023)\n",
            "    Layer 2: dW (mean=-0.000012, std=0.000096), db (mean=-0.000005, std=0.000020)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000165), db (mean=0.000000, std=0.000018)\n",
            "\n",
            "Epoch 170, Batch 1/10\n",
            "  Loss: 0.000019\n",
            "  y_pred (first sample): [7.54031455e-10 9.99980151e-01 2.93131699e-06 9.61137741e-09\n",
            " 4.57634798e-13 4.06814203e-06 1.28391652e-05]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000020), db (mean=-0.000001, std=0.000017)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000011), db (mean=0.000001, std=0.000007)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000027), db (mean=-0.000000, std=0.000006)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000072), db (mean=0.000000, std=0.000007)\n",
            "\n",
            "Epoch 170, Batch 2/10\n",
            "  Loss: 0.000004\n",
            "  y_pred (first sample): [1.36078827e-05 3.10267190e-09 9.53721322e-13 9.99986389e-01\n",
            " 2.73890319e-14 2.17847131e-11 6.79779212e-16]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000002), db (mean=-0.000001, std=0.000003)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 2: dW (mean=0.000000, std=0.000006), db (mean=0.000000, std=0.000001)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000010), db (mean=-0.000000, std=0.000001)\n",
            "\n",
            "Epoch 170, Batch 3/10\n",
            "  Loss: 0.000041\n",
            "  y_pred (first sample): [2.40763216e-14 1.00000000e+00 1.61664449e-12 9.15768437e-12\n",
            " 1.00482820e-23 1.27693647e-11 1.05690337e-11]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000015), db (mean=-0.000003, std=0.000021)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000014), db (mean=0.000000, std=0.000011)\n",
            "    Layer 2: dW (mean=-0.000009, std=0.000037), db (mean=-0.000004, std=0.000009)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000085), db (mean=0.000000, std=0.000010)\n",
            "\n",
            "Epoch 170, Batch 4/10\n",
            "  Loss: 0.000083\n",
            "  y_pred (first sample): [1.39431104e-04 4.31233480e-17 9.99766044e-01 5.99571359e-12\n",
            " 9.16759727e-05 2.84891690e-06 6.00597462e-11]\n",
            "  y_true (first sample): [0. 0. 1. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000024), db (mean=-0.000005, std=0.000025)\n",
            "    Layer 1: dW (mean=-0.000004, std=0.000016), db (mean=-0.000005, std=0.000012)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000060), db (mean=-0.000002, std=0.000013)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000161), db (mean=0.000000, std=0.000017)\n",
            "\n",
            "Epoch 170, Batch 5/10\n",
            "  Loss: 0.000007\n",
            "  y_pred (first sample): [9.99999004e-01 2.12202550e-25 9.96412353e-07 2.39906659e-17\n",
            " 3.69444900e-26 4.50006236e-12 1.18551241e-28]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000005), db (mean=-0.000001, std=0.000008)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000004), db (mean=-0.000000, std=0.000003)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000010), db (mean=-0.000000, std=0.000003)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000014), db (mean=-0.000000, std=0.000002)\n",
            "\n",
            "Epoch 170, Batch 6/10\n",
            "  Loss: 0.000028\n",
            "  y_pred (first sample): [1.77252590e-05 8.05540020e-07 3.19322307e-11 9.99981466e-01\n",
            " 7.05387244e-12 2.92839035e-09 2.18716101e-12]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000058), db (mean=0.000001, std=0.000030)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000031), db (mean=-0.000000, std=0.000015)\n",
            "    Layer 2: dW (mean=-0.000007, std=0.000078), db (mean=-0.000002, std=0.000012)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000135), db (mean=0.000000, std=0.000011)\n",
            "\n",
            "Epoch 170, Batch 7/10\n",
            "  Loss: 0.000028\n",
            "  y_pred (first sample): [9.99990557e-01 1.06152721e-24 9.44253768e-06 6.11729178e-17\n",
            " 1.08347707e-24 3.80702652e-11 1.05748157e-27]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000008), db (mean=0.000002, std=0.000021)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000008), db (mean=-0.000001, std=0.000010)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000025), db (mean=-0.000002, std=0.000008)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000063), db (mean=-0.000000, std=0.000011)\n",
            "\n",
            "Epoch 170, Batch 8/10\n",
            "  Loss: 0.000041\n",
            "  y_pred (first sample): [1.68058656e-14 6.51546468e-05 1.87033617e-08 1.84389565e-11\n",
            " 1.04435761e-04 6.78475413e-05 9.99762543e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000015), db (mean=-0.000003, std=0.000021)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000011), db (mean=-0.000001, std=0.000010)\n",
            "    Layer 2: dW (mean=-0.000005, std=0.000036), db (mean=-0.000002, std=0.000009)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000091), db (mean=0.000000, std=0.000013)\n",
            "\n",
            "Epoch 170, Batch 9/10\n",
            "  Loss: 0.000014\n",
            "  y_pred (first sample): [8.40289070e-06 1.07775470e-06 1.92071641e-12 9.99990519e-01\n",
            " 2.28905506e-13 2.83031224e-10 2.59810073e-13]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000006), db (mean=-0.000002, std=0.000003)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000003), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000009), db (mean=-0.000001, std=0.000001)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000041), db (mean=0.000000, std=0.000005)\n",
            "\n",
            "Epoch 170, Batch 10/10\n",
            "  Loss: 0.000113\n",
            "  y_pred (first sample): [9.99999004e-01 2.06869685e-25 9.96451797e-07 2.35488705e-17\n",
            " 3.59713771e-26 4.43456599e-12 1.15494403e-28]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000003, std=0.000081), db (mean=-0.000004, std=0.000046)\n",
            "    Layer 1: dW (mean=-0.000004, std=0.000043), db (mean=-0.000004, std=0.000018)\n",
            "    Layer 2: dW (mean=-0.000016, std=0.000108), db (mean=-0.000006, std=0.000014)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000198), db (mean=0.000000, std=0.000015)\n",
            "\n",
            "Epoch 171, Batch 1/10\n",
            "  Loss: 0.000045\n",
            "  y_pred (first sample): [9.99999352e-01 6.66961844e-27 6.48139365e-07 2.34933695e-18\n",
            " 1.76125624e-27 1.22322819e-12 2.79053201e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000052), db (mean=-0.000002, std=0.000037)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000030), db (mean=-0.000001, std=0.000019)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000083), db (mean=-0.000001, std=0.000016)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000119), db (mean=-0.000000, std=0.000011)\n",
            "\n",
            "Epoch 171, Batch 2/10\n",
            "  Loss: 0.000091\n",
            "  y_pred (first sample): [4.20025246e-05 3.85260294e-11 9.99737460e-01 6.25389572e-11\n",
            " 2.93037286e-08 2.20506951e-04 8.23337141e-10]\n",
            "  y_true (first sample): [0. 0. 1. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000003, std=0.000026), db (mean=-0.000006, std=0.000024)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000021), db (mean=-0.000002, std=0.000016)\n",
            "    Layer 2: dW (mean=-0.000011, std=0.000085), db (mean=-0.000005, std=0.000022)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000213), db (mean=0.000000, std=0.000031)\n",
            "\n",
            "Epoch 171, Batch 3/10\n",
            "  Loss: 0.000006\n",
            "  y_pred (first sample): [2.08979305e-09 9.99999968e-01 1.39510276e-08 1.57620566e-08\n",
            " 2.94816963e-21 4.69959913e-10 8.64533387e-12]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000004), db (mean=-0.000001, std=0.000004)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000003), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000012), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000028), db (mean=-0.000000, std=0.000002)\n",
            "\n",
            "Epoch 171, Batch 4/10\n",
            "  Loss: 0.000003\n",
            "  y_pred (first sample): [2.42722028e-14 1.00000000e+00 1.61439574e-12 9.20079281e-12\n",
            " 9.64925061e-24 1.26466328e-11 1.03591205e-11]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000003)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000005), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000010), db (mean=0.000000, std=0.000001)\n",
            "\n",
            "Epoch 171, Batch 5/10\n",
            "  Loss: 0.000029\n",
            "  y_pred (first sample): [9.99999937e-01 4.38356158e-25 6.34355890e-08 3.99604599e-17\n",
            " 3.35772628e-28 1.38438916e-12 7.25055944e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000057), db (mean=0.000001, std=0.000029)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000029), db (mean=-0.000000, std=0.000014)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000072), db (mean=-0.000001, std=0.000011)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000124), db (mean=0.000000, std=0.000010)\n",
            "\n",
            "Epoch 171, Batch 6/10\n",
            "  Loss: 0.000035\n",
            "  y_pred (first sample): [7.65095341e-10 9.99980408e-01 2.95598238e-06 9.69110559e-09\n",
            " 4.41283067e-13 4.03918558e-06 1.25862023e-05]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000039), db (mean=-0.000003, std=0.000027)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000025), db (mean=-0.000001, std=0.000015)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000080), db (mean=-0.000001, std=0.000015)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000133), db (mean=-0.000000, std=0.000013)\n",
            "\n",
            "Epoch 171, Batch 7/10\n",
            "  Loss: 0.000092\n",
            "  y_pred (first sample): [1.65748791e-14 6.49688687e-05 1.86493266e-08 1.81507675e-11\n",
            " 1.03012562e-04 6.77513512e-05 9.99764249e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000030), db (mean=-0.000002, std=0.000047)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000023), db (mean=-0.000002, std=0.000026)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000089), db (mean=-0.000002, std=0.000026)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000148), db (mean=0.000000, std=0.000022)\n",
            "\n",
            "Epoch 171, Batch 8/10\n",
            "  Loss: 0.000044\n",
            "  y_pred (first sample): [3.04296226e-12 9.99999994e-01 5.96381544e-10 1.54264779e-10\n",
            " 5.48115833e-20 4.50392862e-09 8.73450816e-10]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000026), db (mean=0.000001, std=0.000018)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000015), db (mean=0.000001, std=0.000008)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000035), db (mean=-0.000001, std=0.000006)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000063), db (mean=0.000000, std=0.000005)\n",
            "\n",
            "Epoch 171, Batch 9/10\n",
            "  Loss: 0.000017\n",
            "  y_pred (first sample): [2.21030066e-15 1.09169865e-16 2.68747705e-05 1.37875561e-16\n",
            " 9.99909912e-01 3.04838312e-05 3.27292263e-05]\n",
            "  y_true (first sample): [0. 0. 0. 0. 1. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000005), db (mean=-0.000002, std=0.000005)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000004), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000011), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000047), db (mean=-0.000000, std=0.000006)\n",
            "\n",
            "Epoch 171, Batch 10/10\n",
            "  Loss: 0.000013\n",
            "  y_pred (first sample): [9.99999031e-01 2.00381627e-25 9.69289660e-07 2.28252799e-17\n",
            " 3.24178004e-26 4.25399395e-12 1.06931768e-28]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000005), db (mean=-0.000002, std=0.000003)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000003), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000009), db (mean=-0.000001, std=0.000001)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000040), db (mean=-0.000000, std=0.000004)\n",
            "\n",
            "=== Epoch 171 Summary ===\n",
            "Average Batch Loss: 0.000037\n",
            "Full Dataset Loss: 0.000037\n",
            "Final y_pred sample: [1.19470716e-13 4.39196407e-15 1.11171640e-04 8.38034468e-15\n",
            " 9.99731294e-01 8.42015759e-05 7.33326295e-05]\n",
            "Final y_true sample: [0. 0. 0. 0. 1. 0. 0.]\n",
            "\n",
            "Epoch 172, Batch 1/10\n",
            "  Loss: 0.000024\n",
            "  y_pred (first sample): [1.39322252e-30 2.91138649e-12 2.81377651e-17 1.44399345e-24\n",
            " 8.78600609e-07 3.90046121e-08 9.99999082e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000002, std=0.000027), db (mean=0.000003, std=0.000023)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000017), db (mean=0.000001, std=0.000011)\n",
            "    Layer 2: dW (mean=0.000013, std=0.000059), db (mean=0.000004, std=0.000011)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000086), db (mean=0.000000, std=0.000010)\n",
            "\n",
            "Epoch 172, Batch 2/10\n",
            "  Loss: 0.000031\n",
            "  y_pred (first sample): [9.99999382e-01 1.77378851e-23 6.17812585e-07 5.89879824e-16\n",
            " 5.13198985e-25 1.15781756e-11 7.38512124e-27]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000016), db (mean=-0.000004, std=0.000012)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000011), db (mean=-0.000001, std=0.000006)\n",
            "    Layer 2: dW (mean=-0.000005, std=0.000030), db (mean=-0.000002, std=0.000005)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000095), db (mean=0.000000, std=0.000010)\n",
            "\n",
            "Epoch 172, Batch 3/10\n",
            "  Loss: 0.000034\n",
            "  y_pred (first sample): [9.99999938e-01 4.26346508e-25 6.23542462e-08 3.91154729e-17\n",
            " 3.16952760e-28 1.34604164e-12 6.90947826e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000003, std=0.000033), db (mean=-0.000005, std=0.000021)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000022), db (mean=-0.000002, std=0.000013)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000071), db (mean=-0.000002, std=0.000013)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000124), db (mean=0.000000, std=0.000012)\n",
            "\n",
            "Epoch 172, Batch 4/10\n",
            "  Loss: 0.000029\n",
            "  y_pred (first sample): [8.31285821e-08 9.99980202e-01 1.89792826e-05 3.48934535e-07\n",
            " 1.41971067e-14 2.31551396e-07 1.54894900e-07]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000061), db (mean=0.000001, std=0.000034)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000033), db (mean=0.000000, std=0.000017)\n",
            "    Layer 2: dW (mean=-0.000007, std=0.000082), db (mean=-0.000002, std=0.000013)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000133), db (mean=-0.000000, std=0.000011)\n",
            "\n",
            "Epoch 172, Batch 5/10\n",
            "  Loss: 0.000035\n",
            "  y_pred (first sample): [9.99999038e-01 1.95250487e-25 9.62268401e-07 2.24475630e-17\n",
            " 3.16651728e-26 4.18769836e-12 1.03940298e-28]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000024), db (mean=-0.000003, std=0.000021)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000019), db (mean=-0.000000, std=0.000013)\n",
            "    Layer 2: dW (mean=-0.000007, std=0.000071), db (mean=-0.000003, std=0.000017)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000124), db (mean=-0.000000, std=0.000016)\n",
            "\n",
            "Epoch 172, Batch 6/10\n",
            "  Loss: 0.000056\n",
            "  y_pred (first sample): [9.99990948e-01 9.78722984e-25 9.05186364e-06 5.73067575e-17\n",
            " 9.23491191e-25 3.54609894e-11 9.21885091e-28]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000010), db (mean=-0.000002, std=0.000021)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000009), db (mean=-0.000002, std=0.000009)\n",
            "    Layer 2: dW (mean=-0.000005, std=0.000030), db (mean=-0.000003, std=0.000008)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000103), db (mean=-0.000000, std=0.000017)\n",
            "\n",
            "Epoch 172, Batch 7/10\n",
            "  Loss: 0.000057\n",
            "  y_pred (first sample): [1.88569572e-26 1.10609918e-09 2.07852861e-15 6.30209841e-21\n",
            " 6.89261938e-07 1.12471687e-07 9.99999197e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000028), db (mean=0.000001, std=0.000031)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000018), db (mean=-0.000000, std=0.000017)\n",
            "    Layer 2: dW (mean=0.000003, std=0.000069), db (mean=0.000000, std=0.000017)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000109), db (mean=0.000000, std=0.000013)\n",
            "\n",
            "Epoch 172, Batch 8/10\n",
            "  Loss: 0.000073\n",
            "  y_pred (first sample): [1.69370088e-05 8.09450589e-07 3.05773193e-11 9.99982251e-01\n",
            " 6.97574690e-12 2.93296919e-09 2.19100365e-12]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000026), db (mean=-0.000006, std=0.000023)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000017), db (mean=0.000000, std=0.000007)\n",
            "    Layer 2: dW (mean=-0.000009, std=0.000050), db (mean=-0.000005, std=0.000009)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000173), db (mean=-0.000000, std=0.000024)\n",
            "\n",
            "Epoch 172, Batch 9/10\n",
            "  Loss: 0.000003\n",
            "  y_pred (first sample): [4.35577178e-06 3.10713172e-08 2.04292222e-13 9.99995613e-01\n",
            " 1.18989513e-14 1.93585450e-11 2.35996927e-15]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000005), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000012), db (mean=-0.000000, std=0.000001)\n",
            "\n",
            "Epoch 172, Batch 10/10\n",
            "  Loss: 0.000027\n",
            "  y_pred (first sample): [9.99999371e-01 6.10981602e-27 6.29482287e-07 2.19962132e-18\n",
            " 1.53148814e-27 1.13568707e-12 2.45706554e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000038), db (mean=-0.000001, std=0.000024)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000022), db (mean=-0.000001, std=0.000013)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000071), db (mean=-0.000001, std=0.000013)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000125), db (mean=0.000000, std=0.000012)\n",
            "\n",
            "Epoch 173, Batch 1/10\n",
            "  Loss: 0.000026\n",
            "  y_pred (first sample): [1.41662104e-14 5.45109193e-05 5.88978287e-08 7.06207087e-12\n",
            " 7.91627866e-05 5.41516943e-05 9.99812116e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000007), db (mean=0.000000, std=0.000017)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000006), db (mean=-0.000001, std=0.000008)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000016), db (mean=-0.000002, std=0.000006)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000050), db (mean=-0.000000, std=0.000009)\n",
            "\n",
            "Epoch 173, Batch 2/10\n",
            "  Loss: 0.000016\n",
            "  y_pred (first sample): [1.33990400e-05 2.93290035e-09 8.98905973e-13 9.99986598e-01\n",
            " 2.52751473e-14 2.05180043e-11 6.16697873e-16]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000006), db (mean=-0.000002, std=0.000003)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000003), db (mean=-0.000001, std=0.000001)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000011), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000044), db (mean=0.000000, std=0.000005)\n",
            "\n",
            "Epoch 173, Batch 3/10\n",
            "  Loss: 0.000031\n",
            "  y_pred (first sample): [9.99984108e-01 4.59772837e-24 1.58919513e-05 9.80266751e-15\n",
            " 1.15359971e-21 3.29809542e-11 7.87010276e-26]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000008), db (mean=-0.000004, std=0.000020)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000008), db (mean=-0.000002, std=0.000011)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000026), db (mean=-0.000002, std=0.000009)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000069), db (mean=-0.000000, std=0.000012)\n",
            "\n",
            "Epoch 173, Batch 4/10\n",
            "  Loss: 0.000004\n",
            "  y_pred (first sample): [8.14434667e-06 1.04048848e-06 1.78972456e-12 9.99990815e-01\n",
            " 2.12326623e-13 2.67362495e-10 2.40103956e-13]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000002), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000007), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000016), db (mean=0.000000, std=0.000001)\n",
            "\n",
            "Epoch 173, Batch 5/10\n",
            "  Loss: 0.000070\n",
            "  y_pred (first sample): [1.87308800e-14 1.82546843e-17 1.12940764e-04 3.65264690e-16\n",
            " 9.99865350e-01 1.76382466e-05 4.07118209e-06]\n",
            "  y_true (first sample): [0. 0. 0. 0. 1. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000033), db (mean=0.000001, std=0.000026)\n",
            "    Layer 1: dW (mean=-0.000003, std=0.000022), db (mean=-0.000003, std=0.000011)\n",
            "    Layer 2: dW (mean=0.000006, std=0.000075), db (mean=0.000001, std=0.000013)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000121), db (mean=0.000000, std=0.000010)\n",
            "\n",
            "Epoch 173, Batch 6/10\n",
            "  Loss: 0.000050\n",
            "  y_pred (first sample): [1.66736439e-05 8.11735576e-07 3.01862740e-11 9.99982512e-01\n",
            " 6.96773171e-12 2.94142431e-09 2.19913364e-12]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000003, std=0.000024), db (mean=-0.000005, std=0.000019)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000014), db (mean=-0.000001, std=0.000009)\n",
            "    Layer 2: dW (mean=-0.000007, std=0.000032), db (mean=-0.000002, std=0.000006)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000110), db (mean=0.000000, std=0.000013)\n",
            "\n",
            "Epoch 173, Batch 7/10\n",
            "  Loss: 0.000009\n",
            "  y_pred (first sample): [9.99997066e-01 9.93716651e-21 2.93340945e-06 1.70733370e-14\n",
            " 3.56225579e-23 3.43260638e-10 1.50961910e-24]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000000, std=0.000010), db (mean=0.000000, std=0.000009)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000008), db (mean=0.000001, std=0.000005)\n",
            "    Layer 2: dW (mean=-0.000000, std=0.000025), db (mean=-0.000000, std=0.000005)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000046), db (mean=-0.000000, std=0.000004)\n",
            "\n",
            "Epoch 173, Batch 8/10\n",
            "  Loss: 0.000093\n",
            "  y_pred (first sample): [4.15556039e-05 3.67289476e-11 9.99743206e-01 5.96192741e-11\n",
            " 2.73149807e-08 2.15210118e-04 7.81772424e-10]\n",
            "  y_true (first sample): [0. 0. 1. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000048), db (mean=-0.000005, std=0.000025)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000032), db (mean=0.000000, std=0.000016)\n",
            "    Layer 2: dW (mean=-0.000021, std=0.000115), db (mean=-0.000008, std=0.000023)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000232), db (mean=-0.000000, std=0.000027)\n",
            "\n",
            "Epoch 173, Batch 9/10\n",
            "  Loss: 0.000002\n",
            "  y_pred (first sample): [1.00275248e-31 4.49305483e-13 6.78717433e-17 3.04481984e-26\n",
            " 6.85252922e-07 4.59941068e-08 9.99999269e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000001), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000001), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 2: dW (mean=0.000000, std=0.000002), db (mean=0.000000, std=0.000001)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000006), db (mean=0.000000, std=0.000001)\n",
            "\n",
            "Epoch 173, Batch 10/10\n",
            "  Loss: 0.000060\n",
            "  y_pred (first sample): [1.32067181e-04 3.95678810e-17 9.99775285e-01 5.51951032e-12\n",
            " 8.98580297e-05 2.78979822e-06 5.75907113e-11]\n",
            "  y_true (first sample): [0. 0. 1. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000004, std=0.000030), db (mean=-0.000009, std=0.000021)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000024), db (mean=-0.000003, std=0.000015)\n",
            "    Layer 2: dW (mean=-0.000007, std=0.000078), db (mean=-0.000003, std=0.000016)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000153), db (mean=0.000000, std=0.000017)\n",
            "\n",
            "Epoch 174, Batch 1/10\n",
            "  Loss: 0.000051\n",
            "  y_pred (first sample): [9.99999382e-01 5.81123742e-27 6.18305991e-07 2.11872465e-18\n",
            " 1.41603860e-27 1.09171277e-12 2.28898236e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000039), db (mean=0.000001, std=0.000034)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000023), db (mean=-0.000000, std=0.000016)\n",
            "    Layer 2: dW (mean=0.000010, std=0.000095), db (mean=0.000003, std=0.000019)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000181), db (mean=-0.000000, std=0.000022)\n",
            "\n",
            "Epoch 174, Batch 2/10\n",
            "  Loss: 0.000056\n",
            "  y_pred (first sample): [1.20411023e-06 2.52496007e-07 2.08330050e-14 9.99998543e-01\n",
            " 2.00816446e-15 1.00706915e-11 4.08877050e-15]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000012), db (mean=-0.000003, std=0.000038)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000014), db (mean=-0.000003, std=0.000021)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000048), db (mean=-0.000004, std=0.000017)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000125), db (mean=0.000000, std=0.000023)\n",
            "\n",
            "Epoch 174, Batch 3/10\n",
            "  Loss: 0.000032\n",
            "  y_pred (first sample): [1.59132837e-10 2.15920049e-08 8.59582855e-06 3.72780761e-15\n",
            " 6.69529519e-15 9.99991382e-01 1.32981974e-10]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000032), db (mean=-0.000005, std=0.000021)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000022), db (mean=-0.000002, std=0.000013)\n",
            "    Layer 2: dW (mean=-0.000005, std=0.000073), db (mean=-0.000001, std=0.000014)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000129), db (mean=0.000000, std=0.000013)\n",
            "\n",
            "Epoch 174, Batch 4/10\n",
            "  Loss: 0.000027\n",
            "  y_pred (first sample): [1.04569766e-30 2.52068442e-12 2.38159520e-17 1.14828877e-24\n",
            " 8.41126352e-07 3.65463311e-08 9.99999122e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000013), db (mean=-0.000002, std=0.000020)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000013), db (mean=0.000001, std=0.000010)\n",
            "    Layer 2: dW (mean=-0.000008, std=0.000035), db (mean=-0.000004, std=0.000009)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000088), db (mean=0.000000, std=0.000011)\n",
            "\n",
            "Epoch 174, Batch 5/10\n",
            "  Loss: 0.000035\n",
            "  y_pred (first sample): [3.74888179e-08 9.99995540e-01 3.89519141e-06 3.43583357e-07\n",
            " 5.86765010e-15 8.13915061e-08 1.02422852e-07]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000006), db (mean=-0.000004, std=0.000007)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000006), db (mean=-0.000001, std=0.000004)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000024), db (mean=-0.000001, std=0.000006)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000091), db (mean=0.000000, std=0.000012)\n",
            "\n",
            "Epoch 174, Batch 6/10\n",
            "  Loss: 0.000078\n",
            "  y_pred (first sample): [2.92798436e-12 9.99999994e-01 5.62856239e-10 1.51821842e-10\n",
            " 4.87702120e-20 4.23304052e-09 8.40126720e-10]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000004, std=0.000058), db (mean=-0.000007, std=0.000045)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000034), db (mean=-0.000001, std=0.000022)\n",
            "    Layer 2: dW (mean=-0.000010, std=0.000083), db (mean=-0.000003, std=0.000017)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000162), db (mean=0.000000, std=0.000017)\n",
            "\n",
            "Epoch 174, Batch 7/10\n",
            "  Loss: 0.000015\n",
            "  y_pred (first sample): [9.99997092e-01 9.60836166e-21 2.90718100e-06 1.66289166e-14\n",
            " 3.35554805e-23 3.33755429e-10 1.43381974e-24]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000007), db (mean=-0.000002, std=0.000005)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000005), db (mean=-0.000001, std=0.000003)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000014), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000049), db (mean=0.000000, std=0.000005)\n",
            "\n",
            "Epoch 174, Batch 8/10\n",
            "  Loss: 0.000009\n",
            "  y_pred (first sample): [2.95217879e-12 9.99999994e-01 5.66522597e-10 1.52632188e-10\n",
            " 4.85965893e-20 4.24008276e-09 8.36129656e-10]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000006), db (mean=-0.000001, std=0.000005)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000004), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000010), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000037), db (mean=0.000000, std=0.000004)\n",
            "\n",
            "Epoch 174, Batch 9/10\n",
            "  Loss: 0.000009\n",
            "  y_pred (first sample): [9.99999940e-01 3.87434060e-25 6.03055431e-08 3.64020867e-17\n",
            " 2.68028265e-28 1.23656630e-12 5.96759686e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000008), db (mean=-0.000000, std=0.000007)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000006), db (mean=0.000000, std=0.000003)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000021), db (mean=-0.000000, std=0.000004)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000040), db (mean=-0.000000, std=0.000003)\n",
            "\n",
            "Epoch 174, Batch 10/10\n",
            "  Loss: 0.000047\n",
            "  y_pred (first sample): [9.99999054e-01 1.74473363e-25 9.45778954e-07 2.06893811e-17\n",
            " 2.71817405e-26 3.85395218e-12 8.98597286e-29]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000058), db (mean=0.000002, std=0.000042)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000034), db (mean=-0.000001, std=0.000023)\n",
            "    Layer 2: dW (mean=-0.000008, std=0.000096), db (mean=-0.000003, std=0.000018)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000183), db (mean=-0.000000, std=0.000020)\n",
            "\n",
            "Epoch 175, Batch 1/10\n",
            "  Loss: 0.000030\n",
            "  y_pred (first sample): [1.06721328e-28 5.18078988e-11 1.75255628e-16 7.19402873e-23\n",
            " 6.63314337e-07 5.83491770e-08 9.99999278e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000007), db (mean=-0.000003, std=0.000011)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000007), db (mean=-0.000001, std=0.000006)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000025), db (mean=-0.000001, std=0.000007)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000094), db (mean=0.000000, std=0.000013)\n",
            "\n",
            "Epoch 175, Batch 2/10\n",
            "  Loss: 0.000077\n",
            "  y_pred (first sample): [9.99999989e-01 3.41063539e-17 3.88953266e-09 6.58885121e-09\n",
            " 3.81834769e-22 3.06642866e-11 7.18814769e-23]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000044), db (mean=0.000003, std=0.000044)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000029), db (mean=0.000000, std=0.000023)\n",
            "    Layer 2: dW (mean=0.000008, std=0.000105), db (mean=0.000002, std=0.000023)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000185), db (mean=0.000000, std=0.000021)\n",
            "\n",
            "Epoch 175, Batch 3/10\n",
            "  Loss: 0.000032\n",
            "  y_pred (first sample): [1.61252366e-10 2.07005121e-08 8.60657760e-06 3.63192922e-15\n",
            " 6.28293050e-15 9.99991372e-01 1.25269535e-10]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000008), db (mean=-0.000004, std=0.000022)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000008), db (mean=-0.000002, std=0.000012)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000026), db (mean=-0.000001, std=0.000009)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000067), db (mean=-0.000000, std=0.000012)\n",
            "\n",
            "Epoch 175, Batch 4/10\n",
            "  Loss: 0.000052\n",
            "  y_pred (first sample): [9.99999381e-01 5.41668295e-27 6.18562879e-07 2.01251104e-18\n",
            " 1.29793061e-27 1.04497664e-12 2.10074585e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000036), db (mean=-0.000004, std=0.000035)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000027), db (mean=-0.000000, std=0.000020)\n",
            "    Layer 2: dW (mean=-0.000010, std=0.000085), db (mean=-0.000004, std=0.000018)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000149), db (mean=0.000000, std=0.000016)\n",
            "\n",
            "Epoch 175, Batch 5/10\n",
            "  Loss: 0.000030\n",
            "  y_pred (first sample): [2.34217663e-14 1.00000000e+00 1.50094337e-12 9.15701280e-12\n",
            " 8.03080265e-24 1.15204074e-11 9.67200988e-12]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000033), db (mean=-0.000003, std=0.000021)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000021), db (mean=-0.000001, std=0.000012)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000069), db (mean=-0.000001, std=0.000013)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000120), db (mean=0.000000, std=0.000012)\n",
            "\n",
            "Epoch 175, Batch 6/10\n",
            "  Loss: 0.000027\n",
            "  y_pred (first sample): [9.99999940e-01 3.77338534e-25 5.98421078e-08 3.56802839e-17\n",
            " 2.55697780e-28 1.20986239e-12 5.74037710e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000007), db (mean=0.000000, std=0.000020)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000007), db (mean=-0.000001, std=0.000010)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000023), db (mean=-0.000002, std=0.000008)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000058), db (mean=-0.000000, std=0.000010)\n",
            "\n",
            "Epoch 175, Batch 7/10\n",
            "  Loss: 0.000066\n",
            "  y_pred (first sample): [9.99988534e-01 2.27610420e-23 1.14658698e-05 4.56993945e-16\n",
            " 1.20694766e-23 9.74073229e-11 2.79234837e-26]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000045), db (mean=-0.000003, std=0.000022)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000029), db (mean=-0.000001, std=0.000016)\n",
            "    Layer 2: dW (mean=-0.000014, std=0.000107), db (mean=-0.000004, std=0.000022)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000177), db (mean=0.000000, std=0.000020)\n",
            "\n",
            "Epoch 175, Batch 8/10\n",
            "  Loss: 0.000019\n",
            "  y_pred (first sample): [2.94165451e-12 9.99999994e-01 5.60158808e-10 1.52554647e-10\n",
            " 4.66822740e-20 4.16482600e-09 8.22561493e-10]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000019), db (mean=-0.000001, std=0.000016)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000011), db (mean=0.000001, std=0.000007)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000025), db (mean=-0.000001, std=0.000005)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000062), db (mean=0.000000, std=0.000006)\n",
            "\n",
            "Epoch 175, Batch 9/10\n",
            "  Loss: 0.000005\n",
            "  y_pred (first sample): [2.93887270e-12 9.99999994e-01 5.59584964e-10 1.52462449e-10\n",
            " 4.64300587e-20 4.15026307e-09 8.20975531e-10]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000003), db (mean=-0.000000, std=0.000004)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000000, std=0.000008), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000015), db (mean=-0.000000, std=0.000002)\n",
            "\n",
            "Epoch 175, Batch 10/10\n",
            "  Loss: 0.000015\n",
            "  y_pred (first sample): [1.65995410e-15 8.56371449e-17 2.41966374e-05 1.05314804e-16\n",
            " 9.99916246e-01 2.83924247e-05 3.11645186e-05]\n",
            "  y_true (first sample): [0. 0. 0. 0. 1. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000005), db (mean=-0.000002, std=0.000005)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000004), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000010), db (mean=-0.000001, std=0.000001)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000046), db (mean=-0.000000, std=0.000005)\n",
            "\n",
            "Epoch 176, Batch 1/10\n",
            "  Loss: 0.000013\n",
            "  y_pred (first sample): [1.58140057e-10 2.07498647e-08 8.50808898e-06 3.60670270e-15\n",
            " 6.12445235e-15 9.99991471e-01 1.24918246e-10]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000004), db (mean=-0.000002, std=0.000003)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000003), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000009), db (mean=-0.000001, std=0.000001)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000042), db (mean=0.000000, std=0.000005)\n",
            "\n",
            "Epoch 176, Batch 2/10\n",
            "  Loss: 0.000108\n",
            "  y_pred (first sample): [9.50922351e-31 2.38591828e-12 2.29019249e-17 1.05913181e-24\n",
            " 8.24221158e-07 3.53948696e-08 9.99999140e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000065), db (mean=-0.000005, std=0.000047)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000037), db (mean=-0.000002, std=0.000026)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000116), db (mean=-0.000002, std=0.000024)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000186), db (mean=0.000000, std=0.000021)\n",
            "\n",
            "Epoch 176, Batch 3/10\n",
            "  Loss: 0.000032\n",
            "  y_pred (first sample): [1.61024059e-05 8.03254596e-07 2.94643069e-11 9.99983091e-01\n",
            " 6.97920010e-12 2.95745124e-09 2.19164996e-12]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000036), db (mean=-0.000002, std=0.000023)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000021), db (mean=-0.000002, std=0.000012)\n",
            "    Layer 2: dW (mean=-0.000005, std=0.000069), db (mean=-0.000001, std=0.000013)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000121), db (mean=-0.000000, std=0.000012)\n",
            "\n",
            "Epoch 176, Batch 4/10\n",
            "  Loss: 0.000048\n",
            "  y_pred (first sample): [9.99999063e-01 1.65542913e-25 9.37358068e-07 1.99411261e-17\n",
            " 2.50860061e-26 3.69452896e-12 8.37465002e-29]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000039), db (mean=-0.000004, std=0.000034)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000025), db (mean=0.000001, std=0.000018)\n",
            "    Layer 2: dW (mean=-0.000007, std=0.000083), db (mean=-0.000003, std=0.000019)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000182), db (mean=0.000000, std=0.000021)\n",
            "\n",
            "Epoch 176, Batch 5/10\n",
            "  Loss: 0.000026\n",
            "  y_pred (first sample): [1.53589103e-10 2.08856394e-08 8.49798223e-06 3.58142946e-15\n",
            " 6.18706317e-15 9.99991481e-01 1.27442913e-10]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000007), db (mean=0.000000, std=0.000019)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000007), db (mean=-0.000001, std=0.000010)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000022), db (mean=-0.000001, std=0.000007)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000055), db (mean=0.000000, std=0.000010)\n",
            "\n",
            "Epoch 176, Batch 6/10\n",
            "  Loss: 0.000034\n",
            "  y_pred (first sample): [5.96891904e-05 3.89316653e-19 9.99809340e-01 7.34998297e-13\n",
            " 1.30705442e-04 2.65651256e-07 6.72143104e-12]\n",
            "  y_true (first sample): [0. 0. 1. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000018), db (mean=-0.000001, std=0.000024)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000016), db (mean=0.000001, std=0.000012)\n",
            "    Layer 2: dW (mean=-0.000008, std=0.000044), db (mean=-0.000004, std=0.000010)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000075), db (mean=0.000000, std=0.000009)\n",
            "\n",
            "Epoch 176, Batch 7/10\n",
            "  Loss: 0.000019\n",
            "  y_pred (first sample): [7.02706393e-12 9.99999971e-01 4.17476371e-09 1.45364549e-10\n",
            " 1.44612220e-19 2.29394444e-08 1.48547219e-09]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000000, std=0.000012), db (mean=0.000000, std=0.000010)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000010), db (mean=-0.000001, std=0.000006)\n",
            "    Layer 2: dW (mean=0.000003, std=0.000039), db (mean=0.000001, std=0.000007)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000079), db (mean=0.000000, std=0.000009)\n",
            "\n",
            "Epoch 176, Batch 8/10\n",
            "  Loss: 0.000012\n",
            "  y_pred (first sample): [9.99999386e-01 5.10424175e-27 6.13749224e-07 1.92949755e-18\n",
            " 1.18686090e-27 9.93713724e-13 1.94196325e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000005), db (mean=-0.000002, std=0.000003)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000003), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000009), db (mean=-0.000001, std=0.000001)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000039), db (mean=0.000000, std=0.000004)\n",
            "\n",
            "Epoch 176, Batch 9/10\n",
            "  Loss: 0.000027\n",
            "  y_pred (first sample): [1.25847274e-14 5.18613732e-05 5.58654818e-08 6.37010525e-12\n",
            " 7.50452015e-05 5.13176129e-05 9.99821720e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000000, std=0.000010), db (mean=0.000002, std=0.000023)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000009), db (mean=-0.000000, std=0.000011)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000026), db (mean=-0.000002, std=0.000009)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000054), db (mean=-0.000000, std=0.000009)\n",
            "\n",
            "Epoch 176, Batch 10/10\n",
            "  Loss: 0.000030\n",
            "  y_pred (first sample): [2.30320383e-14 1.00000000e+00 1.46794683e-12 9.08907851e-12\n",
            " 7.43341101e-24 1.09608502e-11 9.41528357e-12]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000039), db (mean=-0.000002, std=0.000024)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000024), db (mean=-0.000001, std=0.000013)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000078), db (mean=-0.000001, std=0.000014)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000136), db (mean=0.000000, std=0.000013)\n",
            "\n",
            "Epoch 177, Batch 1/10\n",
            "  Loss: 0.000007\n",
            "  y_pred (first sample): [1.73473575e-14 9.99999999e-01 1.19595853e-12 4.25785883e-10\n",
            " 1.23821014e-21 5.02414825e-13 2.96271888e-10]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000005), db (mean=-0.000001, std=0.000007)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000004), db (mean=-0.000000, std=0.000003)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000011), db (mean=-0.000001, std=0.000003)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000017), db (mean=-0.000000, std=0.000002)\n",
            "\n",
            "Epoch 177, Batch 2/10\n",
            "  Loss: 0.000004\n",
            "  y_pred (first sample): [9.99988683e-01 2.15429871e-23 1.13171051e-05 4.38679642e-16\n",
            " 1.10451565e-23 9.24523542e-11 2.58737981e-26]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000002), db (mean=-0.000001, std=0.000003)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000007), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000015), db (mean=0.000000, std=0.000001)\n",
            "\n",
            "Epoch 177, Batch 3/10\n",
            "  Loss: 0.000029\n",
            "  y_pred (first sample): [7.83832855e-06 9.86597155e-07 1.64211980e-12 9.99991175e-01\n",
            " 1.93258752e-13 2.48363969e-10 2.15826321e-13]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000013), db (mean=-0.000003, std=0.000019)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000013), db (mean=0.000001, std=0.000010)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000036), db (mean=-0.000003, std=0.000009)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000089), db (mean=0.000000, std=0.000011)\n",
            "\n",
            "Epoch 177, Batch 4/10\n",
            "  Loss: 0.000076\n",
            "  y_pred (first sample): [6.93919519e-18 9.99998820e-01 4.49607381e-13 9.56004934e-13\n",
            " 1.21405241e-18 1.51597210e-10 1.17996731e-06]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000024), db (mean=0.000001, std=0.000030)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000021), db (mean=-0.000002, std=0.000020)\n",
            "    Layer 2: dW (mean=-0.000010, std=0.000084), db (mean=-0.000005, std=0.000024)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000168), db (mean=0.000000, std=0.000026)\n",
            "\n",
            "Epoch 177, Batch 5/10\n",
            "  Loss: 0.000004\n",
            "  y_pred (first sample): [1.10187370e-16 9.99999748e-01 1.43850228e-12 5.50714799e-12\n",
            " 6.33570290e-19 7.37886095e-11 2.52121689e-07]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000003), db (mean=-0.000001, std=0.000003)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000003), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000009), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000021), db (mean=0.000000, std=0.000002)\n",
            "\n",
            "Epoch 177, Batch 6/10\n",
            "  Loss: 0.000060\n",
            "  y_pred (first sample): [7.08986081e-12 9.99999972e-01 4.13138860e-09 1.46528397e-10\n",
            " 1.37448547e-19 2.23600167e-08 1.43752723e-09]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000027), db (mean=-0.000003, std=0.000026)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000017), db (mean=-0.000001, std=0.000013)\n",
            "    Layer 2: dW (mean=0.000003, std=0.000054), db (mean=0.000001, std=0.000012)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000104), db (mean=0.000000, std=0.000012)\n",
            "\n",
            "Epoch 177, Batch 7/10\n",
            "  Loss: 0.000053\n",
            "  y_pred (first sample): [1.18908671e-14 9.46065358e-11 3.65091376e-05 1.32530135e-16\n",
            " 3.84208787e-05 9.99797518e-01 1.27551988e-04]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000042), db (mean=-0.000001, std=0.000022)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000021), db (mean=-0.000001, std=0.000010)\n",
            "    Layer 2: dW (mean=-0.000009, std=0.000057), db (mean=-0.000002, std=0.000009)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000101), db (mean=0.000000, std=0.000008)\n",
            "\n",
            "Epoch 177, Batch 8/10\n",
            "  Loss: 0.000005\n",
            "  y_pred (first sample): [9.99999906e-01 1.35519381e-22 9.43172714e-08 1.30808540e-15\n",
            " 2.54178111e-26 8.74521233e-12 3.22089259e-27]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000005), db (mean=-0.000000, std=0.000007)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000004), db (mean=0.000000, std=0.000003)\n",
            "    Layer 2: dW (mean=-0.000000, std=0.000010), db (mean=0.000000, std=0.000003)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000015), db (mean=0.000000, std=0.000002)\n",
            "\n",
            "Epoch 177, Batch 9/10\n",
            "  Loss: 0.000067\n",
            "  y_pred (first sample): [9.99999416e-01 1.45725890e-23 5.83580478e-07 5.08498219e-16\n",
            " 3.69558523e-25 9.70047090e-12 5.56452199e-27]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000038), db (mean=-0.000005, std=0.000029)\n",
            "    Layer 1: dW (mean=-0.000003, std=0.000020), db (mean=-0.000004, std=0.000009)\n",
            "    Layer 2: dW (mean=-0.000009, std=0.000055), db (mean=-0.000004, std=0.000008)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000100), db (mean=0.000000, std=0.000008)\n",
            "\n",
            "Epoch 177, Batch 10/10\n",
            "  Loss: 0.000039\n",
            "  y_pred (first sample): [6.43907962e-07 9.77959834e-19 9.99891221e-01 8.22239504e-15\n",
            " 2.97157930e-05 7.84197662e-05 1.40931310e-11]\n",
            "  y_true (first sample): [0. 0. 1. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000025), db (mean=0.000002, std=0.000021)\n",
            "    Layer 1: dW (mean=0.000002, std=0.000017), db (mean=0.000002, std=0.000011)\n",
            "    Layer 2: dW (mean=0.000010, std=0.000053), db (mean=0.000003, std=0.000010)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000097), db (mean=-0.000000, std=0.000010)\n",
            "\n",
            "Epoch 178, Batch 1/10\n",
            "  Loss: 0.000039\n",
            "  y_pred (first sample): [9.99999090e-01 1.56336616e-25 9.09727408e-07 1.89973311e-17\n",
            " 2.20891857e-26 3.46444881e-12 7.58132873e-29]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000009), db (mean=-0.000004, std=0.000013)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000008), db (mean=-0.000002, std=0.000007)\n",
            "    Layer 2: dW (mean=-0.000005, std=0.000028), db (mean=-0.000002, std=0.000007)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000081), db (mean=-0.000000, std=0.000011)\n",
            "\n",
            "Epoch 178, Batch 2/10\n",
            "  Loss: 0.000056\n",
            "  y_pred (first sample): [2.13284452e-09 9.99999969e-01 1.31197303e-08 1.55465028e-08\n",
            " 2.09243507e-21 4.01426827e-10 7.52930454e-12]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000022), db (mean=-0.000002, std=0.000016)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000018), db (mean=-0.000001, std=0.000013)\n",
            "    Layer 2: dW (mean=-0.000008, std=0.000071), db (mean=-0.000004, std=0.000018)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000135), db (mean=-0.000000, std=0.000019)\n",
            "\n",
            "Epoch 178, Batch 3/10\n",
            "  Loss: 0.000034\n",
            "  y_pred (first sample): [9.99999942e-01 3.40589252e-25 5.79048384e-08 3.29557944e-17\n",
            " 2.12315919e-28 1.09655672e-12 4.91469138e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000010), db (mean=-0.000002, std=0.000021)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000009), db (mean=-0.000001, std=0.000011)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000029), db (mean=-0.000001, std=0.000008)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000074), db (mean=0.000000, std=0.000012)\n",
            "\n",
            "Epoch 178, Batch 4/10\n",
            "  Loss: 0.000016\n",
            "  y_pred (first sample): [9.99999906e-01 1.32825518e-22 9.40418744e-08 1.28839610e-15\n",
            " 2.46411863e-26 8.59865972e-12 3.13241507e-27]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000004), db (mean=-0.000002, std=0.000002)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000003), db (mean=-0.000001, std=0.000001)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000008), db (mean=-0.000001, std=0.000001)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000043), db (mean=-0.000000, std=0.000005)\n",
            "\n",
            "Epoch 178, Batch 5/10\n",
            "  Loss: 0.000005\n",
            "  y_pred (first sample): [9.99999088e-01 1.53465260e-25 9.12458103e-07 1.87537962e-17\n",
            " 2.17084631e-26 3.41906737e-12 7.44072572e-29]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000005), db (mean=-0.000000, std=0.000007)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000004), db (mean=0.000000, std=0.000003)\n",
            "    Layer 2: dW (mean=0.000000, std=0.000010), db (mean=0.000000, std=0.000003)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000015), db (mean=-0.000000, std=0.000002)\n",
            "\n",
            "Epoch 178, Batch 6/10\n",
            "  Loss: 0.000028\n",
            "  y_pred (first sample): [9.99999403e-01 4.73601143e-27 5.97236470e-07 1.81746463e-18\n",
            " 1.03956636e-27 9.26585193e-13 1.73671549e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000031), db (mean=-0.000004, std=0.000020)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000021), db (mean=-0.000001, std=0.000012)\n",
            "    Layer 2: dW (mean=-0.000005, std=0.000067), db (mean=-0.000001, std=0.000013)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000118), db (mean=0.000000, std=0.000012)\n",
            "\n",
            "Epoch 178, Batch 7/10\n",
            "  Loss: 0.000063\n",
            "  y_pred (first sample): [3.70876378e-08 9.99995628e-01 3.81815588e-06 3.42940002e-07\n",
            " 5.16668135e-15 7.60302191e-08 9.74346173e-08]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000018), db (mean=0.000002, std=0.000016)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000013), db (mean=-0.000000, std=0.000006)\n",
            "    Layer 2: dW (mean=0.000004, std=0.000048), db (mean=-0.000001, std=0.000008)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000068), db (mean=0.000000, std=0.000010)\n",
            "\n",
            "Epoch 178, Batch 8/10\n",
            "  Loss: 0.000033\n",
            "  y_pred (first sample): [6.75239333e-18 9.99998825e-01 4.37170752e-13 9.54059049e-13\n",
            " 1.16390631e-18 1.47963937e-10 1.17522353e-06]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000023), db (mean=-0.000001, std=0.000020)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000013), db (mean=0.000000, std=0.000009)\n",
            "    Layer 2: dW (mean=0.000004, std=0.000050), db (mean=0.000001, std=0.000011)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000106), db (mean=0.000000, std=0.000013)\n",
            "\n",
            "Epoch 178, Batch 9/10\n",
            "  Loss: 0.000005\n",
            "  y_pred (first sample): [7.14607745e-10 9.99982186e-01 2.72143305e-06 9.35517515e-09\n",
            " 3.45093000e-13 3.50977807e-06 1.15722378e-05]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000005), db (mean=-0.000001, std=0.000005)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000003), db (mean=-0.000000, std=0.000003)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000010), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000019), db (mean=-0.000000, std=0.000002)\n",
            "\n",
            "Epoch 178, Batch 10/10\n",
            "  Loss: 0.000061\n",
            "  y_pred (first sample): [1.57165229e-10 2.00994594e-08 8.58024724e-06 3.51963255e-15\n",
            " 5.68422354e-15 9.99991399e-01 1.20090583e-10]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000037), db (mean=-0.000003, std=0.000019)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000016), db (mean=-0.000001, std=0.000008)\n",
            "    Layer 2: dW (mean=-0.000009, std=0.000045), db (mean=-0.000002, std=0.000007)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000092), db (mean=-0.000000, std=0.000007)\n",
            "\n",
            "Epoch 179, Batch 1/10\n",
            "  Loss: 0.000056\n",
            "  y_pred (first sample): [2.28691828e-14 1.00000000e+00 1.42866201e-12 9.11336588e-12\n",
            " 6.81110918e-24 1.05182906e-11 9.06213369e-12]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000039), db (mean=-0.000003, std=0.000017)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000017), db (mean=-0.000002, std=0.000007)\n",
            "    Layer 2: dW (mean=-0.000012, std=0.000044), db (mean=-0.000003, std=0.000006)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000070), db (mean=0.000000, std=0.000004)\n",
            "\n",
            "Epoch 179, Batch 2/10\n",
            "  Loss: 0.000024\n",
            "  y_pred (first sample): [1.55099614e-05 7.90638187e-07 2.84186830e-11 9.99983696e-01\n",
            " 6.87781109e-12 2.93301084e-09 2.15040067e-12]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000006), db (mean=-0.000000, std=0.000018)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000007), db (mean=-0.000001, std=0.000009)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000021), db (mean=-0.000001, std=0.000007)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000055), db (mean=-0.000000, std=0.000010)\n",
            "\n",
            "Epoch 179, Batch 3/10\n",
            "  Loss: 0.000032\n",
            "  y_pred (first sample): [9.99999096e-01 1.48419186e-25 9.04334325e-07 1.83044146e-17\n",
            " 2.07251494e-26 3.33778909e-12 7.11458773e-29]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000035), db (mean=-0.000002, std=0.000023)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000021), db (mean=-0.000002, std=0.000012)\n",
            "    Layer 2: dW (mean=-0.000005, std=0.000067), db (mean=-0.000002, std=0.000013)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000118), db (mean=0.000000, std=0.000012)\n",
            "\n",
            "Epoch 179, Batch 4/10\n",
            "  Loss: 0.000017\n",
            "  y_pred (first sample): [2.87255892e-12 9.99999995e-01 5.35632367e-10 1.51001608e-10\n",
            " 3.99519104e-20 3.83650898e-09 7.71680172e-10]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000019), db (mean=-0.000001, std=0.000016)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000011), db (mean=0.000001, std=0.000007)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000025), db (mean=-0.000001, std=0.000005)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000058), db (mean=0.000000, std=0.000006)\n",
            "\n",
            "Epoch 179, Batch 5/10\n",
            "  Loss: 0.000052\n",
            "  y_pred (first sample): [9.99999413e-01 4.56058370e-27 5.87283909e-07 1.76447061e-18\n",
            " 9.70812660e-28 9.01018792e-13 1.63246004e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000011), db (mean=-0.000005, std=0.000015)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000009), db (mean=-0.000001, std=0.000006)\n",
            "    Layer 2: dW (mean=-0.000008, std=0.000033), db (mean=-0.000004, std=0.000007)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000110), db (mean=-0.000000, std=0.000017)\n",
            "\n",
            "Epoch 179, Batch 6/10\n",
            "  Loss: 0.000017\n",
            "  y_pred (first sample): [1.54280465e-10 1.99462466e-08 8.26864683e-06 3.48137514e-15\n",
            " 5.39025916e-15 9.99991711e-01 1.16372797e-10]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000024), db (mean=0.000002, std=0.000019)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000014), db (mean=0.000000, std=0.000009)\n",
            "    Layer 2: dW (mean=0.000005, std=0.000041), db (mean=0.000001, std=0.000008)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000075), db (mean=0.000000, std=0.000008)\n",
            "\n",
            "Epoch 179, Batch 7/10\n",
            "  Loss: 0.000025\n",
            "  y_pred (first sample): [1.16669050e-14 5.03996893e-05 5.37416187e-08 5.96857283e-12\n",
            " 7.22523961e-05 5.00188862e-05 9.99827275e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000007), db (mean=-0.000001, std=0.000017)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000007), db (mean=-0.000001, std=0.000009)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000022), db (mean=-0.000002, std=0.000007)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000058), db (mean=-0.000000, std=0.000010)\n",
            "\n",
            "Epoch 179, Batch 8/10\n",
            "  Loss: 0.000060\n",
            "  y_pred (first sample): [4.12809415e-05 3.23328084e-11 9.99762130e-01 5.32664783e-11\n",
            " 2.20573036e-08 1.96565937e-04 6.61831283e-10]\n",
            "  y_true (first sample): [0. 0. 1. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000003, std=0.000024), db (mean=-0.000006, std=0.000025)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000018), db (mean=-0.000001, std=0.000014)\n",
            "    Layer 2: dW (mean=-0.000007, std=0.000072), db (mean=-0.000003, std=0.000018)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000185), db (mean=-0.000000, std=0.000024)\n",
            "\n",
            "Epoch 179, Batch 9/10\n",
            "  Loss: 0.000009\n",
            "  y_pred (first sample): [9.99958135e-01 4.06996364e-17 4.18648062e-05 4.50585562e-12\n",
            " 1.93064148e-23 2.87103187e-10 7.88103696e-24]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000011), db (mean=-0.000001, std=0.000008)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000008), db (mean=0.000000, std=0.000004)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000027), db (mean=-0.000000, std=0.000005)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000051), db (mean=0.000000, std=0.000004)\n",
            "\n",
            "Epoch 179, Batch 10/10\n",
            "  Loss: 0.000042\n",
            "  y_pred (first sample): [7.89666346e-14 2.95536146e-15 9.50669032e-05 5.69714095e-15\n",
            " 9.99765911e-01 7.26475997e-05 6.63741120e-05]\n",
            "  y_true (first sample): [0. 0. 0. 0. 1. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000024), db (mean=-0.000002, std=0.000020)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000015), db (mean=0.000000, std=0.000010)\n",
            "    Layer 2: dW (mean=0.000002, std=0.000056), db (mean=0.000001, std=0.000012)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000139), db (mean=0.000000, std=0.000017)\n",
            "\n",
            "Epoch 180, Batch 1/10\n",
            "  Loss: 0.000029\n",
            "  y_pred (first sample): [6.69384917e-12 9.99999973e-01 3.98330028e-09 1.40744979e-10\n",
            " 1.26752602e-19 2.19367809e-08 1.42758844e-09]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000007), db (mean=-0.000003, std=0.000020)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000008), db (mean=-0.000002, std=0.000011)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000024), db (mean=-0.000002, std=0.000009)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000063), db (mean=0.000000, std=0.000011)\n",
            "\n",
            "Epoch 180, Batch 2/10\n",
            "  Loss: 0.000033\n",
            "  y_pred (first sample): [6.38299275e-18 9.99998813e-01 4.14282528e-13 9.46019368e-13\n",
            " 1.12406484e-18 1.46002261e-10 1.18701289e-06]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000020), db (mean=-0.000003, std=0.000017)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000016), db (mean=-0.000000, std=0.000011)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000064), db (mean=-0.000002, std=0.000015)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000116), db (mean=-0.000000, std=0.000014)\n",
            "\n",
            "Epoch 180, Batch 3/10\n",
            "  Loss: 0.000027\n",
            "  y_pred (first sample): [6.73683666e-32 3.48918863e-13 5.75800069e-17 2.16465458e-26\n",
            " 6.43732030e-07 4.07147314e-08 9.99999316e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000050), db (mean=0.000000, std=0.000025)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000025), db (mean=-0.000000, std=0.000012)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000062), db (mean=-0.000002, std=0.000009)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000106), db (mean=0.000000, std=0.000008)\n",
            "\n",
            "Epoch 180, Batch 4/10\n",
            "  Loss: 0.000038\n",
            "  y_pred (first sample): [9.99996781e-01 2.87688183e-25 3.21907345e-06 1.93669161e-17\n",
            " 1.29607071e-25 9.49295323e-12 2.90007377e-28]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000043), db (mean=-0.000003, std=0.000031)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000027), db (mean=-0.000000, std=0.000017)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000072), db (mean=-0.000001, std=0.000014)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000103), db (mean=-0.000000, std=0.000009)\n",
            "\n",
            "Epoch 180, Batch 5/10\n",
            "  Loss: 0.000033\n",
            "  y_pred (first sample): [1.12994316e-14 4.98502148e-05 5.28064342e-08 5.82411127e-12\n",
            " 7.11694448e-05 4.90658269e-05 9.99829862e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000007), db (mean=-0.000001, std=0.000015)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000006), db (mean=-0.000001, std=0.000007)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000020), db (mean=-0.000002, std=0.000007)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000053), db (mean=-0.000000, std=0.000008)\n",
            "\n",
            "Epoch 180, Batch 6/10\n",
            "  Loss: 0.000007\n",
            "  y_pred (first sample): [9.99999416e-01 4.38926311e-27 5.83624625e-07 1.71581947e-18\n",
            " 9.14903902e-28 8.68934632e-13 1.54897257e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000005), db (mean=-0.000001, std=0.000006)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000004), db (mean=-0.000000, std=0.000003)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000012), db (mean=-0.000001, std=0.000003)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000022), db (mean=0.000000, std=0.000002)\n",
            "\n",
            "Epoch 180, Batch 7/10\n",
            "  Loss: 0.000054\n",
            "  y_pred (first sample): [1.50001685e-05 7.93204049e-07 2.72790305e-11 9.99984204e-01\n",
            " 6.71509388e-12 2.90413312e-09 2.12827387e-12]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000010), db (mean=-0.000003, std=0.000017)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000007), db (mean=-0.000003, std=0.000008)\n",
            "    Layer 2: dW (mean=-0.000008, std=0.000027), db (mean=-0.000003, std=0.000008)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000099), db (mean=-0.000000, std=0.000012)\n",
            "\n",
            "Epoch 180, Batch 8/10\n",
            "  Loss: 0.000024\n",
            "  y_pred (first sample): [9.99957875e-01 4.07246680e-17 4.21249727e-05 4.52593395e-12\n",
            " 1.89247013e-23 2.78719804e-10 7.80551564e-24]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000010), db (mean=0.000001, std=0.000008)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000010), db (mean=-0.000000, std=0.000006)\n",
            "    Layer 2: dW (mean=0.000003, std=0.000044), db (mean=0.000001, std=0.000008)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000094), db (mean=0.000000, std=0.000010)\n",
            "\n",
            "Epoch 180, Batch 9/10\n",
            "  Loss: 0.000025\n",
            "  y_pred (first sample): [9.99999944e-01 3.14221323e-25 5.58191104e-08 3.09856673e-17\n",
            " 1.81192463e-28 1.00786268e-12 4.29925076e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000032), db (mean=-0.000003, std=0.000021)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000020), db (mean=-0.000001, std=0.000012)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000066), db (mean=-0.000001, std=0.000012)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000115), db (mean=-0.000000, std=0.000011)\n",
            "\n",
            "Epoch 180, Batch 10/10\n",
            "  Loss: 0.000062\n",
            "  y_pred (first sample): [9.99985354e-01 3.32789866e-24 1.46459440e-05 8.19316911e-15\n",
            " 7.56824236e-22 2.54368618e-11 5.12975365e-26]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000003, std=0.000017), db (mean=-0.000005, std=0.000026)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000018), db (mean=-0.000001, std=0.000015)\n",
            "    Layer 2: dW (mean=-0.000012, std=0.000051), db (mean=-0.000005, std=0.000013)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000156), db (mean=0.000000, std=0.000020)\n",
            "\n",
            "Epoch 181, Batch 1/10\n",
            "  Loss: 0.000044\n",
            "  y_pred (first sample): [2.80809121e-12 9.99999995e-01 5.18108983e-10 1.49280079e-10\n",
            " 3.67728907e-20 3.66346643e-09 7.47411861e-10]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000003, std=0.000036), db (mean=-0.000005, std=0.000024)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000023), db (mean=-0.000002, std=0.000014)\n",
            "    Layer 2: dW (mean=-0.000008, std=0.000067), db (mean=-0.000002, std=0.000012)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000126), db (mean=-0.000000, std=0.000013)\n",
            "\n",
            "Epoch 181, Batch 2/10\n",
            "  Loss: 0.000015\n",
            "  y_pred (first sample): [6.23303226e-07 8.98440633e-19 9.99892883e-01 7.86244278e-15\n",
            " 2.91333916e-05 7.73599154e-05 1.34098964e-11]\n",
            "  y_true (first sample): [0. 0. 1. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000018), db (mean=-0.000001, std=0.000015)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000010), db (mean=0.000001, std=0.000007)\n",
            "    Layer 2: dW (mean=-0.000000, std=0.000023), db (mean=-0.000000, std=0.000005)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000058), db (mean=-0.000000, std=0.000006)\n",
            "\n",
            "Epoch 181, Batch 3/10\n",
            "  Loss: 0.000020\n",
            "  y_pred (first sample): [1.11551501e-06 2.34053234e-07 1.76448055e-14 9.99998650e-01\n",
            " 1.68482146e-15 8.82882547e-12 3.40933201e-15]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000000, std=0.000011), db (mean=0.000001, std=0.000010)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000009), db (mean=-0.000001, std=0.000005)\n",
            "    Layer 2: dW (mean=0.000003, std=0.000037), db (mean=0.000001, std=0.000007)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000076), db (mean=-0.000000, std=0.000008)\n",
            "\n",
            "Epoch 181, Batch 4/10\n",
            "  Loss: 0.000025\n",
            "  y_pred (first sample): [1.49762923e-05 7.85856359e-07 2.73877518e-11 9.99984235e-01\n",
            " 6.76597209e-12 2.91545006e-09 2.12294960e-12]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000006), db (mean=0.000000, std=0.000018)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000007), db (mean=-0.000001, std=0.000009)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000021), db (mean=-0.000002, std=0.000007)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000053), db (mean=-0.000000, std=0.000009)\n",
            "\n",
            "Epoch 181, Batch 5/10\n",
            "  Loss: 0.000050\n",
            "  y_pred (first sample): [6.78612569e-31 1.96988417e-12 1.91992131e-17 8.05811322e-25\n",
            " 7.77750081e-07 3.23739082e-08 9.99999190e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000062), db (mean=0.000001, std=0.000036)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000032), db (mean=0.000000, std=0.000017)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000096), db (mean=0.000000, std=0.000017)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000135), db (mean=0.000000, std=0.000013)\n",
            "\n",
            "Epoch 181, Batch 6/10\n",
            "  Loss: 0.000001\n",
            "  y_pred (first sample): [9.99999909e-01 1.19791504e-22 9.07298267e-08 1.18875219e-15\n",
            " 2.06539992e-26 7.84607326e-12 2.67961675e-27]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000001), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000001), db (mean=0.000000, std=0.000001)\n",
            "    Layer 2: dW (mean=-0.000000, std=0.000003), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000006), db (mean=0.000000, std=0.000001)\n",
            "\n",
            "Epoch 181, Batch 7/10\n",
            "  Loss: 0.000056\n",
            "  y_pred (first sample): [9.99995188e-01 3.38194620e-15 2.62659180e-08 4.78584732e-06\n",
            " 1.04491210e-17 1.87050901e-10 1.85131835e-19]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000013), db (mean=-0.000003, std=0.000037)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000013), db (mean=-0.000002, std=0.000020)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000041), db (mean=-0.000003, std=0.000016)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000107), db (mean=0.000000, std=0.000020)\n",
            "\n",
            "Epoch 181, Batch 8/10\n",
            "  Loss: 0.000063\n",
            "  y_pred (first sample): [6.92001033e-10 9.99982971e-01 2.59084889e-06 9.20880180e-09\n",
            " 3.09732895e-13 3.33453294e-06 1.10932341e-05]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000003, std=0.000024), db (mean=-0.000005, std=0.000024)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000018), db (mean=-0.000001, std=0.000013)\n",
            "    Layer 2: dW (mean=-0.000007, std=0.000067), db (mean=-0.000003, std=0.000016)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000164), db (mean=-0.000000, std=0.000022)\n",
            "\n",
            "Epoch 181, Batch 9/10\n",
            "  Loss: 0.000028\n",
            "  y_pred (first sample): [9.99999558e-01 5.92916551e-23 4.41944919e-07 7.67928378e-16\n",
            " 5.40708293e-26 2.18325429e-11 1.50249744e-27]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000011), db (mean=-0.000002, std=0.000016)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000011), db (mean=0.000001, std=0.000008)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000031), db (mean=-0.000003, std=0.000007)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000074), db (mean=0.000000, std=0.000009)\n",
            "\n",
            "Epoch 181, Batch 10/10\n",
            "  Loss: 0.000027\n",
            "  y_pred (first sample): [1.39934651e-08 9.99999908e-01 5.44644507e-08 2.22819811e-08\n",
            " 1.13672874e-21 8.86363705e-10 4.62828397e-12]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000031), db (mean=-0.000003, std=0.000020)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000020), db (mean=-0.000001, std=0.000012)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000064), db (mean=-0.000001, std=0.000012)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000112), db (mean=-0.000000, std=0.000011)\n",
            "\n",
            "=== Epoch 181 Summary ===\n",
            "Average Batch Loss: 0.000033\n",
            "Full Dataset Loss: 0.000032\n",
            "Final y_pred sample: [7.00346400e-14 2.59478394e-15 9.13670569e-05 5.02698011e-15\n",
            " 9.99775276e-01 6.95984827e-05 6.37586421e-05]\n",
            "Final y_true sample: [0. 0. 0. 0. 1. 0. 0.]\n",
            "\n",
            "Epoch 182, Batch 1/10\n",
            "  Loss: 0.000057\n",
            "  y_pred (first sample): [7.48665018e-06 9.26151416e-07 1.48017368e-12 9.99991587e-01\n",
            " 1.72654782e-13 2.27530331e-10 1.89813275e-13]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000011), db (mean=-0.000003, std=0.000034)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000012), db (mean=-0.000002, std=0.000018)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000042), db (mean=-0.000003, std=0.000015)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000106), db (mean=-0.000000, std=0.000019)\n",
            "\n",
            "Epoch 182, Batch 2/10\n",
            "  Loss: 0.000003\n",
            "  y_pred (first sample): [2.82962709e-12 9.99999995e-01 5.16023837e-10 1.50222223e-10\n",
            " 3.56512255e-20 3.65037301e-09 7.35476139e-10]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000004), db (mean=-0.000000, std=0.000005)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000003), db (mean=0.000000, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000000, std=0.000008), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000010), db (mean=-0.000000, std=0.000001)\n",
            "\n",
            "Epoch 182, Batch 3/10\n",
            "  Loss: 0.000028\n",
            "  y_pred (first sample): [1.25868645e-12 9.99994539e-01 4.58020337e-10 6.92358356e-08\n",
            " 1.14633044e-14 2.04147690e-10 5.39064279e-06]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000031), db (mean=-0.000003, std=0.000020)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000020), db (mean=-0.000002, std=0.000012)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000063), db (mean=-0.000001, std=0.000012)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000111), db (mean=-0.000000, std=0.000011)\n",
            "\n",
            "Epoch 182, Batch 4/10\n",
            "  Loss: 0.000027\n",
            "  y_pred (first sample): [1.59088921e-14 9.99999999e-01 1.06243724e-12 4.25921050e-10\n",
            " 1.02568013e-21 4.53574816e-13 2.82278651e-10]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000030), db (mean=-0.000003, std=0.000019)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000019), db (mean=-0.000002, std=0.000011)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000063), db (mean=-0.000001, std=0.000012)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000110), db (mean=-0.000000, std=0.000011)\n",
            "\n",
            "Epoch 182, Batch 5/10\n",
            "  Loss: 0.000061\n",
            "  y_pred (first sample): [4.04797397e-06 2.67397972e-08 1.70157547e-13 9.99995925e-01\n",
            " 9.57984590e-15 1.63017532e-11 1.80175330e-15]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000037), db (mean=-0.000003, std=0.000032)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000024), db (mean=0.000000, std=0.000017)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000086), db (mean=-0.000000, std=0.000020)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000139), db (mean=0.000000, std=0.000017)\n",
            "\n",
            "Epoch 182, Batch 6/10\n",
            "  Loss: 0.000004\n",
            "  y_pred (first sample): [1.10000640e-06 2.30857687e-07 1.71187910e-14 9.99998669e-01\n",
            " 1.63266737e-15 8.62600039e-12 3.29955452e-15]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000003), db (mean=-0.000000, std=0.000003)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000003), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000010), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000023), db (mean=0.000000, std=0.000002)\n",
            "\n",
            "Epoch 182, Batch 7/10\n",
            "  Loss: 0.000046\n",
            "  y_pred (first sample): [1.31722144e-25 5.85507140e-12 5.65877896e-11 2.53434550e-23\n",
            " 5.98624382e-05 1.05029365e-04 9.99835108e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000037), db (mean=-0.000001, std=0.000013)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000019), db (mean=-0.000000, std=0.000007)\n",
            "    Layer 2: dW (mean=-0.000008, std=0.000063), db (mean=-0.000002, std=0.000008)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000139), db (mean=0.000000, std=0.000012)\n",
            "\n",
            "Epoch 182, Batch 8/10\n",
            "  Loss: 0.000038\n",
            "  y_pred (first sample): [9.99995227e-01 3.30880151e-15 2.59053020e-08 4.74652674e-06\n",
            " 1.00045191e-17 1.82582033e-10 1.77708350e-19]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000022), db (mean=0.000001, std=0.000015)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000013), db (mean=0.000001, std=0.000007)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000030), db (mean=-0.000002, std=0.000005)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000056), db (mean=0.000000, std=0.000004)\n",
            "\n",
            "Epoch 182, Batch 9/10\n",
            "  Loss: 0.000023\n",
            "  y_pred (first sample): [9.99999436e-01 3.89414172e-27 5.64100834e-07 1.56640069e-18\n",
            " 7.64494907e-28 7.97208551e-13 1.30659152e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000007), db (mean=0.000000, std=0.000017)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000007), db (mean=-0.000001, std=0.000009)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000021), db (mean=-0.000002, std=0.000007)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000049), db (mean=0.000000, std=0.000009)\n",
            "\n",
            "Epoch 182, Batch 10/10\n",
            "  Loss: 0.000035\n",
            "  y_pred (first sample): [9.99959606e-01 3.60759582e-17 4.03938134e-05 4.18539172e-12\n",
            " 1.60776756e-23 2.62068426e-10 6.63539090e-24]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000011), db (mean=-0.000003, std=0.000011)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000009), db (mean=-0.000001, std=0.000006)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000028), db (mean=-0.000001, std=0.000006)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000062), db (mean=0.000000, std=0.000008)\n",
            "\n",
            "Epoch 183, Batch 1/10\n",
            "  Loss: 0.000031\n",
            "  y_pred (first sample): [9.99999138e-01 1.27361254e-25 8.62279351e-07 1.63009687e-17\n",
            " 1.61408163e-26 2.93883987e-12 5.67963150e-29]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000000, std=0.000048), db (mean=0.000000, std=0.000023)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000025), db (mean=-0.000001, std=0.000011)\n",
            "    Layer 2: dW (mean=-0.000008, std=0.000066), db (mean=-0.000002, std=0.000009)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000111), db (mean=0.000000, std=0.000009)\n",
            "\n",
            "Epoch 183, Batch 2/10\n",
            "  Loss: 0.000057\n",
            "  y_pred (first sample): [1.05228084e-14 4.82340268e-05 5.12488495e-08 5.45168014e-12\n",
            " 6.91662736e-05 4.80745754e-05 9.99834474e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000010), db (mean=-0.000003, std=0.000018)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000008), db (mean=-0.000002, std=0.000008)\n",
            "    Layer 2: dW (mean=-0.000007, std=0.000030), db (mean=-0.000003, std=0.000008)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000082), db (mean=-0.000000, std=0.000013)\n",
            "\n",
            "Epoch 183, Batch 3/10\n",
            "  Loss: 0.000006\n",
            "  y_pred (first sample): [7.37363012e-06 9.11529149e-07 1.43215413e-12 9.99991715e-01\n",
            " 1.66673636e-13 2.21606104e-10 1.83011415e-13]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000003), db (mean=-0.000001, std=0.000004)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000003), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000009), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000018), db (mean=-0.000000, std=0.000002)\n",
            "\n",
            "Epoch 183, Batch 4/10\n",
            "  Loss: 0.000053\n",
            "  y_pred (first sample): [9.99999946e-01 2.85758490e-25 5.38130336e-08 2.87570460e-17\n",
            " 1.51725770e-28 9.28776427e-13 3.69650692e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000024), db (mean=-0.000002, std=0.000021)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000015), db (mean=0.000001, std=0.000010)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000042), db (mean=-0.000002, std=0.000008)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000079), db (mean=-0.000000, std=0.000008)\n",
            "\n",
            "Epoch 183, Batch 5/10\n",
            "  Loss: 0.000019\n",
            "  y_pred (first sample): [6.74603899e-10 9.99983389e-01 2.52704376e-06 9.06741936e-09\n",
            " 2.90251979e-13 3.20676157e-06 1.08672088e-05]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000015), db (mean=0.000002, std=0.000013)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000011), db (mean=-0.000000, std=0.000006)\n",
            "    Layer 2: dW (mean=0.000011, std=0.000046), db (mean=0.000003, std=0.000008)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000069), db (mean=-0.000000, std=0.000008)\n",
            "\n",
            "Epoch 183, Batch 6/10\n",
            "  Loss: 0.000025\n",
            "  y_pred (first sample): [2.16432884e-14 1.00000000e+00 1.29896087e-12 8.93624615e-12\n",
            " 5.46368991e-24 9.43046091e-12 8.32671736e-12]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000006), db (mean=0.000000, std=0.000015)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000006), db (mean=-0.000001, std=0.000007)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000016), db (mean=-0.000001, std=0.000006)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000046), db (mean=-0.000000, std=0.000008)\n",
            "\n",
            "Epoch 183, Batch 7/10\n",
            "  Loss: 0.000053\n",
            "  y_pred (first sample): [2.15624051e-14 1.00000000e+00 1.29424484e-12 8.92158990e-12\n",
            " 5.44507617e-24 9.39990837e-12 8.32922415e-12]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000039), db (mean=-0.000004, std=0.000027)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000022), db (mean=-0.000002, std=0.000013)\n",
            "    Layer 2: dW (mean=-0.000009, std=0.000059), db (mean=-0.000003, std=0.000011)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000111), db (mean=-0.000000, std=0.000011)\n",
            "\n",
            "Epoch 183, Batch 8/10\n",
            "  Loss: 0.000028\n",
            "  y_pred (first sample): [1.08708155e-06 2.28155889e-07 1.66866328e-14 9.99998685e-01\n",
            " 1.58992831e-15 8.45352537e-12 3.20982758e-15]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000007), db (mean=-0.000004, std=0.000019)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000007), db (mean=-0.000002, std=0.000010)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000023), db (mean=-0.000002, std=0.000008)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000059), db (mean=-0.000000, std=0.000011)\n",
            "\n",
            "Epoch 183, Batch 9/10\n",
            "  Loss: 0.000029\n",
            "  y_pred (first sample): [1.24430995e-05 2.41961492e-09 7.24873038e-13 9.99987554e-01\n",
            " 1.91863868e-14 1.65770557e-11 4.39206593e-16]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000033), db (mean=-0.000002, std=0.000021)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000020), db (mean=-0.000001, std=0.000011)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000065), db (mean=-0.000001, std=0.000012)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000113), db (mean=0.000000, std=0.000011)\n",
            "\n",
            "Epoch 183, Batch 10/10\n",
            "  Loss: 0.000021\n",
            "  y_pred (first sample): [3.98533008e-06 2.60912355e-08 1.65746866e-13 9.99995989e-01\n",
            " 9.32716726e-15 1.58815807e-11 1.73086067e-15]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000025), db (mean=-0.000001, std=0.000021)\n",
            "    Layer 1: dW (mean=0.000002, std=0.000015), db (mean=0.000001, std=0.000009)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000036), db (mean=-0.000000, std=0.000007)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000059), db (mean=-0.000000, std=0.000005)\n",
            "\n",
            "Epoch 184, Batch 1/10\n",
            "  Loss: 0.000027\n",
            "  y_pred (first sample): [3.98591040e-06 2.60504506e-08 1.65484455e-13 9.99995988e-01\n",
            " 9.30257864e-15 1.58562497e-11 1.72595961e-15]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000032), db (mean=-0.000002, std=0.000020)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000020), db (mean=-0.000001, std=0.000011)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000066), db (mean=-0.000001, std=0.000012)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000116), db (mean=-0.000000, std=0.000011)\n",
            "\n",
            "Epoch 184, Batch 2/10\n",
            "  Loss: 0.000003\n",
            "  y_pred (first sample): [9.99999431e-01 3.65158631e-27 5.69218719e-07 1.50001193e-18\n",
            " 7.21364161e-28 7.69030479e-13 1.22653914e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000003)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000006), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000014), db (mean=-0.000000, std=0.000001)\n",
            "\n",
            "Epoch 184, Batch 3/10\n",
            "  Loss: 0.000061\n",
            "  y_pred (first sample): [1.15794652e-04 2.88486323e-17 9.99803259e-01 4.20276373e-12\n",
            " 7.84593164e-05 2.48740024e-06 4.66584210e-11]\n",
            "  y_true (first sample): [0. 0. 1. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000056), db (mean=-0.000002, std=0.000030)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000029), db (mean=-0.000002, std=0.000013)\n",
            "    Layer 2: dW (mean=-0.000011, std=0.000073), db (mean=-0.000003, std=0.000011)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000123), db (mean=-0.000000, std=0.000011)\n",
            "\n",
            "Epoch 184, Batch 4/10\n",
            "  Loss: 0.000027\n",
            "  y_pred (first sample): [2.76570750e-12 9.99999995e-01 4.98681894e-10 1.48665888e-10\n",
            " 3.25193658e-20 3.48347140e-09 7.09806678e-10]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000011), db (mean=-0.000002, std=0.000016)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000011), db (mean=0.000001, std=0.000008)\n",
            "    Layer 2: dW (mean=-0.000007, std=0.000031), db (mean=-0.000003, std=0.000007)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000074), db (mean=0.000000, std=0.000009)\n",
            "\n",
            "Epoch 184, Batch 5/10\n",
            "  Loss: 0.000038\n",
            "  y_pred (first sample): [5.24000542e-29 3.65790715e-11 1.18973644e-16 4.06511113e-23\n",
            " 5.64267270e-07 4.73630545e-08 9.99999388e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000018), db (mean=-0.000004, std=0.000015)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000009), db (mean=-0.000001, std=0.000005)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000026), db (mean=-0.000002, std=0.000006)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000090), db (mean=-0.000000, std=0.000014)\n",
            "\n",
            "Epoch 184, Batch 6/10\n",
            "  Loss: 0.000028\n",
            "  y_pred (first sample): [2.26617518e-17 3.78325345e-10 9.69377905e-07 9.89459649e-19\n",
            " 1.75786278e-08 9.99983960e-01 1.50524468e-05]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000031), db (mean=-0.000005, std=0.000020)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000022), db (mean=-0.000001, std=0.000013)\n",
            "    Layer 2: dW (mean=-0.000005, std=0.000070), db (mean=-0.000001, std=0.000013)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000122), db (mean=0.000000, std=0.000012)\n",
            "\n",
            "Epoch 184, Batch 7/10\n",
            "  Loss: 0.000038\n",
            "  y_pred (first sample): [6.20543855e-12 9.99999974e-01 3.81355485e-09 1.32757160e-10\n",
            " 1.09579092e-19 2.09706776e-08 1.39090952e-09]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000023), db (mean=-0.000002, std=0.000020)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000014), db (mean=-0.000000, std=0.000010)\n",
            "    Layer 2: dW (mean=0.000003, std=0.000053), db (mean=0.000001, std=0.000011)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000129), db (mean=0.000000, std=0.000015)\n",
            "\n",
            "Epoch 184, Batch 8/10\n",
            "  Loss: 0.000032\n",
            "  y_pred (first sample): [1.42773764e-05 7.85286991e-07 2.65800107e-11 9.99984934e-01\n",
            " 6.83400911e-12 2.96429645e-09 2.14797897e-12]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000006), db (mean=-0.000001, std=0.000016)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000006), db (mean=-0.000001, std=0.000008)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000019), db (mean=-0.000002, std=0.000006)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000050), db (mean=0.000000, std=0.000008)\n",
            "\n",
            "Epoch 184, Batch 9/10\n",
            "  Loss: 0.000027\n",
            "  y_pred (first sample): [9.99959684e-01 3.47971804e-17 4.03155312e-05 4.06779193e-12\n",
            " 1.48647126e-23 2.56844704e-10 6.28031307e-24]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000000, std=0.000009), db (mean=0.000001, std=0.000014)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000007), db (mean=-0.000000, std=0.000007)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000025), db (mean=-0.000001, std=0.000006)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000063), db (mean=0.000000, std=0.000009)\n",
            "\n",
            "Epoch 184, Batch 10/10\n",
            "  Loss: 0.000033\n",
            "  y_pred (first sample): [3.95100193e-05 2.87753900e-11 9.99773502e-01 4.69272494e-11\n",
            " 1.91168610e-08 1.86967903e-04 5.92805504e-10]\n",
            "  y_true (first sample): [0. 0. 1. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000019), db (mean=-0.000003, std=0.000015)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000016), db (mean=-0.000000, std=0.000011)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000061), db (mean=-0.000002, std=0.000014)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000112), db (mean=0.000000, std=0.000014)\n",
            "\n",
            "Epoch 185, Batch 1/10\n",
            "  Loss: 0.000004\n",
            "  y_pred (first sample): [9.99999983e-01 2.95714253e-26 1.71936516e-08 5.23344072e-18\n",
            " 4.47991928e-30 2.35228402e-13 1.45026602e-31]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000004), db (mean=-0.000000, std=0.000004)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000003), db (mean=0.000000, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000000, std=0.000008), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000013), db (mean=0.000000, std=0.000001)\n",
            "\n",
            "Epoch 185, Batch 2/10\n",
            "  Loss: 0.000050\n",
            "  y_pred (first sample): [6.70208680e-10 9.99983780e-01 2.48268545e-06 9.04795859e-09\n",
            " 2.74478375e-13 3.13671873e-06 1.05910701e-05]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000024), db (mean=-0.000002, std=0.000021)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000015), db (mean=0.000001, std=0.000010)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000040), db (mean=-0.000001, std=0.000007)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000082), db (mean=0.000000, std=0.000008)\n",
            "\n",
            "Epoch 185, Batch 3/10\n",
            "  Loss: 0.000069\n",
            "  y_pred (first sample): [9.57575996e-15 7.88209811e-11 3.21277269e-05 1.13923021e-16\n",
            " 3.42753431e-05 9.99820818e-01 1.12779027e-04]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000003, std=0.000061), db (mean=-0.000004, std=0.000037)\n",
            "    Layer 1: dW (mean=-0.000003, std=0.000038), db (mean=-0.000003, std=0.000017)\n",
            "    Layer 2: dW (mean=-0.000010, std=0.000116), db (mean=-0.000003, std=0.000018)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000205), db (mean=0.000000, std=0.000018)\n",
            "\n",
            "Epoch 185, Batch 4/10\n",
            "  Loss: 0.000047\n",
            "  y_pred (first sample): [1.30953582e-14 1.16640650e-17 1.00449767e-04 2.77353449e-16\n",
            " 9.99880243e-01 1.59460367e-05 3.36130596e-06]\n",
            "  y_true (first sample): [0. 0. 0. 0. 1. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000000, std=0.000018), db (mean=-0.000001, std=0.000016)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000012), db (mean=-0.000001, std=0.000007)\n",
            "    Layer 2: dW (mean=0.000002, std=0.000035), db (mean=0.000000, std=0.000006)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000051), db (mean=-0.000000, std=0.000005)\n",
            "\n",
            "Epoch 185, Batch 5/10\n",
            "  Loss: 0.000030\n",
            "  y_pred (first sample): [1.42357375e-05 7.76475030e-07 2.64756383e-11 9.99984985e-01\n",
            " 6.81180030e-12 2.95253974e-09 2.12273162e-12]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000021), db (mean=-0.000003, std=0.000017)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000016), db (mean=-0.000000, std=0.000011)\n",
            "    Layer 2: dW (mean=-0.000005, std=0.000062), db (mean=-0.000002, std=0.000014)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000114), db (mean=0.000000, std=0.000014)\n",
            "\n",
            "Epoch 185, Batch 6/10\n",
            "  Loss: 0.000029\n",
            "  y_pred (first sample): [9.99997439e-01 6.84483968e-21 2.56034887e-06 1.27069250e-14\n",
            " 1.76864272e-23 2.45633814e-10 8.37896176e-25]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000008), db (mean=-0.000002, std=0.000021)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000007), db (mean=-0.000002, std=0.000011)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000023), db (mean=-0.000002, std=0.000008)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000059), db (mean=-0.000000, std=0.000011)\n",
            "\n",
            "Epoch 185, Batch 7/10\n",
            "  Loss: 0.000045\n",
            "  y_pred (first sample): [4.00439866e-06 2.54168072e-08 1.62742318e-13 9.99995970e-01\n",
            " 9.00936220e-15 1.55581495e-11 1.65904313e-15]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000019), db (mean=-0.000002, std=0.000010)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000010), db (mean=-0.000000, std=0.000003)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000023), db (mean=-0.000002, std=0.000005)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000073), db (mean=-0.000000, std=0.000010)\n",
            "\n",
            "Epoch 185, Batch 8/10\n",
            "  Loss: 0.000031\n",
            "  y_pred (first sample): [9.99991943e-01 5.34748142e-25 8.05718288e-06 3.64584672e-17\n",
            " 3.88475162e-25 2.30015593e-11 4.09377059e-28]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000000, std=0.000048), db (mean=-0.000000, std=0.000024)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000025), db (mean=-0.000001, std=0.000012)\n",
            "    Layer 2: dW (mean=-0.000007, std=0.000066), db (mean=-0.000002, std=0.000010)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000111), db (mean=-0.000000, std=0.000009)\n",
            "\n",
            "Epoch 185, Batch 9/10\n",
            "  Loss: 0.000004\n",
            "  y_pred (first sample): [1.41915751e-05 7.73536494e-07 2.64515046e-11 9.99985032e-01\n",
            " 6.82096708e-12 2.95370488e-09 2.11828233e-12]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000003)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000004), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000010), db (mean=-0.000000, std=0.000001)\n",
            "\n",
            "Epoch 185, Batch 10/10\n",
            "  Loss: 0.000004\n",
            "  y_pred (first sample): [9.99989625e-01 1.52070889e-23 1.03746650e-05 3.36445583e-16\n",
            " 6.42748404e-24 7.07942175e-11 1.58055259e-26]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000003), db (mean=-0.000001, std=0.000003)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000003), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000010), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000026), db (mean=0.000000, std=0.000002)\n",
            "\n",
            "Epoch 186, Batch 1/10\n",
            "  Loss: 0.000032\n",
            "  y_pred (first sample): [1.34066301e-10 1.70592010e-08 7.57805667e-06 2.98654138e-15\n",
            " 4.39779706e-15 9.99992405e-01 1.01206833e-10]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000006), db (mean=-0.000001, std=0.000016)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000006), db (mean=-0.000001, std=0.000008)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000019), db (mean=-0.000002, std=0.000006)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000047), db (mean=0.000000, std=0.000007)\n",
            "\n",
            "Epoch 186, Batch 2/10\n",
            "  Loss: 0.000033\n",
            "  y_pred (first sample): [1.01973015e-15 4.95915340e-17 2.10852491e-05 6.35070324e-17\n",
            " 9.99928544e-01 2.40217012e-05 2.63493789e-05]\n",
            "  y_true (first sample): [0. 0. 0. 0. 1. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000003, std=0.000029), db (mean=-0.000005, std=0.000019)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000020), db (mean=-0.000002, std=0.000012)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000060), db (mean=-0.000002, std=0.000011)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000107), db (mean=-0.000000, std=0.000010)\n",
            "\n",
            "Epoch 186, Batch 3/10\n",
            "  Loss: 0.000008\n",
            "  y_pred (first sample): [2.77450275e-12 9.99999995e-01 4.90790399e-10 1.49366343e-10\n",
            " 3.01400706e-20 3.37812432e-09 6.82751356e-10]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000008), db (mean=-0.000001, std=0.000007)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000007), db (mean=0.000000, std=0.000004)\n",
            "    Layer 2: dW (mean=-0.000000, std=0.000022), db (mean=-0.000000, std=0.000004)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000045), db (mean=0.000000, std=0.000003)\n",
            "\n",
            "Epoch 186, Batch 4/10\n",
            "  Loss: 0.000032\n",
            "  y_pred (first sample): [4.00412569e-05 2.75120846e-11 9.99780153e-01 4.58757631e-11\n",
            " 1.79727048e-08 1.79786971e-04 5.57276195e-10]\n",
            "  y_true (first sample): [0. 0. 1. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000019), db (mean=-0.000003, std=0.000016)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000015), db (mean=-0.000000, std=0.000010)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000057), db (mean=-0.000002, std=0.000014)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000101), db (mean=-0.000000, std=0.000013)\n",
            "\n",
            "Epoch 186, Batch 5/10\n",
            "  Loss: 0.000036\n",
            "  y_pred (first sample): [9.99997469e-01 6.64321440e-21 2.53070025e-06 1.24377088e-14\n",
            " 1.68509538e-23 2.38606742e-10 8.02186482e-25]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000016), db (mean=-0.000000, std=0.000010)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000010), db (mean=-0.000000, std=0.000004)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000029), db (mean=-0.000001, std=0.000005)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000051), db (mean=0.000000, std=0.000004)\n",
            "\n",
            "Epoch 186, Batch 6/10\n",
            "  Loss: 0.000066\n",
            "  y_pred (first sample): [5.92800916e-07 7.24284952e-19 9.99900351e-01 6.79560061e-15\n",
            " 2.60499438e-05 7.30061026e-05 1.13727896e-11]\n",
            "  y_true (first sample): [0. 0. 1. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000003, std=0.000025), db (mean=-0.000007, std=0.000026)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000018), db (mean=-0.000002, std=0.000014)\n",
            "    Layer 2: dW (mean=-0.000008, std=0.000046), db (mean=-0.000003, std=0.000011)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000122), db (mean=0.000000, std=0.000014)\n",
            "\n",
            "Epoch 186, Batch 7/10\n",
            "  Loss: 0.000002\n",
            "  y_pred (first sample): [9.99999584e-01 5.02025902e-23 4.15786221e-07 6.74628425e-16\n",
            " 3.96967790e-26 1.88036502e-11 1.15736151e-27]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000001), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000001), db (mean=-0.000000, std=0.000000)\n",
            "    Layer 2: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000000)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000003), db (mean=-0.000000, std=0.000000)\n",
            "\n",
            "Epoch 186, Batch 8/10\n",
            "  Loss: 0.000023\n",
            "  y_pred (first sample): [9.99999949e-01 2.48867643e-25 5.13995768e-08 2.58162025e-17\n",
            " 1.19570624e-28 8.22993059e-13 3.00858471e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000050), db (mean=0.000001, std=0.000026)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000026), db (mean=-0.000000, std=0.000012)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000068), db (mean=-0.000002, std=0.000010)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000116), db (mean=0.000000, std=0.000009)\n",
            "\n",
            "Epoch 186, Batch 9/10\n",
            "  Loss: 0.000006\n",
            "  y_pred (first sample): [4.91165034e-29 3.44228752e-11 1.17575940e-16 3.81710785e-23\n",
            " 5.64706750e-07 4.64099515e-08 9.99999389e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000004), db (mean=-0.000001, std=0.000006)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000003), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000000, std=0.000007), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000020), db (mean=0.000000, std=0.000003)\n",
            "\n",
            "Epoch 186, Batch 10/10\n",
            "  Loss: 0.000069\n",
            "  y_pred (first sample): [4.56262114e-31 1.58821537e-12 1.58600739e-17 5.79959430e-25\n",
            " 7.26474454e-07 2.89078674e-08 9.99999245e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000031), db (mean=-0.000003, std=0.000037)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000018), db (mean=-0.000003, std=0.000014)\n",
            "    Layer 2: dW (mean=-0.000007, std=0.000047), db (mean=-0.000004, std=0.000010)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000112), db (mean=-0.000000, std=0.000016)\n",
            "\n",
            "Epoch 187, Batch 1/10\n",
            "  Loss: 0.000026\n",
            "  y_pred (first sample): [1.23599735e-05 2.28516696e-09 6.86194024e-13 9.99987638e-01\n",
            " 1.76636632e-14 1.56449485e-11 3.97866303e-16]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000000, std=0.000048), db (mean=0.000000, std=0.000024)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000024), db (mean=-0.000000, std=0.000012)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000061), db (mean=-0.000001, std=0.000009)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000104), db (mean=-0.000000, std=0.000008)\n",
            "\n",
            "Epoch 187, Batch 2/10\n",
            "  Loss: 0.000005\n",
            "  y_pred (first sample): [1.38928961e-05 7.69000915e-07 2.57563495e-11 9.99985335e-01\n",
            " 6.71039012e-12 2.92397860e-09 2.08982342e-12]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000003), db (mean=-0.000001, std=0.000005)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000003), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000006), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000017), db (mean=-0.000000, std=0.000003)\n",
            "\n",
            "Epoch 187, Batch 3/10\n",
            "  Loss: 0.000052\n",
            "  y_pred (first sample): [9.40657315e-15 4.60312824e-05 4.89145115e-08 4.93722546e-12\n",
            " 6.57549170e-05 4.57142500e-05 9.99842451e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000000, std=0.000020), db (mean=0.000001, std=0.000020)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000013), db (mean=0.000000, std=0.000011)\n",
            "    Layer 2: dW (mean=0.000002, std=0.000057), db (mean=0.000000, std=0.000013)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000102), db (mean=0.000000, std=0.000012)\n",
            "\n",
            "Epoch 187, Batch 4/10\n",
            "  Loss: 0.000050\n",
            "  y_pred (first sample): [1.24097751e-14 1.12378412e-17 9.95956311e-05 2.69323765e-16\n",
            " 9.99881554e-01 1.55098478e-05 3.34075306e-06]\n",
            "  y_true (first sample): [0. 0. 0. 0. 1. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000025), db (mean=0.000001, std=0.000014)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000018), db (mean=-0.000001, std=0.000010)\n",
            "    Layer 2: dW (mean=0.000005, std=0.000073), db (mean=0.000001, std=0.000013)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000141), db (mean=-0.000000, std=0.000015)\n",
            "\n",
            "Epoch 187, Batch 5/10\n",
            "  Loss: 0.000023\n",
            "  y_pred (first sample): [5.30519950e-05 2.70227118e-19 9.99837056e-01 5.41763313e-13\n",
            " 1.09661325e-04 2.30770814e-07 5.18721932e-12]\n",
            "  y_true (first sample): [0. 0. 1. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000011), db (mean=-0.000001, std=0.000016)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000010), db (mean=0.000001, std=0.000008)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000028), db (mean=-0.000003, std=0.000007)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000075), db (mean=0.000000, std=0.000009)\n",
            "\n",
            "Epoch 187, Batch 6/10\n",
            "  Loss: 0.000073\n",
            "  y_pred (first sample): [9.21287570e-15 4.58064138e-05 4.81943403e-08 4.86516840e-12\n",
            " 6.51177024e-05 4.52211286e-05 9.99843807e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000034), db (mean=-0.000005, std=0.000030)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000018), db (mean=-0.000003, std=0.000010)\n",
            "    Layer 2: dW (mean=-0.000009, std=0.000044), db (mean=-0.000004, std=0.000008)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000098), db (mean=0.000000, std=0.000013)\n",
            "\n",
            "Epoch 187, Batch 7/10\n",
            "  Loss: 0.000030\n",
            "  y_pred (first sample): [7.03464080e-06 8.61457832e-07 1.28598952e-12 9.99992104e-01\n",
            " 1.48665546e-13 2.03154224e-10 1.61738094e-13]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000021), db (mean=-0.000003, std=0.000018)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000016), db (mean=0.000000, std=0.000011)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000060), db (mean=-0.000002, std=0.000014)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000106), db (mean=0.000000, std=0.000013)\n",
            "\n",
            "Epoch 187, Batch 8/10\n",
            "  Loss: 0.000004\n",
            "  y_pred (first sample): [1.27233545e-10 1.74720532e-08 7.41398939e-06 2.95150156e-15\n",
            " 4.25440434e-15 9.99992568e-01 1.03015855e-10]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000003), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 2: dW (mean=-0.000000, std=0.000009), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000020), db (mean=0.000000, std=0.000002)\n",
            "\n",
            "Epoch 187, Batch 9/10\n",
            "  Loss: 0.000028\n",
            "  y_pred (first sample): [1.43913905e-14 9.99999999e-01 9.34884984e-13 4.24844971e-10\n",
            " 8.34995048e-22 3.95452558e-13 2.67201619e-10]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000006), db (mean=-0.000002, std=0.000007)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000006), db (mean=-0.000001, std=0.000004)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000021), db (mean=-0.000001, std=0.000005)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000083), db (mean=-0.000000, std=0.000011)\n",
            "\n",
            "Epoch 187, Batch 10/10\n",
            "  Loss: 0.000015\n",
            "  y_pred (first sample): [9.99999467e-01 3.12576876e-27 5.33270959e-07 1.32823983e-18\n",
            " 5.45080547e-28 6.67697903e-13 9.63276920e-31]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000017), db (mean=-0.000001, std=0.000014)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000010), db (mean=0.000001, std=0.000006)\n",
            "    Layer 2: dW (mean=-0.000000, std=0.000023), db (mean=-0.000000, std=0.000004)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000062), db (mean=-0.000000, std=0.000006)\n",
            "\n",
            "Epoch 188, Batch 1/10\n",
            "  Loss: 0.000040\n",
            "  y_pred (first sample): [1.34887378e-05 7.78274238e-07 2.49515764e-11 9.99985730e-01\n",
            " 6.63310615e-12 2.92460390e-09 2.10161758e-12]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000045), db (mean=-0.000003, std=0.000031)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000027), db (mean=-0.000001, std=0.000016)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000073), db (mean=-0.000001, std=0.000013)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000107), db (mean=0.000000, std=0.000009)\n",
            "\n",
            "Epoch 188, Batch 2/10\n",
            "  Loss: 0.000041\n",
            "  y_pred (first sample): [5.25777471e-05 2.65422057e-19 9.99838295e-01 5.32482749e-13\n",
            " 1.08897748e-04 2.29687887e-07 5.13265517e-12]\n",
            "  y_true (first sample): [0. 0. 1. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000000, std=0.000048), db (mean=0.000000, std=0.000019)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000024), db (mean=0.000001, std=0.000008)\n",
            "    Layer 2: dW (mean=-0.000010, std=0.000062), db (mean=-0.000004, std=0.000009)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000136), db (mean=0.000000, std=0.000013)\n",
            "\n",
            "Epoch 188, Batch 3/10\n",
            "  Loss: 0.000003\n",
            "  y_pred (first sample): [2.08780911e-14 1.00000000e+00 1.19863398e-12 8.84721277e-12\n",
            " 4.36308357e-24 8.42888920e-12 7.56297461e-12]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000002), db (mean=-0.000001, std=0.000003)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 2: dW (mean=0.000001, std=0.000006), db (mean=0.000000, std=0.000001)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000011), db (mean=-0.000000, std=0.000001)\n",
            "\n",
            "Epoch 188, Batch 4/10\n",
            "  Loss: 0.000033\n",
            "  y_pred (first sample): [1.33672914e-08 9.99999914e-01 5.06132583e-08 2.09919494e-08\n",
            " 8.35671403e-22 7.74603082e-10 4.16601538e-12]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000008), db (mean=-0.000003, std=0.000011)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000008), db (mean=-0.000001, std=0.000006)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000026), db (mean=-0.000002, std=0.000006)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000079), db (mean=0.000000, std=0.000010)\n",
            "\n",
            "Epoch 188, Batch 5/10\n",
            "  Loss: 0.000030\n",
            "  y_pred (first sample): [3.84857120e-06 2.44792107e-08 1.50406702e-13 9.99996127e-01\n",
            " 8.30858987e-15 1.45928101e-11 1.52114567e-15]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000006), db (mean=-0.000001, std=0.000015)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000006), db (mean=-0.000001, std=0.000007)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000019), db (mean=-0.000002, std=0.000006)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000048), db (mean=-0.000000, std=0.000007)\n",
            "\n",
            "Epoch 188, Batch 6/10\n",
            "  Loss: 0.000007\n",
            "  y_pred (first sample): [1.35191123e-05 7.70648030e-07 2.49856561e-11 9.99985707e-01\n",
            " 6.60812304e-12 2.90911209e-09 2.07766491e-12]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000004), db (mean=-0.000001, std=0.000006)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000003), db (mean=-0.000001, std=0.000003)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000009), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000018), db (mean=-0.000000, std=0.000003)\n",
            "\n",
            "Epoch 188, Batch 7/10\n",
            "  Loss: 0.000006\n",
            "  y_pred (first sample): [9.99999950e-01 2.37085385e-25 5.01198048e-08 2.48368208e-17\n",
            " 1.05711039e-28 7.78490965e-13 2.73907608e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000007), db (mean=-0.000000, std=0.000006)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000005), db (mean=0.000000, std=0.000003)\n",
            "    Layer 2: dW (mean=0.000000, std=0.000019), db (mean=-0.000000, std=0.000003)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000036), db (mean=0.000000, std=0.000003)\n",
            "\n",
            "Epoch 188, Batch 8/10\n",
            "  Loss: 0.000067\n",
            "  y_pred (first sample): [9.99999478e-01 1.02460427e-23 5.21759745e-07 3.87690308e-16\n",
            " 1.98359576e-25 7.03383890e-12 3.26770983e-27]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000002, std=0.000042), db (mean=-0.000000, std=0.000040)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000027), db (mean=-0.000000, std=0.000021)\n",
            "    Layer 2: dW (mean=0.000013, std=0.000095), db (mean=0.000003, std=0.000021)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000157), db (mean=0.000000, std=0.000018)\n",
            "\n",
            "Epoch 188, Batch 9/10\n",
            "  Loss: 0.000022\n",
            "  y_pred (first sample): [9.99995472e-01 2.92289677e-15 2.42923080e-08 4.50387826e-06\n",
            " 8.06162782e-18 1.59524225e-10 1.45437408e-19]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000006), db (mean=0.000001, std=0.000016)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000006), db (mean=-0.000001, std=0.000008)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000020), db (mean=-0.000002, std=0.000006)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000052), db (mean=0.000000, std=0.000009)\n",
            "\n",
            "Epoch 188, Batch 10/10\n",
            "  Loss: 0.000051\n",
            "  y_pred (first sample): [9.99986471e-01 2.33004053e-24 1.35290810e-05 6.52606517e-15\n",
            " 4.70226428e-22 1.96004997e-11 3.20622536e-26]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000003, std=0.000032), db (mean=-0.000006, std=0.000024)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000020), db (mean=-0.000001, std=0.000012)\n",
            "    Layer 2: dW (mean=-0.000008, std=0.000052), db (mean=-0.000003, std=0.000010)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000095), db (mean=-0.000000, std=0.000009)\n",
            "\n",
            "Epoch 189, Batch 1/10\n",
            "  Loss: 0.000011\n",
            "  y_pred (first sample): [5.82602840e-12 9.99999976e-01 3.60868409e-09 1.27118118e-10\n",
            " 9.21932481e-20 1.93520858e-08 1.31967006e-09]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000006), db (mean=-0.000002, std=0.000004)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000004), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000011), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000037), db (mean=-0.000000, std=0.000004)\n",
            "\n",
            "Epoch 189, Batch 2/10\n",
            "  Loss: 0.000036\n",
            "  y_pred (first sample): [8.32885695e-17 9.99999755e-01 1.07897272e-12 5.28701421e-12\n",
            " 4.44938879e-19 5.97746017e-11 2.44559657e-07]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000002, std=0.000056), db (mean=0.000003, std=0.000033)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000029), db (mean=-0.000000, std=0.000015)\n",
            "    Layer 2: dW (mean=0.000006, std=0.000075), db (mean=0.000002, std=0.000012)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000117), db (mean=0.000000, std=0.000010)\n",
            "\n",
            "Epoch 189, Batch 3/10\n",
            "  Loss: 0.000049\n",
            "  y_pred (first sample): [9.99999469e-01 2.99475703e-27 5.31463438e-07 1.28508770e-18\n",
            " 5.06200507e-28 6.42612167e-13 9.07000244e-31]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000038), db (mean=-0.000002, std=0.000035)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000026), db (mean=0.000000, std=0.000019)\n",
            "    Layer 2: dW (mean=-0.000008, std=0.000082), db (mean=-0.000003, std=0.000017)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000125), db (mean=-0.000000, std=0.000012)\n",
            "\n",
            "Epoch 189, Batch 4/10\n",
            "  Loss: 0.000005\n",
            "  y_pred (first sample): [1.33255230e-05 7.74320022e-07 2.47535124e-11 9.99985897e-01\n",
            " 6.63225847e-12 2.92767294e-09 2.09469187e-12]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000002), db (mean=-0.000001, std=0.000004)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000005), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000012), db (mean=0.000000, std=0.000002)\n",
            "\n",
            "Epoch 189, Batch 5/10\n",
            "  Loss: 0.000020\n",
            "  y_pred (first sample): [9.99997060e-01 1.94075708e-25 2.94038704e-06 1.43836890e-17\n",
            " 7.18503124e-26 7.03236201e-12 1.68838438e-28]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000021), db (mean=-0.000002, std=0.000018)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000012), db (mean=0.000000, std=0.000008)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000027), db (mean=-0.000001, std=0.000005)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000062), db (mean=-0.000000, std=0.000006)\n",
            "\n",
            "Epoch 189, Batch 6/10\n",
            "  Loss: 0.000031\n",
            "  y_pred (first sample): [6.92390514e-06 8.43883116e-07 1.24260364e-12 9.99992232e-01\n",
            " 1.43234074e-13 1.97407613e-10 1.55006923e-13]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000007), db (mean=-0.000004, std=0.000005)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000004), db (mean=-0.000002, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000007, std=0.000016), db (mean=-0.000002, std=0.000002)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000096), db (mean=0.000000, std=0.000012)\n",
            "\n",
            "Epoch 189, Batch 7/10\n",
            "  Loss: 0.000069\n",
            "  y_pred (first sample): [8.90034838e-15 7.49599762e-11 3.12190167e-05 1.09466162e-16\n",
            " 3.26312932e-05 9.99827551e-01 1.08599070e-04]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000035), db (mean=-0.000004, std=0.000019)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000019), db (mean=-0.000001, std=0.000008)\n",
            "    Layer 2: dW (mean=-0.000011, std=0.000046), db (mean=-0.000004, std=0.000009)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000088), db (mean=0.000000, std=0.000010)\n",
            "\n",
            "Epoch 189, Batch 8/10\n",
            "  Loss: 0.000048\n",
            "  y_pred (first sample): [8.76274475e-15 4.46663279e-05 4.70821970e-08 4.65806792e-12\n",
            " 6.38165640e-05 4.43934442e-05 9.99847077e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000007), db (mean=-0.000002, std=0.000017)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000007), db (mean=-0.000002, std=0.000007)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000024), db (mean=-0.000003, std=0.000007)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000088), db (mean=0.000000, std=0.000014)\n",
            "\n",
            "Epoch 189, Batch 9/10\n",
            "  Loss: 0.000003\n",
            "  y_pred (first sample): [9.99999999e-01 1.19915590e-20 1.08475295e-09 2.46563053e-11\n",
            " 1.56055359e-25 1.10209470e-12 9.36376569e-27]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000003)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 2: dW (mean=0.000001, std=0.000006), db (mean=0.000000, std=0.000001)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000010), db (mean=-0.000000, std=0.000001)\n",
            "\n",
            "Epoch 189, Batch 10/10\n",
            "  Loss: 0.000024\n",
            "  y_pred (first sample): [9.99999916e-01 9.12372826e-23 8.42703184e-08 9.62525453e-16\n",
            " 1.30168315e-26 6.16907962e-12 1.80140990e-27]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000006), db (mean=-0.000003, std=0.000017)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000006), db (mean=-0.000001, std=0.000010)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000022), db (mean=-0.000002, std=0.000008)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000057), db (mean=0.000000, std=0.000010)\n",
            "\n",
            "Epoch 190, Batch 1/10\n",
            "  Loss: 0.000039\n",
            "  y_pred (first sample): [9.99999204e-01 9.89774208e-26 7.96399071e-07 1.34134400e-17\n",
            " 1.03948906e-26 2.34218478e-12 3.90158437e-29]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000003, std=0.000034), db (mean=-0.000005, std=0.000024)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000023), db (mean=-0.000000, std=0.000014)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000063), db (mean=-0.000001, std=0.000012)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000088), db (mean=-0.000000, std=0.000008)\n",
            "\n",
            "Epoch 190, Batch 2/10\n",
            "  Loss: 0.000003\n",
            "  y_pred (first sample): [1.32851324e-05 7.66679391e-07 2.47183830e-11 9.99985945e-01\n",
            " 6.63374060e-12 2.92275838e-09 2.07775721e-12]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000003)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 2: dW (mean=0.000000, std=0.000005), db (mean=0.000000, std=0.000001)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000010), db (mean=-0.000000, std=0.000001)\n",
            "\n",
            "Epoch 190, Batch 3/10\n",
            "  Loss: 0.000004\n",
            "  y_pred (first sample): [9.99992380e-01 4.52752628e-25 7.62044745e-06 3.21273365e-17\n",
            " 2.92589776e-25 1.98573743e-11 3.19469787e-28]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000002), db (mean=-0.000001, std=0.000003)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000008), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000018), db (mean=-0.000000, std=0.000001)\n",
            "\n",
            "Epoch 190, Batch 4/10\n",
            "  Loss: 0.000027\n",
            "  y_pred (first sample): [1.32579600e-05 7.64344833e-07 2.46067538e-11 9.99985975e-01\n",
            " 6.59978535e-12 2.91123100e-09 2.06550044e-12]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000006), db (mean=-0.000003, std=0.000008)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000006), db (mean=-0.000001, std=0.000005)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000021), db (mean=-0.000001, std=0.000005)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000078), db (mean=0.000000, std=0.000011)\n",
            "\n",
            "Epoch 190, Batch 5/10\n",
            "  Loss: 0.000005\n",
            "  y_pred (first sample): [9.99997581e-01 5.92905756e-21 2.41877478e-06 1.13643172e-14\n",
            " 1.35114206e-23 2.13828324e-10 6.68131732e-25]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000006), db (mean=-0.000000, std=0.000005)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000005), db (mean=0.000000, std=0.000003)\n",
            "    Layer 2: dW (mean=-0.000000, std=0.000017), db (mean=-0.000000, std=0.000003)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000034), db (mean=-0.000000, std=0.000003)\n",
            "\n",
            "Epoch 190, Batch 6/10\n",
            "  Loss: 0.000033\n",
            "  y_pred (first sample): [2.08970939e-14 1.00000000e+00 1.17405347e-12 8.89236728e-12\n",
            " 4.01375420e-24 8.17965845e-12 7.27502669e-12]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000007), db (mean=-0.000003, std=0.000017)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000006), db (mean=-0.000002, std=0.000009)\n",
            "    Layer 2: dW (mean=-0.000005, std=0.000021), db (mean=-0.000002, std=0.000007)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000051), db (mean=0.000000, std=0.000008)\n",
            "\n",
            "Epoch 190, Batch 7/10\n",
            "  Loss: 0.000039\n",
            "  y_pred (first sample): [8.69683212e-15 4.44236309e-05 4.71673303e-08 4.60732139e-12\n",
            " 6.34751725e-05 4.45551582e-05 9.99847499e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000049), db (mean=0.000002, std=0.000036)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000029), db (mean=-0.000001, std=0.000019)\n",
            "    Layer 2: dW (mean=-0.000007, std=0.000082), db (mean=-0.000002, std=0.000016)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000157), db (mean=0.000000, std=0.000017)\n",
            "\n",
            "Epoch 190, Batch 8/10\n",
            "  Loss: 0.000030\n",
            "  y_pred (first sample): [9.99999917e-01 8.89226658e-23 8.34595849e-08 9.42521285e-16\n",
            " 1.23980128e-26 6.03191128e-12 1.72781571e-27]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000011), db (mean=-0.000003, std=0.000016)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000011), db (mean=0.000000, std=0.000009)\n",
            "    Layer 2: dW (mean=-0.000007, std=0.000030), db (mean=-0.000003, std=0.000007)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000064), db (mean=-0.000000, std=0.000007)\n",
            "\n",
            "Epoch 190, Batch 9/10\n",
            "  Loss: 0.000045\n",
            "  y_pred (first sample): [9.99999952e-01 2.18900793e-25 4.84441312e-08 2.32971460e-17\n",
            " 9.14626264e-29 7.23034047e-13 2.42185320e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000029), db (mean=0.000000, std=0.000024)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000018), db (mean=0.000000, std=0.000011)\n",
            "    Layer 2: dW (mean=0.000006, std=0.000058), db (mean=0.000001, std=0.000012)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000101), db (mean=0.000000, std=0.000012)\n",
            "\n",
            "Epoch 190, Batch 10/10\n",
            "  Loss: 0.000068\n",
            "  y_pred (first sample): [1.33857154e-08 9.99999915e-01 5.00172339e-08 2.07409175e-08\n",
            " 7.59240940e-22 7.51219640e-10 4.03638642e-12]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000019), db (mean=-0.000004, std=0.000015)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000012), db (mean=-0.000001, std=0.000006)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000044), db (mean=-0.000001, std=0.000009)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000104), db (mean=0.000000, std=0.000009)\n",
            "\n",
            "Epoch 191, Batch 1/10\n",
            "  Loss: 0.000010\n",
            "  y_pred (first sample): [9.99999951e-01 2.17481266e-25 4.85077653e-08 2.31982465e-17\n",
            " 9.09230711e-29 7.18898243e-13 2.40707570e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000004), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000003), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000008), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000031), db (mean=-0.000000, std=0.000004)\n",
            "\n",
            "Epoch 191, Batch 2/10\n",
            "  Loss: 0.000025\n",
            "  y_pred (first sample): [9.99964510e-01 2.66515988e-17 3.54899571e-05 3.39663204e-12\n",
            " 8.96756720e-24 1.90832981e-10 4.04747185e-24]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000008), db (mean=-0.000000, std=0.000014)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000007), db (mean=-0.000000, std=0.000007)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000025), db (mean=-0.000002, std=0.000006)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000063), db (mean=0.000000, std=0.000009)\n",
            "\n",
            "Epoch 191, Batch 3/10\n",
            "  Loss: 0.000049\n",
            "  y_pred (first sample): [1.30840357e-05 7.66846967e-07 2.43658246e-11 9.99986146e-01\n",
            " 6.60631378e-12 2.92237506e-09 2.07571904e-12]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000021), db (mean=-0.000002, std=0.000020)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000014), db (mean=0.000001, std=0.000009)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000037), db (mean=-0.000001, std=0.000007)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000074), db (mean=-0.000000, std=0.000007)\n",
            "\n",
            "Epoch 191, Batch 4/10\n",
            "  Loss: 0.000028\n",
            "  y_pred (first sample): [6.83164682e-06 8.26095915e-07 1.20468411e-12 9.99992342e-01\n",
            " 1.38449861e-13 1.92105038e-10 1.48805582e-13]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000026), db (mean=-0.000004, std=0.000016)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000017), db (mean=-0.000002, std=0.000010)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000057), db (mean=-0.000001, std=0.000011)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000101), db (mean=0.000000, std=0.000010)\n",
            "\n",
            "Epoch 191, Batch 5/10\n",
            "  Loss: 0.000013\n",
            "  y_pred (first sample): [3.74812550e-29 2.99941913e-11 1.00718805e-16 3.08993347e-23\n",
            " 5.29834943e-07 4.29149609e-08 9.99999427e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000015), db (mean=-0.000001, std=0.000013)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000009), db (mean=0.000001, std=0.000006)\n",
            "    Layer 2: dW (mean=0.000000, std=0.000020), db (mean=0.000000, std=0.000004)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000052), db (mean=-0.000000, std=0.000005)\n",
            "\n",
            "Epoch 191, Batch 6/10\n",
            "  Loss: 0.000049\n",
            "  y_pred (first sample): [1.33424277e-08 9.99999915e-01 5.01476153e-08 2.06723653e-08\n",
            " 7.53326296e-22 7.47907065e-10 4.05222833e-12]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000022), db (mean=-0.000003, std=0.000019)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000017), db (mean=-0.000001, std=0.000011)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000071), db (mean=-0.000001, std=0.000016)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000122), db (mean=-0.000000, std=0.000014)\n",
            "\n",
            "Epoch 191, Batch 7/10\n",
            "  Loss: 0.000027\n",
            "  y_pred (first sample): [9.99999220e-01 9.39980181e-26 7.79538596e-07 1.28754543e-17\n",
            " 9.43712165e-27 2.22583287e-12 3.59757587e-29]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000007), db (mean=-0.000003, std=0.000019)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000007), db (mean=-0.000001, std=0.000011)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000023), db (mean=-0.000001, std=0.000008)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000054), db (mean=0.000000, std=0.000009)\n",
            "\n",
            "Epoch 191, Batch 8/10\n",
            "  Loss: 0.000025\n",
            "  y_pred (first sample): [9.99999486e-01 2.69275759e-27 5.13809764e-07 1.18364918e-18\n",
            " 4.29773653e-28 5.85529057e-13 7.84249317e-31]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000006), db (mean=-0.000002, std=0.000009)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000006), db (mean=-0.000001, std=0.000005)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000019), db (mean=-0.000001, std=0.000005)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000068), db (mean=0.000000, std=0.000010)\n",
            "\n",
            "Epoch 191, Batch 9/10\n",
            "  Loss: 0.000039\n",
            "  y_pred (first sample): [1.37214337e-14 9.99999999e-01 8.72837300e-13 4.28912962e-10\n",
            " 7.47591723e-22 3.71440771e-13 2.60425964e-10]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000000, std=0.000038), db (mean=-0.000001, std=0.000018)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000017), db (mean=-0.000001, std=0.000007)\n",
            "    Layer 2: dW (mean=-0.000008, std=0.000044), db (mean=-0.000002, std=0.000006)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000079), db (mean=-0.000000, std=0.000006)\n",
            "\n",
            "Epoch 191, Batch 10/10\n",
            "  Loss: 0.000022\n",
            "  y_pred (first sample): [9.99986714e-01 2.03986234e-24 1.32863296e-05 5.99111843e-15\n",
            " 4.10398867e-22 1.77860685e-11 2.76924146e-26]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000006), db (mean=0.000000, std=0.000016)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000006), db (mean=-0.000001, std=0.000008)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000020), db (mean=-0.000002, std=0.000006)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000049), db (mean=0.000000, std=0.000008)\n",
            "\n",
            "=== Epoch 191 Summary ===\n",
            "Average Batch Loss: 0.000029\n",
            "Full Dataset Loss: 0.000029\n",
            "Final y_pred sample: [4.73279538e-14 1.67272923e-15 8.19122735e-05 3.36130847e-15\n",
            " 9.99801751e-01 6.07213343e-05 5.56158714e-05]\n",
            "Final y_true sample: [0. 0. 0. 0. 1. 0. 0.]\n",
            "\n",
            "Epoch 192, Batch 1/10\n",
            "  Loss: 0.000029\n",
            "  y_pred (first sample): [9.99986710e-01 2.03524911e-24 1.32896196e-05 5.99321872e-15\n",
            " 4.09875826e-22 1.77506335e-11 2.76191456e-26]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000009), db (mean=-0.000004, std=0.000006)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000006), db (mean=-0.000002, std=0.000003)\n",
            "    Layer 2: dW (mean=-0.000007, std=0.000017), db (mean=-0.000002, std=0.000003)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000092), db (mean=-0.000000, std=0.000011)\n",
            "\n",
            "Epoch 192, Batch 2/10\n",
            "  Loss: 0.000050\n",
            "  y_pred (first sample): [1.06008176e-04 2.28559483e-17 9.99820968e-01 3.44459149e-12\n",
            " 7.07559667e-05 2.26772861e-06 3.98034568e-11]\n",
            "  y_true (first sample): [0. 0. 1. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000012), db (mean=-0.000004, std=0.000014)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000010), db (mean=-0.000001, std=0.000008)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000033), db (mean=-0.000002, std=0.000008)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000098), db (mean=-0.000000, std=0.000011)\n",
            "\n",
            "Epoch 192, Batch 3/10\n",
            "  Loss: 0.000014\n",
            "  y_pred (first sample): [2.34328277e-16 1.91271584e-17 1.15480984e-05 1.70194031e-17\n",
            " 9.99944346e-01 1.87955785e-05 2.53105361e-05]\n",
            "  y_true (first sample): [0. 0. 0. 0. 1. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000009), db (mean=-0.000001, std=0.000007)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000007), db (mean=-0.000000, std=0.000004)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000022), db (mean=-0.000001, std=0.000003)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000058), db (mean=0.000000, std=0.000005)\n",
            "\n",
            "Epoch 192, Batch 4/10\n",
            "  Loss: 0.000022\n",
            "  y_pred (first sample): [8.09821821e-15 4.29341055e-05 4.54461531e-08 4.35492005e-12\n",
            " 6.22169660e-05 4.30428369e-05 9.99851761e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000006), db (mean=0.000000, std=0.000017)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000006), db (mean=-0.000001, std=0.000008)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000018), db (mean=-0.000001, std=0.000006)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000047), db (mean=-0.000000, std=0.000008)\n",
            "\n",
            "Epoch 192, Batch 5/10\n",
            "  Loss: 0.000001\n",
            "  y_pred (first sample): [9.99999999e-01 1.11207238e-20 1.05058106e-09 2.37105057e-11\n",
            " 1.38335188e-25 1.01920285e-12 8.36412653e-27]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000000), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000000), db (mean=-0.000000, std=0.000000)\n",
            "    Layer 2: dW (mean=-0.000000, std=0.000001), db (mean=-0.000000, std=0.000000)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000003), db (mean=-0.000000, std=0.000000)\n",
            "\n",
            "Epoch 192, Batch 6/10\n",
            "  Loss: 0.000061\n",
            "  y_pred (first sample): [2.66456884e-12 9.99999996e-01 4.56456937e-10 1.47009499e-10\n",
            " 2.39243660e-20 3.00231750e-09 6.24324445e-10]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000036), db (mean=-0.000001, std=0.000019)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000019), db (mean=-0.000000, std=0.000009)\n",
            "    Layer 2: dW (mean=-0.000014, std=0.000053), db (mean=-0.000005, std=0.000010)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000109), db (mean=-0.000000, std=0.000011)\n",
            "\n",
            "Epoch 192, Batch 7/10\n",
            "  Loss: 0.000005\n",
            "  y_pred (first sample): [9.99997617e-01 5.55877500e-21 2.38303173e-06 1.08294555e-14\n",
            " 1.22655848e-23 2.02046234e-10 6.12691926e-25]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000003), db (mean=-0.000001, std=0.000005)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000003), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000007), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000011), db (mean=0.000000, std=0.000001)\n",
            "\n",
            "Epoch 192, Batch 8/10\n",
            "  Loss: 0.000003\n",
            "  y_pred (first sample): [1.28274341e-05 7.70915326e-07 2.43518046e-11 9.99986399e-01\n",
            " 6.76437636e-12 2.98630058e-09 2.12426980e-12]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000003)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 2: dW (mean=0.000000, std=0.000005), db (mean=0.000000, std=0.000001)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000010), db (mean=0.000000, std=0.000001)\n",
            "\n",
            "Epoch 192, Batch 9/10\n",
            "  Loss: 0.000059\n",
            "  y_pred (first sample): [9.99999612e-01 4.17279437e-23 3.88286901e-07 5.84339264e-16\n",
            " 2.81019755e-26 1.57478844e-11 8.66760920e-28]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000003, std=0.000037), db (mean=-0.000005, std=0.000026)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000021), db (mean=-0.000002, std=0.000013)\n",
            "    Layer 2: dW (mean=-0.000010, std=0.000053), db (mean=-0.000003, std=0.000010)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000095), db (mean=-0.000000, std=0.000010)\n",
            "\n",
            "Epoch 192, Batch 10/10\n",
            "  Loss: 0.000042\n",
            "  y_pred (first sample): [8.14065014e-15 4.80712809e-05 1.27268048e-08 1.01753486e-11\n",
            " 7.97172505e-05 5.11489305e-05 9.99821050e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000009), db (mean=-0.000002, std=0.000030)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000012), db (mean=-0.000002, std=0.000017)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000039), db (mean=-0.000003, std=0.000014)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000100), db (mean=-0.000000, std=0.000018)\n",
            "\n",
            "Epoch 193, Batch 1/10\n",
            "  Loss: 0.000064\n",
            "  y_pred (first sample): [4.40935418e-14 1.59529055e-15 7.96450226e-05 3.15835395e-15\n",
            " 9.99805021e-01 5.99260211e-05 5.54075932e-05]\n",
            "  y_true (first sample): [0. 0. 0. 0. 1. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000020), db (mean=-0.000001, std=0.000014)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000012), db (mean=-0.000001, std=0.000005)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000042), db (mean=-0.000001, std=0.000007)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000100), db (mean=-0.000000, std=0.000008)\n",
            "\n",
            "Epoch 193, Batch 2/10\n",
            "  Loss: 0.000016\n",
            "  y_pred (first sample): [9.99999992e-01 2.28317873e-17 3.15842614e-09 5.20693897e-09\n",
            " 1.77436503e-22 1.96987580e-11 3.69335330e-23]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000016), db (mean=-0.000001, std=0.000013)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000009), db (mean=0.000001, std=0.000006)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000022), db (mean=-0.000000, std=0.000004)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000046), db (mean=0.000000, std=0.000005)\n",
            "\n",
            "Epoch 193, Batch 3/10\n",
            "  Loss: 0.000026\n",
            "  y_pred (first sample): [2.89435230e-31 1.26419369e-12 1.23734635e-17 4.03884351e-25\n",
            " 6.58822733e-07 2.53558784e-08 9.99999316e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000044), db (mean=0.000002, std=0.000023)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000024), db (mean=0.000000, std=0.000012)\n",
            "    Layer 2: dW (mean=-0.000005, std=0.000063), db (mean=-0.000001, std=0.000010)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000110), db (mean=-0.000000, std=0.000009)\n",
            "\n",
            "Epoch 193, Batch 4/10\n",
            "  Loss: 0.000002\n",
            "  y_pred (first sample): [9.99999229e-01 8.79596291e-26 7.71261496e-07 1.22652836e-17\n",
            " 8.59573817e-27 2.11399596e-12 3.29410498e-29]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000001), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000001), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 2: dW (mean=0.000000, std=0.000004), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000008), db (mean=-0.000000, std=0.000001)\n",
            "\n",
            "Epoch 193, Batch 5/10\n",
            "  Loss: 0.000040\n",
            "  y_pred (first sample): [2.60632954e-12 9.99999996e-01 4.43149836e-10 1.44937810e-10\n",
            " 2.25497847e-20 2.91672750e-09 6.09952691e-10]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000008), db (mean=-0.000002, std=0.000011)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000008), db (mean=0.000000, std=0.000004)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000026), db (mean=-0.000003, std=0.000005)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000088), db (mean=0.000000, std=0.000013)\n",
            "\n",
            "Epoch 193, Batch 6/10\n",
            "  Loss: 0.000025\n",
            "  y_pred (first sample): [9.99999963e-01 5.17742285e-23 3.68020239e-08 4.99807867e-16\n",
            " 1.01806861e-28 2.42730738e-12 2.55737015e-29]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000006), db (mean=-0.000003, std=0.000017)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000006), db (mean=-0.000001, std=0.000009)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000021), db (mean=-0.000002, std=0.000007)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000056), db (mean=0.000000, std=0.000010)\n",
            "\n",
            "Epoch 193, Batch 7/10\n",
            "  Loss: 0.000011\n",
            "  y_pred (first sample): [9.99999504e-01 8.77993509e-24 4.96153748e-07 3.44542905e-16\n",
            " 1.53799514e-25 6.09433574e-12 2.61719122e-27]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000003), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000007), db (mean=-0.000001, std=0.000001)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000033), db (mean=0.000000, std=0.000004)\n",
            "\n",
            "Epoch 193, Batch 8/10\n",
            "  Loss: 0.000039\n",
            "  y_pred (first sample): [9.99999620e-01 4.08278288e-23 3.79798888e-07 5.73537680e-16\n",
            " 2.62903523e-26 1.53151611e-11 8.24292024e-28]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000021), db (mean=0.000000, std=0.000020)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000014), db (mean=-0.000000, std=0.000010)\n",
            "    Layer 2: dW (mean=0.000008, std=0.000046), db (mean=0.000002, std=0.000009)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000062), db (mean=-0.000000, std=0.000007)\n",
            "\n",
            "Epoch 193, Batch 9/10\n",
            "  Loss: 0.000034\n",
            "  y_pred (first sample): [3.90814283e-05 2.49475516e-11 9.99796135e-01 4.15426294e-11\n",
            " 1.47504933e-08 1.64768542e-04 4.88908733e-10]\n",
            "  y_true (first sample): [0. 0. 1. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000023), db (mean=-0.000003, std=0.000020)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000016), db (mean=-0.000000, std=0.000011)\n",
            "    Layer 2: dW (mean=-0.000007, std=0.000059), db (mean=-0.000002, std=0.000014)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000107), db (mean=-0.000000, std=0.000013)\n",
            "\n",
            "Epoch 193, Batch 10/10\n",
            "  Loss: 0.000027\n",
            "  y_pred (first sample): [1.25347378e-05 7.75711021e-07 2.37099771e-11 9.99986687e-01\n",
            " 6.67738175e-12 2.97640338e-09 2.12159433e-12]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000027), db (mean=-0.000003, std=0.000018)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000018), db (mean=-0.000002, std=0.000010)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000057), db (mean=-0.000001, std=0.000011)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000100), db (mean=-0.000000, std=0.000010)\n",
            "\n",
            "Epoch 194, Batch 1/10\n",
            "  Loss: 0.000004\n",
            "  y_pred (first sample): [1.15526991e-05 2.07032001e-09 5.87238795e-13 9.99988445e-01\n",
            " 1.47996318e-14 1.36430404e-11 3.25059801e-16]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000002), db (mean=-0.000001, std=0.000003)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 2: dW (mean=-0.000000, std=0.000006), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000012), db (mean=0.000000, std=0.000001)\n",
            "\n",
            "Epoch 194, Batch 2/10\n",
            "  Loss: 0.000043\n",
            "  y_pred (first sample): [2.82462160e-32 2.04712380e-13 4.03160741e-17 1.01234110e-26\n",
            " 5.59190008e-07 3.22122141e-08 9.99999409e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000000, std=0.000049), db (mean=0.000000, std=0.000029)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000025), db (mean=0.000000, std=0.000013)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000075), db (mean=0.000000, std=0.000013)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000104), db (mean=-0.000000, std=0.000010)\n",
            "\n",
            "Epoch 194, Batch 3/10\n",
            "  Loss: 0.000031\n",
            "  y_pred (first sample): [9.99995653e-01 2.63572587e-15 2.31169819e-08 4.32404976e-06\n",
            " 6.89466336e-18 1.42644079e-10 1.24404583e-19]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000016), db (mean=-0.000001, std=0.000010)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000008), db (mean=0.000000, std=0.000003)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000022), db (mean=-0.000001, std=0.000005)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000074), db (mean=0.000000, std=0.000011)\n",
            "\n",
            "Epoch 194, Batch 4/10\n",
            "  Loss: 0.000003\n",
            "  y_pred (first sample): [3.66785753e-06 2.27044122e-08 1.36019093e-13 9.99996309e-01\n",
            " 7.45064382e-15 1.33190698e-11 1.32263421e-15]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000001), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000001), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 2: dW (mean=-0.000000, std=0.000003), db (mean=0.000000, std=0.000001)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000007), db (mean=-0.000000, std=0.000001)\n",
            "\n",
            "Epoch 194, Batch 5/10\n",
            "  Loss: 0.000021\n",
            "  y_pred (first sample): [1.24040872e-05 7.77316405e-07 2.34857269e-11 9.99986816e-01\n",
            " 6.65933211e-12 2.97702122e-09 2.12396983e-12]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000009), db (mean=-0.000001, std=0.000014)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000009), db (mean=0.000001, std=0.000007)\n",
            "    Layer 2: dW (mean=-0.000005, std=0.000025), db (mean=-0.000003, std=0.000006)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000073), db (mean=-0.000000, std=0.000009)\n",
            "\n",
            "Epoch 194, Batch 6/10\n",
            "  Loss: 0.000030\n",
            "  y_pred (first sample): [3.26827711e-08 9.99996323e-01 3.18089081e-06 3.24782771e-07\n",
            " 3.07943961e-15 5.79162927e-08 8.05031796e-08]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000031), db (mean=-0.000002, std=0.000021)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000019), db (mean=-0.000001, std=0.000011)\n",
            "    Layer 2: dW (mean=-0.000005, std=0.000058), db (mean=-0.000002, std=0.000010)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000101), db (mean=0.000000, std=0.000010)\n",
            "\n",
            "Epoch 194, Batch 7/10\n",
            "  Loss: 0.000017\n",
            "  y_pred (first sample): [9.99999238e-01 8.50488339e-26 7.62451127e-07 1.19673724e-17\n",
            " 8.06081124e-27 2.03910749e-12 3.12804124e-29]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000014), db (mean=0.000002, std=0.000011)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000010), db (mean=-0.000000, std=0.000006)\n",
            "    Layer 2: dW (mean=0.000010, std=0.000043), db (mean=0.000003, std=0.000007)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000066), db (mean=0.000000, std=0.000007)\n",
            "\n",
            "Epoch 194, Batch 8/10\n",
            "  Loss: 0.000111\n",
            "  y_pred (first sample): [8.02991929e-15 7.04331104e-11 3.02049665e-05 1.01700434e-16\n",
            " 3.07724020e-05 9.99834194e-01 1.04828781e-04]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000003, std=0.000034), db (mean=-0.000007, std=0.000027)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000018), db (mean=-0.000003, std=0.000011)\n",
            "    Layer 2: dW (mean=-0.000013, std=0.000053), db (mean=-0.000006, std=0.000013)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000162), db (mean=0.000000, std=0.000023)\n",
            "\n",
            "Epoch 194, Batch 9/10\n",
            "  Loss: 0.000011\n",
            "  y_pred (first sample): [1.23791822e-05 7.75314612e-07 2.35129121e-11 9.99986842e-01\n",
            " 6.67863372e-12 2.98254362e-09 2.12372931e-12]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000003), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000002), db (mean=-0.000001, std=0.000001)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000007), db (mean=-0.000001, std=0.000001)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000034), db (mean=0.000000, std=0.000004)\n",
            "\n",
            "Epoch 194, Batch 10/10\n",
            "  Loss: 0.000010\n",
            "  y_pred (first sample): [1.95752683e-14 1.00000000e+00 1.08648294e-12 8.59346406e-12\n",
            " 3.30819701e-24 7.32104702e-12 6.86474464e-12]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000009), db (mean=-0.000000, std=0.000008)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000008), db (mean=0.000000, std=0.000004)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000026), db (mean=-0.000001, std=0.000005)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000056), db (mean=-0.000000, std=0.000004)\n",
            "\n",
            "Epoch 195, Batch 1/10\n",
            "  Loss: 0.000027\n",
            "  y_pred (first sample): [2.63390631e-32 1.94895954e-13 3.89579668e-17 9.59214896e-27\n",
            " 5.58609512e-07 3.13958289e-08 9.99999410e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000019), db (mean=-0.000002, std=0.000016)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000014), db (mean=0.000000, std=0.000010)\n",
            "    Layer 2: dW (mean=-0.000005, std=0.000054), db (mean=-0.000002, std=0.000013)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000096), db (mean=-0.000000, std=0.000012)\n",
            "\n",
            "Epoch 195, Batch 2/10\n",
            "  Loss: 0.000016\n",
            "  y_pred (first sample): [9.99996276e-01 3.72189862e-22 3.72347626e-06 2.64557466e-15\n",
            " 3.15442317e-23 6.41829816e-11 5.82343474e-25]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000013), db (mean=0.000001, std=0.000011)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000010), db (mean=-0.000000, std=0.000006)\n",
            "    Layer 2: dW (mean=0.000010, std=0.000044), db (mean=0.000003, std=0.000008)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000064), db (mean=0.000000, std=0.000007)\n",
            "\n",
            "Epoch 195, Batch 3/10\n",
            "  Loss: 0.000010\n",
            "  y_pred (first sample): [9.99999496e-01 2.37377651e-27 5.03763949e-07 1.07828162e-18\n",
            " 3.53738920e-28 5.27026538e-13 6.57022415e-31]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000003), db (mean=-0.000001, std=0.000002)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000002), db (mean=-0.000001, std=0.000001)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000006), db (mean=-0.000001, std=0.000001)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000032), db (mean=-0.000000, std=0.000004)\n",
            "\n",
            "Epoch 195, Batch 4/10\n",
            "  Loss: 0.000010\n",
            "  y_pred (first sample): [5.27728193e-12 9.99999977e-01 3.44383203e-09 1.18676037e-10\n",
            " 7.79483386e-20 1.81450798e-08 1.29991434e-09]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000003), db (mean=-0.000001, std=0.000001)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000002), db (mean=-0.000001, std=0.000001)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000007), db (mean=-0.000001, std=0.000001)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000029), db (mean=0.000000, std=0.000003)\n",
            "\n",
            "Epoch 195, Batch 5/10\n",
            "  Loss: 0.000021\n",
            "  y_pred (first sample): [9.99992558e-01 3.71661754e-25 7.44210230e-06 2.78411552e-17\n",
            " 2.24791697e-25 1.71169307e-11 2.47709599e-28]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000010), db (mean=-0.000001, std=0.000015)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000010), db (mean=0.000001, std=0.000008)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000027), db (mean=-0.000003, std=0.000007)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000067), db (mean=0.000000, std=0.000008)\n",
            "\n",
            "Epoch 195, Batch 6/10\n",
            "  Loss: 0.000065\n",
            "  y_pred (first sample): [7.30536865e-15 4.14823053e-05 4.31293207e-08 3.99932165e-12\n",
            " 5.90690083e-05 4.10381051e-05 9.99858367e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000003, std=0.000026), db (mean=-0.000006, std=0.000017)\n",
            "    Layer 1: dW (mean=-0.000003, std=0.000017), db (mean=-0.000003, std=0.000007)\n",
            "    Layer 2: dW (mean=-0.000011, std=0.000048), db (mean=-0.000004, std=0.000007)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000101), db (mean=-0.000000, std=0.000008)\n",
            "\n",
            "Epoch 195, Batch 7/10\n",
            "  Loss: 0.000044\n",
            "  y_pred (first sample): [9.99999503e-01 8.22228414e-24 4.97077211e-07 3.28666821e-16\n",
            " 1.42258094e-25 5.77933982e-12 2.42279728e-27]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000000, std=0.000045), db (mean=-0.000001, std=0.000037)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000027), db (mean=-0.000002, std=0.000020)\n",
            "    Layer 2: dW (mean=-0.000008, std=0.000079), db (mean=-0.000003, std=0.000016)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000152), db (mean=0.000000, std=0.000017)\n",
            "\n",
            "Epoch 195, Batch 8/10\n",
            "  Loss: 0.000027\n",
            "  y_pred (first sample): [1.00150678e-04 2.08082909e-17 9.99829090e-01 3.12584754e-12\n",
            " 6.85602598e-05 2.19853244e-06 3.78488899e-11]\n",
            "  y_true (first sample): [0. 0. 1. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000005), db (mean=-0.000003, std=0.000006)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000005), db (mean=-0.000001, std=0.000003)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000018), db (mean=-0.000001, std=0.000004)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000069), db (mean=0.000000, std=0.000009)\n",
            "\n",
            "Epoch 195, Batch 9/10\n",
            "  Loss: 0.000030\n",
            "  y_pred (first sample): [5.28626843e-07 5.41938969e-19 9.99908626e-01 5.48396377e-15\n",
            " 2.31783977e-05 6.76673610e-05 9.44995205e-12]\n",
            "  y_true (first sample): [0. 0. 1. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000015), db (mean=-0.000000, std=0.000009)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000008), db (mean=0.000000, std=0.000003)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000021), db (mean=-0.000001, std=0.000005)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000073), db (mean=0.000000, std=0.000010)\n",
            "\n",
            "Epoch 195, Batch 10/10\n",
            "  Loss: 0.000027\n",
            "  y_pred (first sample): [1.13908542e-10 1.51108387e-08 7.04620597e-06 2.50660152e-15\n",
            " 3.32034048e-15 9.99992938e-01 8.88641040e-11]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000028), db (mean=-0.000003, std=0.000019)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000020), db (mean=-0.000001, std=0.000012)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000064), db (mean=-0.000001, std=0.000012)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000107), db (mean=0.000000, std=0.000010)\n",
            "\n",
            "Epoch 196, Batch 1/10\n",
            "  Loss: 0.000063\n",
            "  y_pred (first sample): [9.99999499e-01 2.28758932e-27 5.01128548e-07 1.04794870e-18\n",
            " 3.36302454e-28 5.12820934e-13 6.25523432e-31]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000004, std=0.000051), db (mean=-0.000008, std=0.000041)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000038), db (mean=-0.000001, std=0.000026)\n",
            "    Layer 2: dW (mean=-0.000010, std=0.000125), db (mean=-0.000004, std=0.000025)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000199), db (mean=-0.000000, std=0.000019)\n",
            "\n",
            "Epoch 196, Batch 2/10\n",
            "  Loss: 0.000040\n",
            "  y_pred (first sample): [1.16490685e-10 1.49852567e-08 7.02087679e-06 2.50226483e-15\n",
            " 3.18784998e-15 9.99992964e-01 8.59556646e-11]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000045), db (mean=0.000002, std=0.000034)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000026), db (mean=-0.000001, std=0.000018)\n",
            "    Layer 2: dW (mean=-0.000008, std=0.000075), db (mean=-0.000003, std=0.000014)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000142), db (mean=-0.000000, std=0.000015)\n",
            "\n",
            "Epoch 196, Batch 3/10\n",
            "  Loss: 0.000002\n",
            "  y_pred (first sample): [2.72315898e-32 1.93475716e-13 4.05729063e-17 9.65851698e-27\n",
            " 5.68090378e-07 3.31086467e-08 9.99999399e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000001), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000001), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 2: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000005), db (mean=0.000000, std=0.000001)\n",
            "\n",
            "Epoch 196, Batch 4/10\n",
            "  Loss: 0.000045\n",
            "  y_pred (first sample): [9.99999256e-01 8.03695760e-26 7.44191573e-07 1.13920772e-17\n",
            " 7.12517062e-27 1.93185839e-12 2.82759454e-29]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000018), db (mean=-0.000001, std=0.000014)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000015), db (mean=-0.000001, std=0.000011)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000059), db (mean=-0.000003, std=0.000015)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000111), db (mean=-0.000000, std=0.000015)\n",
            "\n",
            "Epoch 196, Batch 5/10\n",
            "  Loss: 0.000036\n",
            "  y_pred (first sample): [9.99999513e-01 2.27164646e-27 4.86577114e-07 1.03542306e-18\n",
            " 3.13554229e-28 5.03216143e-13 5.98937744e-31]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000002, std=0.000022), db (mean=0.000000, std=0.000025)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000015), db (mean=-0.000000, std=0.000013)\n",
            "    Layer 2: dW (mean=0.000008, std=0.000050), db (mean=0.000002, std=0.000011)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000077), db (mean=0.000000, std=0.000010)\n",
            "\n",
            "Epoch 196, Batch 6/10\n",
            "  Loss: 0.000036\n",
            "  y_pred (first sample): [9.99999992e-01 2.12415518e-17 3.05765779e-09 4.91562425e-09\n",
            " 1.52393986e-22 1.82865647e-11 3.25748723e-23]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000021), db (mean=-0.000002, std=0.000018)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000012), db (mean=-0.000000, std=0.000009)\n",
            "    Layer 2: dW (mean=0.000003, std=0.000047), db (mean=0.000001, std=0.000010)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000116), db (mean=0.000000, std=0.000014)\n",
            "\n",
            "Epoch 196, Batch 7/10\n",
            "  Loss: 0.000009\n",
            "  y_pred (first sample): [5.18915925e-12 9.99999977e-01 3.38174792e-09 1.17421161e-10\n",
            " 7.40317755e-20 1.80443678e-08 1.27778596e-09]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000003), db (mean=-0.000001, std=0.000003)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000002), db (mean=-0.000001, std=0.000001)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000007), db (mean=-0.000001, std=0.000001)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000034), db (mean=-0.000000, std=0.000004)\n",
            "\n",
            "Epoch 196, Batch 8/10\n",
            "  Loss: 0.000007\n",
            "  y_pred (first sample): [9.99999985e-01 2.01400064e-26 1.46151212e-08 3.85871107e-18\n",
            " 2.07531300e-30 1.59073855e-13 7.68835620e-32]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000007), db (mean=-0.000001, std=0.000009)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000005), db (mean=0.000000, std=0.000004)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000013), db (mean=-0.000001, std=0.000003)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000018), db (mean=0.000000, std=0.000002)\n",
            "\n",
            "Epoch 196, Batch 9/10\n",
            "  Loss: 0.000023\n",
            "  y_pred (first sample): [9.99999999e-01 9.95903531e-21 9.88552125e-10 2.19094778e-11\n",
            " 1.08806979e-25 9.06673918e-13 6.84161144e-27]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000007), db (mean=-0.000002, std=0.000010)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000006), db (mean=-0.000001, std=0.000005)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000023), db (mean=-0.000001, std=0.000006)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000076), db (mean=0.000000, std=0.000010)\n",
            "\n",
            "Epoch 196, Batch 10/10\n",
            "  Loss: 0.000014\n",
            "  y_pred (first sample): [5.40768520e-07 5.40645772e-19 9.99909447e-01 5.47016827e-15\n",
            " 2.19563692e-05 6.80558513e-05 9.12752677e-12]\n",
            "  y_true (first sample): [0. 0. 1. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000015), db (mean=-0.000001, std=0.000013)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000009), db (mean=0.000001, std=0.000006)\n",
            "    Layer 2: dW (mean=-0.000000, std=0.000021), db (mean=-0.000000, std=0.000004)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000052), db (mean=-0.000000, std=0.000005)\n",
            "\n",
            "Epoch 197, Batch 1/10\n",
            "  Loss: 0.000051\n",
            "  y_pred (first sample): [4.65852055e-05 1.98848512e-19 9.99857518e-01 4.06569223e-13\n",
            " 9.56906138e-05 2.06171437e-07 4.26081152e-12]\n",
            "  y_true (first sample): [0. 0. 1. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000023), db (mean=-0.000004, std=0.000027)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000018), db (mean=0.000001, std=0.000014)\n",
            "    Layer 2: dW (mean=-0.000009, std=0.000054), db (mean=-0.000004, std=0.000013)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000126), db (mean=0.000000, std=0.000016)\n",
            "\n",
            "Epoch 197, Batch 2/10\n",
            "  Loss: 0.000005\n",
            "  y_pred (first sample): [4.26633221e-27 5.09302787e-10 9.24116442e-16 1.91000997e-21\n",
            " 4.99247231e-07 7.33293935e-08 9.99999427e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000005), db (mean=-0.000000, std=0.000006)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000004), db (mean=0.000000, std=0.000003)\n",
            "    Layer 2: dW (mean=-0.000000, std=0.000008), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000012), db (mean=-0.000000, std=0.000002)\n",
            "\n",
            "Epoch 197, Batch 3/10\n",
            "  Loss: 0.000003\n",
            "  y_pred (first sample): [9.99995824e-01 2.46658494e-15 2.26020304e-08 4.15314413e-06\n",
            " 6.22560969e-18 1.33982585e-10 1.13044242e-19]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000006), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000017), db (mean=-0.000000, std=0.000001)\n",
            "\n",
            "Epoch 197, Batch 4/10\n",
            "  Loss: 0.000021\n",
            "  y_pred (first sample): [2.57074398e-12 9.99999996e-01 4.28648037e-10 1.44550686e-10\n",
            " 1.96031926e-20 2.73545323e-09 5.75916613e-10]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000025), db (mean=-0.000002, std=0.000016)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000016), db (mean=-0.000001, std=0.000009)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000052), db (mean=-0.000001, std=0.000009)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000091), db (mean=-0.000000, std=0.000009)\n",
            "\n",
            "Epoch 197, Batch 5/10\n",
            "  Loss: 0.000017\n",
            "  y_pred (first sample): [1.97137880e-14 1.00000000e+00 1.07080597e-12 8.65179100e-12\n",
            " 3.01087537e-24 7.07418781e-12 6.55778416e-12]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000021), db (mean=0.000001, std=0.000017)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000012), db (mean=0.000000, std=0.000007)\n",
            "    Layer 2: dW (mean=0.000004, std=0.000036), db (mean=0.000001, std=0.000006)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000066), db (mean=0.000000, std=0.000007)\n",
            "\n",
            "Epoch 197, Batch 6/10\n",
            "  Loss: 0.000044\n",
            "  y_pred (first sample): [4.06068937e-14 1.41454855e-15 8.01539040e-05 2.83930469e-15\n",
            " 9.99807561e-01 5.92604906e-05 5.30243890e-05]\n",
            "  y_true (first sample): [0. 0. 0. 0. 1. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000025), db (mean=-0.000002, std=0.000021)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000016), db (mean=0.000001, std=0.000011)\n",
            "    Layer 2: dW (mean=0.000002, std=0.000052), db (mean=0.000001, std=0.000011)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000116), db (mean=-0.000000, std=0.000013)\n",
            "\n",
            "Epoch 197, Batch 7/10\n",
            "  Loss: 0.000033\n",
            "  y_pred (first sample): [1.15158842e-05 1.95991268e-09 5.61797250e-13 9.99988482e-01\n",
            " 1.37487867e-14 1.29559541e-11 2.96649620e-16]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000007), db (mean=-0.000003, std=0.000018)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000006), db (mean=-0.000002, std=0.000009)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000020), db (mean=-0.000002, std=0.000007)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000051), db (mean=-0.000000, std=0.000008)\n",
            "\n",
            "Epoch 197, Batch 8/10\n",
            "  Loss: 0.000038\n",
            "  y_pred (first sample): [1.97759644e-14 1.00000000e+00 1.07162763e-12 8.68386534e-12\n",
            " 3.00217125e-24 7.05718357e-12 6.53726446e-12]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000025), db (mean=-0.000001, std=0.000018)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000014), db (mean=-0.000002, std=0.000006)\n",
            "    Layer 2: dW (mean=-0.000005, std=0.000043), db (mean=-0.000002, std=0.000006)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000080), db (mean=0.000000, std=0.000007)\n",
            "\n",
            "Epoch 197, Batch 9/10\n",
            "  Loss: 0.000020\n",
            "  y_pred (first sample): [9.99999519e-01 2.14876410e-27 4.80905504e-07 9.93933831e-19\n",
            " 2.91799820e-28 4.78500767e-13 5.59977746e-31]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000006), db (mean=0.000000, std=0.000014)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000006), db (mean=-0.000001, std=0.000007)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000019), db (mean=-0.000002, std=0.000006)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000049), db (mean=0.000000, std=0.000008)\n",
            "\n",
            "Epoch 197, Batch 10/10\n",
            "  Loss: 0.000039\n",
            "  y_pred (first sample): [2.37817067e-31 1.10215160e-12 1.11598532e-17 3.46141516e-25\n",
            " 6.48266884e-07 2.43922089e-08 9.99999327e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000000, std=0.000046), db (mean=-0.000001, std=0.000021)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000023), db (mean=-0.000001, std=0.000009)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000060), db (mean=-0.000002, std=0.000009)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000131), db (mean=0.000000, std=0.000013)\n",
            "\n",
            "Epoch 198, Batch 1/10\n",
            "  Loss: 0.000049\n",
            "  y_pred (first sample): [9.99992903e-01 3.36955975e-25 7.09714331e-06 2.56954909e-17\n",
            " 1.85785451e-25 1.56486130e-11 2.11219750e-28]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000019), db (mean=-0.000005, std=0.000019)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000015), db (mean=-0.000001, std=0.000011)\n",
            "    Layer 2: dW (mean=-0.000007, std=0.000059), db (mean=-0.000003, std=0.000014)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000149), db (mean=-0.000000, std=0.000020)\n",
            "\n",
            "Epoch 198, Batch 2/10\n",
            "  Loss: 0.000038\n",
            "  y_pred (first sample): [6.21063011e-16 2.85206343e-17 1.83223035e-05 3.82801030e-17\n",
            " 9.99939246e-01 2.01965894e-05 2.22347911e-05]\n",
            "  y_true (first sample): [0. 0. 0. 0. 1. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000036), db (mean=-0.000004, std=0.000027)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000022), db (mean=-0.000001, std=0.000014)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000057), db (mean=-0.000001, std=0.000011)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000077), db (mean=-0.000000, std=0.000007)\n",
            "\n",
            "Epoch 198, Batch 3/10\n",
            "  Loss: 0.000007\n",
            "  y_pred (first sample): [1.19758645e-05 7.61477660e-07 2.29579755e-11 9.99987260e-01\n",
            " 6.67094000e-12 2.98340924e-09 2.09529991e-12]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000004), db (mean=-0.000001, std=0.000005)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000003), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000009), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000017), db (mean=-0.000000, std=0.000002)\n",
            "\n",
            "Epoch 198, Batch 4/10\n",
            "  Loss: 0.000038\n",
            "  y_pred (first sample): [2.24611311e-09 9.99999971e-01 1.11068591e-08 1.50031129e-08\n",
            " 8.47079062e-22 2.70772010e-10 5.22418662e-12]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000025), db (mean=-0.000001, std=0.000018)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000014), db (mean=-0.000002, std=0.000006)\n",
            "    Layer 2: dW (mean=-0.000005, std=0.000043), db (mean=-0.000002, std=0.000006)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000080), db (mean=0.000000, std=0.000007)\n",
            "\n",
            "Epoch 198, Batch 5/10\n",
            "  Loss: 0.000002\n",
            "  y_pred (first sample): [6.43794396e-06 7.61449809e-07 1.05745063e-12 9.99992800e-01\n",
            " 1.20126574e-13 1.71792838e-10 1.26189388e-13]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000001), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000005), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000011), db (mean=-0.000000, std=0.000001)\n",
            "\n",
            "Epoch 198, Batch 6/10\n",
            "  Loss: 0.000063\n",
            "  y_pred (first sample): [1.86252044e-16 1.43858627e-17 1.09272178e-05 1.33551648e-17\n",
            " 9.99948901e-01 1.72018801e-05 2.29701558e-05]\n",
            "  y_true (first sample): [0. 0. 0. 0. 1. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000069), db (mean=0.000002, std=0.000046)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000038), db (mean=0.000000, std=0.000021)\n",
            "    Layer 2: dW (mean=0.000002, std=0.000113), db (mean=0.000001, std=0.000020)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000176), db (mean=0.000000, std=0.000019)\n",
            "\n",
            "Epoch 198, Batch 7/10\n",
            "  Loss: 0.000005\n",
            "  y_pred (first sample): [1.10351676e-12 9.99995336e-01 3.63322092e-10 7.32205292e-08\n",
            " 7.15955598e-15 1.44257973e-10 4.59068241e-06]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000003), db (mean=-0.000000, std=0.000003)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000007), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000016), db (mean=0.000000, std=0.000001)\n",
            "\n",
            "Epoch 198, Batch 8/10\n",
            "  Loss: 0.000003\n",
            "  y_pred (first sample): [6.51028210e-08 9.99984938e-01 1.44329022e-05 3.03947256e-07\n",
            " 5.95769874e-15 1.44919850e-07 1.14630552e-07]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000004), db (mean=-0.000000, std=0.000005)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000003), db (mean=0.000000, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000008), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000014), db (mean=0.000000, std=0.000001)\n",
            "\n",
            "Epoch 198, Batch 9/10\n",
            "  Loss: 0.000040\n",
            "  y_pred (first sample): [9.99999264e-01 7.43129775e-26 7.36121594e-07 1.07632104e-17\n",
            " 6.33904452e-27 1.79537511e-12 2.54048156e-29]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000009), db (mean=-0.000002, std=0.000028)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000011), db (mean=-0.000002, std=0.000016)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000036), db (mean=-0.000002, std=0.000012)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000094), db (mean=0.000000, std=0.000017)\n",
            "\n",
            "Epoch 198, Batch 10/10\n",
            "  Loss: 0.000023\n",
            "  y_pred (first sample): [3.87466037e-18 9.99998839e-01 2.59279310e-13 8.47305412e-13\n",
            " 6.48053533e-19 1.07401887e-10 1.16060739e-06]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000011), db (mean=-0.000001, std=0.000016)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000010), db (mean=0.000001, std=0.000008)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000030), db (mean=-0.000002, std=0.000007)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000058), db (mean=0.000000, std=0.000007)\n",
            "\n",
            "Epoch 199, Batch 1/10\n",
            "  Loss: 0.000025\n",
            "  y_pred (first sample): [7.76794684e-15 6.40188120e-11 2.96922180e-05 9.77118220e-17\n",
            " 2.88356104e-05 9.99846676e-01 9.47960814e-05]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000029), db (mean=-0.000002, std=0.000019)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000018), db (mean=-0.000001, std=0.000011)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000060), db (mean=-0.000001, std=0.000011)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000104), db (mean=-0.000000, std=0.000010)\n",
            "\n",
            "Epoch 199, Batch 2/10\n",
            "  Loss: 0.000026\n",
            "  y_pred (first sample): [9.99997754e-01 4.65689645e-21 2.24631789e-06 9.43730001e-15\n",
            " 8.83799868e-24 1.71207452e-10 4.63450534e-25]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000007), db (mean=-0.000003, std=0.000004)\n",
            "    Layer 1: dW (mean=-0.000002, std=0.000004), db (mean=-0.000002, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000014), db (mean=-0.000002, std=0.000002)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000084), db (mean=0.000000, std=0.000010)\n",
            "\n",
            "Epoch 199, Batch 3/10\n",
            "  Loss: 0.000004\n",
            "  y_pred (first sample): [1.16843146e-05 7.70265316e-07 2.25357256e-11 9.99987542e-01\n",
            " 6.68317898e-12 3.01075942e-09 2.12410978e-12]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000002), db (mean=-0.000001, std=0.000003)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000005), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000011), db (mean=0.000000, std=0.000001)\n",
            "\n",
            "Epoch 199, Batch 4/10\n",
            "  Loss: 0.000020\n",
            "  y_pred (first sample): [8.51622404e-15 7.13663544e-18 8.60493090e-05 1.98943581e-16\n",
            " 9.99897402e-01 1.37713226e-05 2.77725648e-06]\n",
            "  y_true (first sample): [0. 0. 0. 0. 1. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000001, std=0.000013), db (mean=0.000001, std=0.000011)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000010), db (mean=-0.000001, std=0.000006)\n",
            "    Layer 2: dW (mean=0.000008, std=0.000042), db (mean=0.000002, std=0.000007)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000082), db (mean=-0.000000, std=0.000009)\n",
            "\n",
            "Epoch 199, Batch 5/10\n",
            "  Loss: 0.000003\n",
            "  y_pred (first sample): [9.99996419e-01 3.31259208e-22 3.58077999e-06 2.41540362e-15\n",
            " 2.56504000e-23 5.74847577e-11 4.86937595e-25]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000002), db (mean=-0.000001, std=0.000003)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 2: dW (mean=0.000000, std=0.000005), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000009), db (mean=0.000000, std=0.000001)\n",
            "\n",
            "Epoch 199, Batch 6/10\n",
            "  Loss: 0.000054\n",
            "  y_pred (first sample): [1.90840850e-14 1.00000000e+00 1.02825923e-12 8.53878354e-12\n",
            " 2.78157475e-24 6.76274261e-12 6.38957691e-12]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000032), db (mean=-0.000004, std=0.000034)\n",
            "    Layer 1: dW (mean=0.000002, std=0.000023), db (mean=0.000002, std=0.000018)\n",
            "    Layer 2: dW (mean=-0.000009, std=0.000074), db (mean=-0.000004, std=0.000017)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000197), db (mean=-0.000000, std=0.000023)\n",
            "\n",
            "Epoch 199, Batch 7/10\n",
            "  Loss: 0.000023\n",
            "  y_pred (first sample): [1.09206646e-10 1.39823724e-08 6.69931771e-06 2.36196770e-15\n",
            " 2.93877656e-15 9.99993287e-01 8.11019845e-11]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000027), db (mean=-0.000001, std=0.000018)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000016), db (mean=-0.000001, std=0.000010)\n",
            "    Layer 2: dW (mean=-0.000004, std=0.000055), db (mean=-0.000001, std=0.000010)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000097), db (mean=0.000000, std=0.000009)\n",
            "\n",
            "Epoch 199, Batch 8/10\n",
            "  Loss: 0.000042\n",
            "  y_pred (first sample): [5.52970245e-16 2.62036083e-17 1.74868629e-05 3.45005353e-17\n",
            " 9.99940848e-01 1.97016512e-05 2.19635279e-05]\n",
            "  y_true (first sample): [0. 0. 0. 0. 1. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000009), db (mean=-0.000001, std=0.000025)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000010), db (mean=-0.000001, std=0.000013)\n",
            "    Layer 2: dW (mean=-0.000005, std=0.000032), db (mean=-0.000003, std=0.000011)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000079), db (mean=-0.000000, std=0.000013)\n",
            "\n",
            "Epoch 199, Batch 9/10\n",
            "  Loss: 0.000039\n",
            "  y_pred (first sample): [5.78240257e-26 3.56241575e-12 4.26378809e-11 1.22198813e-23\n",
            " 5.09900485e-05 8.45373007e-05 9.99864473e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000000, std=0.000044), db (mean=-0.000002, std=0.000032)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000026), db (mean=-0.000001, std=0.000019)\n",
            "    Layer 2: dW (mean=-0.000007, std=0.000077), db (mean=-0.000003, std=0.000015)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000146), db (mean=-0.000000, std=0.000017)\n",
            "\n",
            "Epoch 199, Batch 10/10\n",
            "  Loss: 0.000028\n",
            "  y_pred (first sample): [6.33640868e-06 7.48598001e-07 1.02020614e-12 9.99992915e-01\n",
            " 1.15715823e-13 1.67119482e-10 1.21290640e-13]\n",
            "  y_true (first sample): [0. 0. 0. 1. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000007), db (mean=-0.000002, std=0.000007)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000006), db (mean=-0.000001, std=0.000003)\n",
            "    Layer 2: dW (mean=-0.000002, std=0.000018), db (mean=-0.000001, std=0.000004)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000056), db (mean=-0.000000, std=0.000008)\n",
            "\n",
            "Epoch 200, Batch 1/10\n",
            "  Loss: 0.000052\n",
            "  y_pred (first sample): [6.35926434e-17 9.99999751e-01 8.49035296e-13 4.99481191e-12\n",
            " 3.43139466e-19 5.12720115e-11 2.48819403e-07]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000010), db (mean=-0.000001, std=0.000019)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000010), db (mean=-0.000000, std=0.000009)\n",
            "    Layer 2: dW (mean=-0.000008, std=0.000034), db (mean=-0.000004, std=0.000008)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000109), db (mean=-0.000000, std=0.000018)\n",
            "\n",
            "Epoch 200, Batch 2/10\n",
            "  Loss: 0.000034\n",
            "  y_pred (first sample): [9.99999278e-01 7.10430098e-26 7.22319864e-07 1.04124480e-17\n",
            " 5.90132717e-27 1.72968942e-12 2.38147895e-29]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000002, std=0.000019), db (mean=-0.000003, std=0.000015)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000014), db (mean=-0.000000, std=0.000009)\n",
            "    Layer 2: dW (mean=-0.000006, std=0.000051), db (mean=-0.000002, std=0.000012)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000095), db (mean=0.000000, std=0.000012)\n",
            "\n",
            "Epoch 200, Batch 3/10\n",
            "  Loss: 0.000023\n",
            "  y_pred (first sample): [9.99997789e-01 4.53365736e-21 2.21093506e-06 9.23332916e-15\n",
            " 8.34143463e-24 1.66548647e-10 4.42358032e-25]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000006), db (mean=-0.000003, std=0.000016)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000006), db (mean=-0.000001, std=0.000009)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000020), db (mean=-0.000002, std=0.000007)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000051), db (mean=-0.000000, std=0.000009)\n",
            "\n",
            "Epoch 200, Batch 4/10\n",
            "  Loss: 0.000034\n",
            "  y_pred (first sample): [9.99999999e-01 9.17733185e-21 9.52367578e-10 2.11111846e-11\n",
            " 9.46513466e-26 8.24485449e-13 6.01759748e-27]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000017), db (mean=-0.000003, std=0.000017)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000011), db (mean=-0.000000, std=0.000009)\n",
            "    Layer 2: dW (mean=-0.000003, std=0.000031), db (mean=-0.000001, std=0.000007)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000108), db (mean=0.000000, std=0.000013)\n",
            "\n",
            "Epoch 200, Batch 5/10\n",
            "  Loss: 0.000001\n",
            "  y_pred (first sample): [2.08985848e-32 1.63706357e-13 3.57927481e-17 7.82640462e-27\n",
            " 5.49531216e-07 3.00614658e-08 9.99999420e-01]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 0. 1.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000001), db (mean=-0.000000, std=0.000001)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000001), db (mean=-0.000000, std=0.000000)\n",
            "    Layer 2: dW (mean=-0.000000, std=0.000001), db (mean=-0.000000, std=0.000000)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000002), db (mean=-0.000000, std=0.000000)\n",
            "\n",
            "Epoch 200, Batch 6/10\n",
            "  Loss: 0.000004\n",
            "  y_pred (first sample): [9.99995906e-01 2.32493149e-15 2.22133361e-08 4.07184744e-06\n",
            " 5.76062130e-18 1.25980852e-10 1.04008289e-19]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000003), db (mean=-0.000000, std=0.000004)\n",
            "    Layer 1: dW (mean=0.000000, std=0.000002), db (mean=0.000000, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000006), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000009), db (mean=-0.000000, std=0.000001)\n",
            "\n",
            "Epoch 200, Batch 7/10\n",
            "  Loss: 0.000016\n",
            "  y_pred (first sample): [1.88083407e-14 1.00000000e+00 1.01915892e-12 8.43283253e-12\n",
            " 2.64815365e-24 6.55935833e-12 6.32447980e-12]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=0.000002, std=0.000018), db (mean=0.000002, std=0.000015)\n",
            "    Layer 1: dW (mean=0.000001, std=0.000012), db (mean=0.000001, std=0.000007)\n",
            "    Layer 2: dW (mean=0.000010, std=0.000042), db (mean=0.000003, std=0.000007)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000061), db (mean=-0.000000, std=0.000007)\n",
            "\n",
            "Epoch 200, Batch 8/10\n",
            "  Loss: 0.000047\n",
            "  y_pred (first sample): [7.44462465e-15 6.33755739e-11 2.95500757e-05 9.43467552e-17\n",
            " 2.82767833e-05 9.99846989e-01 9.51844213e-05]\n",
            "  y_true (first sample): [0. 0. 0. 0. 0. 1. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000000, std=0.000027), db (mean=-0.000001, std=0.000014)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000015), db (mean=-0.000001, std=0.000007)\n",
            "    Layer 2: dW (mean=-0.000009, std=0.000042), db (mean=-0.000002, std=0.000007)\n",
            "    Layer 3: dW (mean=-0.000000, std=0.000071), db (mean=-0.000000, std=0.000005)\n",
            "\n",
            "Epoch 200, Batch 9/10\n",
            "  Loss: 0.000006\n",
            "  y_pred (first sample): [9.99999956e-01 1.57183860e-25 4.44633731e-08 1.81401625e-17\n",
            " 5.24201872e-29 5.32692387e-13 1.49522317e-30]\n",
            "  y_true (first sample): [1. 0. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000004), db (mean=-0.000001, std=0.000005)\n",
            "    Layer 1: dW (mean=-0.000000, std=0.000003), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 2: dW (mean=-0.000001, std=0.000010), db (mean=-0.000000, std=0.000002)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000021), db (mean=0.000000, std=0.000002)\n",
            "\n",
            "Epoch 200, Batch 10/10\n",
            "  Loss: 0.000045\n",
            "  y_pred (first sample): [5.72828427e-10 9.99986465e-01 2.10154300e-06 8.29184108e-09\n",
            " 1.68535079e-13 2.37247884e-06 9.05180460e-06]\n",
            "  y_true (first sample): [0. 1. 0. 0. 0. 0. 0.]\n",
            "  Gradients (per layer):\n",
            "    Layer 0: dW (mean=-0.000001, std=0.000018), db (mean=-0.000002, std=0.000010)\n",
            "    Layer 1: dW (mean=-0.000001, std=0.000012), db (mean=-0.000001, std=0.000006)\n",
            "    Layer 2: dW (mean=0.000001, std=0.000044), db (mean=0.000000, std=0.000007)\n",
            "    Layer 3: dW (mean=0.000000, std=0.000114), db (mean=0.000000, std=0.000012)\n",
            "\n",
            "=== Epoch 200 Summary ===\n",
            "Average Batch Loss: 0.000026\n",
            "Full Dataset Loss: 0.000026\n",
            "Final y_pred sample: [3.32612093e-14 1.19004041e-15 7.34364530e-05 2.39447842e-15\n",
            " 9.99820667e-01 5.47641522e-05 5.11320940e-05]\n",
            "Final y_true sample: [0. 0. 0. 0. 1. 0. 0.]\n",
            "\n",
            "Test accuracy: 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1fad28a",
        "outputId": "46fa35ed-9919-41f7-f0f2-689b38250447"
      },
      "source": [
        "# Get the features of the last animal in the original DataFrame\n",
        "# Exclude 'animal_name' and 'class_type'\n",
        "last_animal_features_df = df.tail(1).drop(['animal_name', 'class_type'], axis=1)\n",
        "\n",
        "# Convert the DataFrame row to a NumPy array and transpose it\n",
        "# to match the expected input shape (number_of_features, 1)\n",
        "new_animal_features = last_animal_features_df.values.T # Shape (16, 1)\n",
        "\n",
        "\n",
        "# Make a prediction for the new animal\n",
        "prediction = nn.forward(new_animal_features)\n",
        "\n",
        "# Interpret the prediction (get the class with the highest probability)\n",
        "predicted_class_index = np.argmax(prediction, axis=0)\n",
        "\n",
        "# The original class labels in the zoo dataset are 1-7.\n",
        "# Our one-hot encoding shifted them to 0-6.\n",
        "# So, we add 1 to the predicted index to get the original class number.\n",
        "predicted_class = predicted_class_index[0] + 1\n",
        "\n",
        "print(f\"\\nFeatures of the animal: {new_animal_features.T}\")\n",
        "print(f\"The predicted class for the new animal is: {predicted_class}\")\n",
        "\n",
        "# You can compare this to the actual class of the last animal in the original df\n",
        "actual_class = df.tail(1)['class_type'].values[0]\n",
        "print(f\"The actual class of the last animal is: {actual_class}\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Features of the animal: [[0 1 1 0 1 0 0 0 1 1 0 0 2 1 0 0]]\n",
            "The predicted class for the new animal is: 2\n",
            "The actual class of the last animal is: 2\n"
          ]
        }
      ]
    }
  ]
}